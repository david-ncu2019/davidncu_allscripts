{
 "cells": [
  {
   "cell_type": "raw",
   "id": "039bbf76-1f65-4dee-92d4-dba9ca4d2c94",
   "metadata": {},
   "source": [
    "# ==============================================================================\n",
    "# SCRIPT DESCRIPTION\n",
    "# ==============================================================================\n",
    "# This script processes time-series data from multiple monitoring stations for use\n",
    "# in a Geographically and Temporally Weighted Regression (GTWR) model.\n",
    "#\n",
    "# The script performs the following key steps:\n",
    "# 1. Loads a comprehensive dataset containing measurements from various stations\n",
    "#    over time.\n",
    "# 2. Iterates through distinct data \"layers\" (e.g., from different geological strata).\n",
    "# 3. For each layer, it processes the data station by station:\n",
    "#    a. It filters out stations that have incomplete or zero-value data for\n",
    "#       the current layer, ensuring data quality.\n",
    "#    b. It normalizes the time-series measurements (both for the layer and for\n",
    "#       InSAR 'CUMDISP') by subtracting the initial measurement, effectively\n",
    "#       setting the start of the time series to zero. This focuses the analysis\n",
    "#       on the change over time.\n",
    "# 4. It assembles the cleaned and normalized data from all valid stations for the\n",
    "#    current layer into a single DataFrame.\n",
    "# 5. Finally, it saves this processed DataFrame to a new CSV file, creating one\n",
    "#    output file for each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0996b76d-c022-4d66-a31e-3f5dcd152ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from appgeopy import *\n",
    "from my_packages import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd963f21-e782-404d-9f50-fe65eae1c462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>STATION</th>\n",
       "      <th>X_TWD97</th>\n",
       "      <th>Y_TWD97</th>\n",
       "      <th>Layer_1</th>\n",
       "      <th>Layer_2</th>\n",
       "      <th>Layer_3</th>\n",
       "      <th>Layer_4</th>\n",
       "      <th>CUMDISP</th>\n",
       "      <th>monthly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>ANHE</td>\n",
       "      <td>179539.204623</td>\n",
       "      <td>2.602035e+06</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>-88.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>BEICHEN</td>\n",
       "      <td>178859.958807</td>\n",
       "      <td>2.608229e+06</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-32.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>CANLIN</td>\n",
       "      <td>173088.151033</td>\n",
       "      <td>2.608157e+06</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-45.0</td>\n",
       "      <td>-56.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>DONGGUANG</td>\n",
       "      <td>175783.144962</td>\n",
       "      <td>2.616755e+06</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>-77.0</td>\n",
       "      <td>-93.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>ERLUN</td>\n",
       "      <td>190429.148778</td>\n",
       "      <td>2.629865e+06</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2161</th>\n",
       "      <td>2021-12-01</td>\n",
       "      <td>TUKU</td>\n",
       "      <td>187772.134694</td>\n",
       "      <td>2.620611e+06</td>\n",
       "      <td>-38.0</td>\n",
       "      <td>-203.0</td>\n",
       "      <td>-377.0</td>\n",
       "      <td>-34.0</td>\n",
       "      <td>-259.472772</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2162</th>\n",
       "      <td>2021-12-01</td>\n",
       "      <td>XINSHENG</td>\n",
       "      <td>188342.160622</td>\n",
       "      <td>2.648279e+06</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>-103.0</td>\n",
       "      <td>-94.0</td>\n",
       "      <td>-125.0</td>\n",
       "      <td>-164.040167</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2163</th>\n",
       "      <td>2021-12-01</td>\n",
       "      <td>XIUTAN</td>\n",
       "      <td>183652.118876</td>\n",
       "      <td>2.617397e+06</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-187.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-359.210283</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2164</th>\n",
       "      <td>2021-12-01</td>\n",
       "      <td>XIZHOU</td>\n",
       "      <td>199069.972355</td>\n",
       "      <td>2.638501e+06</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>-37.0</td>\n",
       "      <td>-56.0</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>-180.072782</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2165</th>\n",
       "      <td>2021-12-01</td>\n",
       "      <td>YUANCHANG</td>\n",
       "      <td>179485.192133</td>\n",
       "      <td>2.616803e+06</td>\n",
       "      <td>-216.0</td>\n",
       "      <td>-302.0</td>\n",
       "      <td>-362.0</td>\n",
       "      <td>-129.0</td>\n",
       "      <td>-279.977873</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2166 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           time    STATION        X_TWD97       Y_TWD97  Layer_1  Layer_2  \\\n",
       "0    2016-04-01       ANHE  179539.204623  2.602035e+06    -33.0    -88.0   \n",
       "1    2016-04-01    BEICHEN  178859.958807  2.608229e+06     -8.0    -32.0   \n",
       "2    2016-04-01     CANLIN  173088.151033  2.608157e+06     -3.0    -45.0   \n",
       "3    2016-04-01  DONGGUANG  175783.144962  2.616755e+06    -23.0    -77.0   \n",
       "4    2016-04-01      ERLUN  190429.148778  2.629865e+06    -19.0    -23.0   \n",
       "...         ...        ...            ...           ...      ...      ...   \n",
       "2161 2021-12-01       TUKU  187772.134694  2.620611e+06    -38.0   -203.0   \n",
       "2162 2021-12-01   XINSHENG  188342.160622  2.648279e+06    -19.0   -103.0   \n",
       "2163 2021-12-01     XIUTAN  183652.118876  2.617397e+06   -182.0   -187.0   \n",
       "2164 2021-12-01     XIZHOU  199069.972355  2.638501e+06    -22.0    -37.0   \n",
       "2165 2021-12-01  YUANCHANG  179485.192133  2.616803e+06   -216.0   -302.0   \n",
       "\n",
       "      Layer_3  Layer_4     CUMDISP  monthly  \n",
       "0       -13.0     -2.0    0.000000        0  \n",
       "1       -20.0     -8.0    0.000000        0  \n",
       "2       -56.0    -16.0    0.000000        0  \n",
       "3       -93.0     -3.0    0.000000        0  \n",
       "4       -22.0     -4.0    0.000000        0  \n",
       "...       ...      ...         ...      ...  \n",
       "2161   -377.0    -34.0 -259.472772       68  \n",
       "2162    -94.0   -125.0 -164.040167       68  \n",
       "2163   -182.0     -6.0 -359.210283       68  \n",
       "2164    -56.0    -21.0 -180.072782       68  \n",
       "2165   -362.0   -129.0 -279.977873       68  \n",
       "\n",
       "[2166 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the primary dataset from a compressed pickle file.\n",
    "# This file contains the raw time-series data for all stations.\n",
    "# df = pd.read_pickle(\n",
    "#     r\"D:\\1000_SCRIPTS\\003_Project002\\20250222_GTWR001\\3_MGTWR\\2_Test_Run001\\20250416_GWR_InputData_CUMDISP_MLCW_InSAR.xz\"\n",
    "# )\n",
    "\n",
    "df = pd.read_pickle(r\"20250724_GWR_InputData_MLCW_InSAR.xz\")\n",
    "\n",
    "# Engineer a time-based feature: create a column representing the month of each reading.\n",
    "df[\"monthly\"] = df[\"time\"].dt.to_period(\"M\")\n",
    "\n",
    "# Calculate the number of months elapsed since the very first measurement.\n",
    "# This creates a simple integer index for the time periods (0, 1, 2, ...).\n",
    "df[\"monthly\"] = df[\"monthly\"].sub(df[\"monthly\"].iloc[0]).apply(lambda x: x.n)\n",
    "\n",
    "# Get a list of all unique station names present in the dataset.\n",
    "unique_stations = df[\"STATION\"].unique()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39286e76-88c4-42fa-8fcb-f442c915b5fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88664de41f97464d8f8676d190c2cd47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Layers:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Layer 1\n",
      "Skip ANHE\n",
      "Skip TANQIFENXIAO\n",
      "Skip XINPI\n",
      "20250724_GTWR_InputData_MLCW_InSAR_Layer_1.csv\n",
      "Saved data for Layer_1 to 20250724_GTWR_InputData_MLCW_InSAR_Layer_1.csv\n",
      "\n",
      "Processing Layer 2\n",
      "Skip ANHE\n",
      "Skip TANQIFENXIAO\n",
      "Skip XINPI\n",
      "20250724_GTWR_InputData_MLCW_InSAR_Layer_2.csv\n",
      "Saved data for Layer_2 to 20250724_GTWR_InputData_MLCW_InSAR_Layer_2.csv\n",
      "\n",
      "Processing Layer 3\n",
      "Skip ANHE\n",
      "Skip JIANYANG\n",
      "Skip TANQIFENXIAO\n",
      "Skip XINPI\n",
      "20250724_GTWR_InputData_MLCW_InSAR_Layer_3.csv\n",
      "Saved data for Layer_3 to 20250724_GTWR_InputData_MLCW_InSAR_Layer_3.csv\n",
      "\n",
      "Processing Layer 4\n",
      "Skip ANHE\n",
      "Skip HAIFENG\n",
      "Skip JIANYANG\n",
      "Skip JIAXING\n",
      "Skip TANQIFENXIAO\n",
      "Skip XINPI\n",
      "Skip XINXING\n",
      "20250724_GTWR_InputData_MLCW_InSAR_Layer_4.csv\n",
      "Saved data for Layer_4 to 20250724_GTWR_InputData_MLCW_InSAR_Layer_4.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 2. MAIN PROCESSING LOOP\n",
    "# This section iterates through each data layer to process and save its data.\n",
    "# ==============================================================================\n",
    "\n",
    "# --- Outer Loop: Iterate through each data layer (e.g., Layer 1 to 4) ---\n",
    "for lay_num in trange(1, 5, desc=\"Processing Layers\"):\n",
    "\n",
    "    # Initialize an empty DataFrame to store the processed data for the current layer.\n",
    "    final_mlcw_input = pd.DataFrame()\n",
    "    print(f\"Processing Layer {lay_num}\")\n",
    "\n",
    "    # --- Inner Loop: Iterate through each unique station ---\n",
    "    for select_station in unique_stations:\n",
    "\n",
    "        # Define the column name for the current layer being processed.\n",
    "        current_layer = f\"Layer_{lay_num}\"\n",
    "\n",
    "        # Filter the main DataFrame to get the data for only the current station.\n",
    "        df_byStation = df.query(\"STATION==@select_station\")\n",
    "\n",
    "        # smooth the cumulative displacement with windows = 3\n",
    "        # it means taking 3 points, including the current point (so we have 2 neighbors)\n",
    "        # df_byStation[\"CUMDISP_ma3\"] = smoothing.simple_moving_average(\n",
    "        #     df_byStation[\"CUMDISP\"], window_size=3\n",
    "        # )\n",
    "\n",
    "        # --- Data Quality Checks ---\n",
    "        # Define conditions to identify and skip stations with unreliable data.\n",
    "        # Condition 1: The station has too few data points (less than 67).\n",
    "        cond1 = len(df_byStation) < 67\n",
    "        # Condition 2: All measurements for the current layer are missing (NaN).\n",
    "        cond2 = df_byStation[current_layer].isna().all()\n",
    "        # Condition 3: All measurements for the current layer are zero.\n",
    "        cond3 = df_byStation[current_layer].mean() == 0\n",
    "\n",
    "        # If any of the above conditions are true, skip this station and move to the next.\n",
    "        if cond1 or cond2 or cond3:\n",
    "            print(f\"Skip {select_station}\")\n",
    "            continue\n",
    "\n",
    "        # --- Data Normalization ---\n",
    "        # Identify all columns that contain measurement data.\n",
    "        measurement_cols = [col for col in df.columns if \"Layer\" in col] + [\n",
    "            \"CUMDISP\"\n",
    "        ]\n",
    "        # Isolate the two columns we want to normalize for this run.\n",
    "        select_measure_cols = [current_layer, \"CUMDISP\"]\n",
    "\n",
    "        # Separate the station's informational data (like coordinates, time)\n",
    "        # from its measurement data.\n",
    "        info_df_byStation = df_byStation.loc[\n",
    "            :, df_byStation.columns.difference(measurement_cols)\n",
    "        ]\n",
    "        measurement_df_byStation = df_byStation.loc[:, select_measure_cols]\n",
    "\n",
    "        # **CRITICAL STEP: Normalize the measurements.**\n",
    "        # Subtract the first measurement (iloc[0]) from all subsequent measurements.\n",
    "        # This makes the time series start at 0 and represent the change over time.\n",
    "\n",
    "        # measurement_df_byStation = measurement_df_byStation.subtract(\n",
    "        #     measurement_df_byStation.iloc[0, :], axis=1\n",
    "        # )\n",
    "        measurement_df_byStation[current_layer] = (\n",
    "            measurement_df_byStation[current_layer]\n",
    "            - measurement_df_byStation[current_layer].iloc[0]\n",
    "        )\n",
    "\n",
    "        # --- Recombine and Finalize Data for the Station ---\n",
    "        # Concatenate the informational columns and the newly normalized measurement columns.\n",
    "        temp = pd.concat([info_df_byStation, measurement_df_byStation], axis=1)\n",
    "\n",
    "        # Select a fixed window of time steps (from the 2nd to the 67th).\n",
    "        # The first row is skipped because it's now all zeros after normalization.\n",
    "        temp = temp.iloc[1:68, :]\n",
    "\n",
    "        # Append the cleaned, normalized data for this station to the layer's final DataFrame.\n",
    "        final_mlcw_input = pd.concat(\n",
    "            [final_mlcw_input, temp], axis=0, ignore_index=True\n",
    "        )\n",
    "\n",
    "    # --- Save the Processed Data for the Layer ---\n",
    "    # After processing all stations, save the combined DataFrame to a CSV file.\n",
    "    today_string = datetime.today().strftime(\"%Y%m%d\")\n",
    "    output_filename = (\n",
    "        f\"{today_string}_GTWR_InputData_MLCW_InSAR_{current_layer}.csv\"\n",
    "    )\n",
    "    print(output_filename)\n",
    "    final_mlcw_input.to_csv(output_filename, index=False)\n",
    "    print(f\"Saved data for {current_layer} to {output_filename}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fe8952-d660-40b6-80a2-915770795c08",
   "metadata": {},
   "source": [
    "#### Produce `All_Layer` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea11ce25-11ef-44b4-bbd3-c4e510bc7d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>STATION</th>\n",
       "      <th>X_TWD97</th>\n",
       "      <th>Y_TWD97</th>\n",
       "      <th>Layer_1</th>\n",
       "      <th>Layer_2</th>\n",
       "      <th>Layer_3</th>\n",
       "      <th>Layer_4</th>\n",
       "      <th>All_Layer</th>\n",
       "      <th>CUMDISP</th>\n",
       "      <th>monthly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>ANHE</td>\n",
       "      <td>179539.204623</td>\n",
       "      <td>2.602035e+06</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>-88.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-136.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>BEICHEN</td>\n",
       "      <td>178859.958807</td>\n",
       "      <td>2.608229e+06</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-32.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>CANLIN</td>\n",
       "      <td>173088.151033</td>\n",
       "      <td>2.608157e+06</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-45.0</td>\n",
       "      <td>-56.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-120.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>DONGGUANG</td>\n",
       "      <td>175783.144962</td>\n",
       "      <td>2.616755e+06</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>-77.0</td>\n",
       "      <td>-93.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-196.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>ERLUN</td>\n",
       "      <td>190429.148778</td>\n",
       "      <td>2.629865e+06</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        time    STATION        X_TWD97       Y_TWD97  Layer_1  Layer_2  \\\n",
       "0 2016-04-01       ANHE  179539.204623  2.602035e+06    -33.0    -88.0   \n",
       "1 2016-04-01    BEICHEN  178859.958807  2.608229e+06     -8.0    -32.0   \n",
       "2 2016-04-01     CANLIN  173088.151033  2.608157e+06     -3.0    -45.0   \n",
       "3 2016-04-01  DONGGUANG  175783.144962  2.616755e+06    -23.0    -77.0   \n",
       "4 2016-04-01      ERLUN  190429.148778  2.629865e+06    -19.0    -23.0   \n",
       "\n",
       "   Layer_3  Layer_4  All_Layer  CUMDISP  monthly  \n",
       "0    -13.0     -2.0     -136.0      0.0        0  \n",
       "1    -20.0     -8.0      -68.0      0.0        0  \n",
       "2    -56.0    -16.0     -120.0      0.0        0  \n",
       "3    -93.0     -3.0     -196.0      0.0        0  \n",
       "4    -22.0     -4.0      -68.0      0.0        0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = df.copy()\n",
    "all_layer_arr = df.loc[:, [f\"Layer_{lay_num}\" for lay_num in range(1, 5)]].sum(\n",
    "    axis=1\n",
    ")\n",
    "sub.insert(loc=len(sub.columns) - 2, column=\"All_Layer\", value=all_layer_arr)\n",
    "sub.head(5)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3c2d3c5c-c043-45f8-9522-f2be39d88ba6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "\n",
    "scaler = RobustScaler()\n",
    "\n",
    "sub_byStation = sub.query(\"STATION=='BEICHEN'\")\n",
    "\n",
    "temp = sub_byStation[[\"All_Layer\", \"CUMDISP\"]]\n",
    "temp[\"All_Layer_relative\"] = temp[\"All_Layer\"] - temp[\"All_Layer\"].iloc[0]\n",
    "# temp_scaled = pd.DataFrame(scaler.fit_transform(temp), columns=temp.columns, index=temp.index)\n",
    "\n",
    "\n",
    "temp\n",
    "# temp_scaled.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3e24126-11f4-45fa-b02b-1047cefa7d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skip ANHE\n",
      "Skip TANQIFENXIAO\n",
      "Skip XINPI\n",
      "20250724_GTWR_InputData_MLCW_InSAR_All_Layer.csv\n",
      "Saved data for All_Layer to 20250724_GTWR_InputData_MLCW_InSAR_All_Layer.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty DataFrame to store the processed data for the current layer.\n",
    "final_mlcw_input = pd.DataFrame()\n",
    "\n",
    "# --- Inner Loop: Iterate through each unique station ---\n",
    "for select_station in unique_stations:\n",
    "\n",
    "    # Define the column name for the current layer being processed.\n",
    "    current_layer = f\"All_Layer\"\n",
    "\n",
    "    # Filter the main DataFrame to get the data for only the current station.\n",
    "    df_byStation = sub.query(\"STATION==@select_station\")\n",
    "\n",
    "    # smooth the cumulative displacement with windows = 3\n",
    "    # it means taking 3 points, including the current point (so we have 2 neighbors)\n",
    "    # df_byStation[\"CUMDISP_ma3\"] = smoothing.simple_moving_average(\n",
    "    #     df_byStation[\"CUMDISP\"], window_size=3\n",
    "    # )\n",
    "\n",
    "    # --- Data Quality Checks ---\n",
    "    # Define conditions to identify and skip stations with unreliable data.\n",
    "    # Condition 1: The station has too few data points (less than 67).\n",
    "    cond1 = len(df_byStation) < 67\n",
    "    # Condition 2: All measurements for the current layer are missing (NaN).\n",
    "    cond2 = df_byStation[current_layer].isna().all()\n",
    "    # Condition 3: All measurements for the current layer are zero.\n",
    "    cond3 = df_byStation[current_layer].mean() == 0\n",
    "\n",
    "    # If any of the above conditions are true, skip this station and move to the next.\n",
    "    if cond1 or cond2 or cond3:\n",
    "        print(f\"Skip {select_station}\")\n",
    "        continue\n",
    "\n",
    "    # --- Data Normalization ---\n",
    "    # Identify all columns that contain measurement data.\n",
    "    measurement_cols = [col for col in df.columns if \"Layer\" in col] + [\n",
    "        \"All_Layer\",\n",
    "        \"CUMDISP\",\n",
    "        # \"CUMDISP_ma3\",\n",
    "    ]\n",
    "    # Isolate the two columns we want to normalize for this run.\n",
    "    select_measure_cols = [current_layer, \"CUMDISP\"]  # , \"CUMDISP_ma3\"]\n",
    "\n",
    "    # Separate the station's informational data (like coordinates, time)\n",
    "    # from its measurement data.\n",
    "    info_df_byStation = df_byStation.loc[\n",
    "        :, df_byStation.columns.difference(measurement_cols)\n",
    "    ]\n",
    "    measurement_df_byStation = df_byStation.loc[:, select_measure_cols]\n",
    "\n",
    "    # **CRITICAL STEP: Normalize the measurements.**\n",
    "    # Subtract the first measurement (iloc[0]) from all subsequent measurements.\n",
    "    # This makes the time series start at 0 and represent the change over time.\n",
    "    measurement_df_byStation = measurement_df_byStation.subtract(\n",
    "        measurement_df_byStation.iloc[0, :], axis=1\n",
    "    )\n",
    "\n",
    "    # --- Recombine and Finalize Data for the Station ---\n",
    "    # Concatenate the informational columns and the newly normalized measurement columns.\n",
    "    temp = pd.concat([info_df_byStation, measurement_df_byStation], axis=1)\n",
    "\n",
    "    # Select a fixed window of time steps (from the 2nd to the 67th).\n",
    "    # The first row is skipped because it's now all zeros after normalization.\n",
    "    temp = temp.iloc[1:67, :]\n",
    "\n",
    "    # Append the cleaned, normalized data for this station to the layer's final DataFrame.\n",
    "    final_mlcw_input = pd.concat(\n",
    "        [final_mlcw_input, temp], axis=0, ignore_index=True\n",
    "    )\n",
    "\n",
    "# --- Save the Processed Data for the Layer ---\n",
    "# After processing all stations, save the combined DataFrame to a CSV file.\n",
    "today_string = datetime.today().strftime(\"%Y%m%d\")\n",
    "output_filename = (\n",
    "    f\"{today_string}_GTWR_InputData_MLCW_InSAR_{current_layer}.csv\"\n",
    ")\n",
    "print(output_filename)\n",
    "final_mlcw_input.to_csv(output_filename, index=False)\n",
    "print(f\"Saved data for {current_layer} to {output_filename}\\n\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2387d574-8c43-4c64-82b9-880747a8d260",
   "metadata": {},
   "source": [
    "files = glob(\"2025*Layer_*.csv\")\n",
    "\n",
    "# f = files[0]\n",
    "for f in files:\n",
    "    print(f)\n",
    "    df = pd.read_csv(f)\n",
    "    stations = df[\"STATION\"].unique()\n",
    "\n",
    "    check_len = [\n",
    "        len(df.query(\"STATION==@select_station\")) for select_station in stations\n",
    "    ]\n",
    "    print(len(set(check_len)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d4c12aef-bcf7-4722-b2c2-bdb330b5f67e",
   "metadata": {},
   "source": [
    "df = pd.read_csv(\"20250724_GTWR_InputData_MLCW_InSAR_All_Layer.csv\")\n",
    "stations = df[\"STATION\"].unique()\n",
    "check_len = [\n",
    "    len(df.query(\"STATION==@select_station\")) for select_station in stations\n",
    "]\n",
    "print(len(set(check_len)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8ad664-0e89-4c44-8b3b-6c80dda668b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
