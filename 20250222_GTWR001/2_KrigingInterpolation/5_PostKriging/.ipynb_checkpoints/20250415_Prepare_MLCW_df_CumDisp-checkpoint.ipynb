{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78fdc010-3b5f-4e13-9dfe-1bb862850abf",
   "metadata": {},
   "source": [
    "# MLCW Data Preparation and Compilation Workflow\n",
    "\n",
    "## Scientific Purpose\n",
    "Transform complex multi-layered geospatial displacement measurements into a unified, analysis-ready dataset.\n",
    "\n",
    "## Workflow Overview\n",
    "1. **Data Extraction**\n",
    "   - Load monthly displacement measurements from HDF5 file\n",
    "   - Extract time series for multiple monitoring stations\n",
    "\n",
    "2. **Data Processing Stages**\n",
    "   - Decode time and measurement arrays\n",
    "   - Create multi-layered DataFrame\n",
    "   - Temporal filtering (from 2014 onwards)\n",
    "   - Trim to first and last valid measurements\n",
    "\n",
    "3. **Geospatial Enrichment**\n",
    "   - Append station geographical coordinates (TWD97 system)\n",
    "   - Add station identifiers to each measurement record\n",
    "\n",
    "4. **Data Compilation**\n",
    "   - Concatenate measurements from all stations\n",
    "   - Preserve cumulative displacement time series\n",
    "   - Maintain multi-layer structure\n",
    "\n",
    "5. **Output**\n",
    "   - Save processed data as compressed pickle file\n",
    "   - Retain high-precision floating-point representation\n",
    "\n",
    "## Key Scientific Techniques\n",
    "- Multidimensional time series management\n",
    "- Geospatial data integration\n",
    "- Temporal data cleaning and validation\n",
    "\n",
    "## Computational Strategy\n",
    "- Vectorized pandas operations\n",
    "- Memory-efficient data processing\n",
    "- Systematic station-wise data transformation\n",
    "\n",
    "## Use Case\n",
    "Preparing ground displacement monitoring data for advanced geospatial analysis, focusing on multi-layer cumulative displacement measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25cc956c-e57e-4eb3-9be1-28317d32291c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T14:50:17.288570Z",
     "iopub.status.busy": "2025-04-16T14:50:17.288570Z",
     "iopub.status.idle": "2025-04-16T14:50:21.601098Z",
     "shell.execute_reply": "2025-04-16T14:50:21.600601Z",
     "shell.execute_reply.started": "2025-04-16T14:50:17.288570Z"
    }
   },
   "outputs": [],
   "source": [
    "from my_packages import *\n",
    "from appgeopy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c706244-b842-4189-a547-980b13bf4e91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T14:50:38.156534Z",
     "iopub.status.busy": "2025-04-16T14:50:38.156039Z",
     "iopub.status.idle": "2025-04-16T14:50:38.298390Z",
     "shell.execute_reply": "2025-04-16T14:50:38.297894Z",
     "shell.execute_reply.started": "2025-04-16T14:50:38.156534Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ANHE', 'BEICHEN', 'CANLIN', 'DONGGUANG', 'ERLUN']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlcw_fpath = r\"MLCW_dataset/20250415_MLCW_CRFP_monthly_v2.h5\"\n",
    "mlcw_obj = MLCW(mlcw_fpath)\n",
    "\n",
    "mlcw_measures, mlcw_metadata = mlcw_obj.get_data()\n",
    "\n",
    "available_stations = mlcw_obj.list_stations()\n",
    "available_stations[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c738f00-28b1-41ae-bb55-d07ed91a4ece",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T14:50:39.757376Z",
     "iopub.status.busy": "2025-04-16T14:50:39.757376Z",
     "iopub.status.idle": "2025-04-16T14:50:39.975965Z",
     "shell.execute_reply": "2025-04-16T14:50:39.975469Z",
     "shell.execute_reply.started": "2025-04-16T14:50:39.757376Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'MLCW_station_info.xz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m station_info \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMLCW_station_info.xz\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Programs\\miniconda3\\Library\\envs\\fafalab\\Lib\\site-packages\\pandas\\io\\pickle.py:185\u001b[0m, in \u001b[0;36mread_pickle\u001b[1;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;124;03mLoad pickled pandas object (or any object) from file.\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;124;03m4    4    9\u001b[39;00m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    184\u001b[0m excs_to_catch \u001b[38;5;241m=\u001b[39m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m)\n\u001b[1;32m--> 185\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;66;03m# 1) try standard library Pickle\u001b[39;00m\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;66;03m# 2) try pickle_compat (older pandas version) to handle subclass changes\u001b[39;00m\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;66;03m# 3) try pickle_compat with latin-1 encoding upon a UnicodeDecodeError\u001b[39;00m\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    197\u001b[0m         \u001b[38;5;66;03m# TypeError for Cython complaints about object.__new__ vs Tick.__new__\u001b[39;00m\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\Programs\\miniconda3\\Library\\envs\\fafalab\\Lib\\site-packages\\pandas\\io\\common.py:843\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    838\u001b[0m \u001b[38;5;66;03m# XZ Compression\u001b[39;00m\n\u001b[0;32m    839\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m compression \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxz\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    840\u001b[0m     \u001b[38;5;66;03m# error: Argument 1 to \"LZMAFile\" has incompatible type \"Union[str,\u001b[39;00m\n\u001b[0;32m    841\u001b[0m     \u001b[38;5;66;03m# BaseBuffer]\"; expected \"Optional[Union[Union[str, bytes, PathLike[str],\u001b[39;00m\n\u001b[0;32m    842\u001b[0m     \u001b[38;5;66;03m# PathLike[bytes]], IO[bytes]], None]\"\u001b[39;00m\n\u001b[1;32m--> 843\u001b[0m     handle \u001b[38;5;241m=\u001b[39m \u001b[43mget_lzma_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcompression_args\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m    845\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[38;5;66;03m# Zstd Compression\u001b[39;00m\n\u001b[0;32m    848\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m compression \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mD:\\Programs\\miniconda3\\Library\\envs\\fafalab\\Lib\\lzma.py:120\u001b[0m, in \u001b[0;36mLZMAFile.__init__\u001b[1;34m(self, filename, mode, format, check, preset, filters)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m    119\u001b[0m     mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 120\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_closefp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m mode_code\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'MLCW_station_info.xz'"
     ]
    }
   ],
   "source": [
    "station_info = pd.read_pickle(r\"MLCW_dataset/MLCW_station_info.xz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e344d958-3f92-438e-906b-ebdb796f5095",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-16T14:50:22.438249Z",
     "iopub.status.idle": "2025-04-16T14:50:22.439240Z",
     "shell.execute_reply": "2025-04-16T14:50:22.438744Z",
     "shell.execute_reply.started": "2025-04-16T14:50:22.438744Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_df = pd.DataFrame(data=None, index=None, dtype=np.float32)\n",
    "\n",
    "# select_station = available_stations[0]\n",
    "\n",
    "number_of_layers = []\n",
    "for select_station in tqdm(available_stations[:]):\n",
    "    \n",
    "    string_decoder = lambda arr: [x.decode(\"utf-8\") for x in arr]\n",
    "    \n",
    "    measures_byStation = mlcw_measures[select_station]\n",
    "    monthly_date_arr = pd.to_datetime(string_decoder(measures_byStation[\"monthly_date\"]))\n",
    "    monthly_values_arr = measures_byStation[\"monthly_values\"][\"compactbylayer_PCA\"]\n",
    "    \n",
    "    cdisp_mlcw_df = pd.DataFrame(data={\"time\":monthly_date_arr})\n",
    "    \n",
    "    n_layers = monthly_values_arr.shape[0]\n",
    "    number_of_layers.append(n_layers)\n",
    "    \n",
    "    for i in range(n_layers):\n",
    "        cdisp_mlcw_df[f\"Layer_{i+1}\"] = monthly_values_arr[i]\n",
    "\n",
    "    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
    "    # 2025/4/15 : decide to keep working with cumulative displacement\n",
    "    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "    cdisp_mlcw_df = cdisp_mlcw_df.set_index(\"time\")\n",
    "    # cdisp_mlcw_df = cdisp_mlcw_df.interpolate(method=\"time\")\n",
    "    \n",
    "    cdisp_mlcw_df = cdisp_mlcw_df.loc[\"2014\":, :]\n",
    "\n",
    "    first_datetime = cdisp_mlcw_df.first_valid_index()\n",
    "    last_datetime = cdisp_mlcw_df.last_valid_index()\n",
    "\n",
    "    cdisp_mlcw_df = cdisp_mlcw_df.loc[first_datetime:last_datetime, :]\n",
    "\n",
    "    y_twd97 = station_info.loc[select_station].Y_TWD97\n",
    "    x_twd97 = station_info.loc[select_station].X_TWD97\n",
    "    \n",
    "    cdisp_mlcw_df.insert(loc=0, column=\"Y_TWD97\", value=[y_twd97]*len(cdisp_mlcw_df))\n",
    "    cdisp_mlcw_df.insert(loc=0, column=\"X_TWD97\", value=[x_twd97]*len(cdisp_mlcw_df))\n",
    "    cdisp_mlcw_df.insert(loc=0, column=\"STATION\", value=[select_station]*len(cdisp_mlcw_df))\n",
    "    \n",
    "    \n",
    "    combined_df = pd.concat([combined_df, cdisp_mlcw_df], axis=0)\n",
    "    # - - - - - - - - - - - - - - - - - - - - - - - - - \n",
    "    # 2025/4/8 : convert to displacement time series\n",
    "    # - - - - - - - - - - - - - - - - - - - - - - - - - \n",
    "    # disp_mlcw_df = cdisp_mlcw_df.diff(axis=0)\n",
    "    # disp_mlcw_df = disp_mlcw_df.loc[\"2014\":, :]\n",
    "    \n",
    "    # first_datetime = disp_mlcw_df.first_valid_index()\n",
    "    # last_datetime = disp_mlcw_df.last_valid_index()\n",
    "    \n",
    "    # disp_mlcw_df = disp_mlcw_df.loc[first_datetime:last_datetime, :]\n",
    "    # disp_mlcw_df.insert(loc=0, column=\"STATION\", value=[select_station]*len(disp_mlcw_df))\n",
    "    \n",
    "    # combined_df = pd.concat([combined_df, disp_mlcw_df], axis=0)\n",
    "\n",
    "combined_df.to_pickle(r\"Monthly_MLCW_pca_CUMDISP_v2.xz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf643734-8b89-44c2-bf4f-a6a50cdd8426",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "09c4c2de-6d3f-4acb-9c41-1d2f30ca7f7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T14:18:38.714296Z",
     "iopub.status.busy": "2025-04-15T14:18:38.713299Z",
     "iopub.status.idle": "2025-04-15T14:18:39.088643Z",
     "shell.execute_reply": "2025-04-15T14:18:39.088643Z",
     "shell.execute_reply.started": "2025-04-15T14:18:38.714296Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "n_lay = 1\n",
    "\n",
    "for n_lay in range(1, 5):\n",
    "    \n",
    "    gwl_df = pd.read_pickle(r\"gwl_L1.xz\")\n",
    "    info_df = gwl_df.iloc[:, [0, 1,2]].copy()\n",
    "    \n",
    "    sub_df = combined_df[[\"STATION\", f\"Layer_{n_lay}\"]]\n",
    "    \n",
    "    output_df = pd.DataFrame(data={\"time\":pd.date_range(start=datetime(2000, 1, 1), end=datetime(2024, 1, 1))})\n",
    "    output_df = output_df.set_index(\"time\")\n",
    "    \n",
    "    for station in available_stations:\n",
    "        temp = sub_df.query(\"STATION==@station\")\n",
    "        output_df[station] = output_df.index.map(temp[f\"Layer_{n_lay}\"])\n",
    "    \n",
    "    first_valid_idx = output_df.first_valid_index()\n",
    "    last_valid_idx = output_df.last_valid_index()\n",
    "    \n",
    "    output_df = output_df.loc[first_valid_idx:last_valid_idx, ].dropna(how='all')\n",
    "    output_df = output_df.loc[\"2014\":\"2021\", :].T\n",
    "    output_df.columns = [\"N\"+col.strftime(\"%Y%m%d\") for col in output_df.columns]\n",
    "    output_df[np.abs(output_df)<0.1] = 1e-3\n",
    "    \n",
    "    for col in output_df:\n",
    "        info_df[col] = info_df.index.map(output_df[col])\n",
    "    \n",
    "    # info_df.to_pickle(f\"Monthly_MLCW_CRFP_L{n_lay}.xz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c747759-6933-41bd-b391-205a5ea60ee0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
