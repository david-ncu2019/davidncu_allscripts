{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12768a29-bd02-47e6-8708-7b9497e034ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from scipy.optimize import curve_fit\n",
    "from skgstat.models import exponential\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14dbfa0-bbee-474b-84af-642130f5f0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 1. CONFIGURATION\n",
    "# =============================================================================\n",
    "class Config:\n",
    "    \"\"\"A centralized class for all user-configurable parameters.\"\"\"\n",
    "    \n",
    "    # --- Input File Paths ---\n",
    "    SHAPEFILE_PATH = Path(r\"D:\\1000_SCRIPTS\\003_Project002\\20250222_GTWR001\\2_KrigingInterpolation\\points_fld\\mlcw_twd97.shp\")\n",
    "    MODEL_FOLDER = Path(r\"D:\\1000_SCRIPTS\\003_Project002\\20250222_GTWR001\\5_GTWR_Prediction\")\n",
    "    \n",
    "    # --- Output Folder ---\n",
    "    OUTPUT_FOLDER = Path(r\"Curve_Fitting_Results\")\n",
    "    \n",
    "    # --- Analysis Settings ---\n",
    "    KERNEL_NAME: str = \"bisquare\"\n",
    "    START_DATE = pd.Timestamp(year=2016, month=5, day=1)\n",
    "    \n",
    "    # --- Plotting Style ---\n",
    "    plt.style.use(\"seaborn-v0_8-talk\")\n",
    "    plt.rcParams[\"figure.figsize\"] = (12, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73853724-78e3-4ab3-8679-58d9ce6872d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 2. HELPER FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def load_and_prepare_data(file_path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Loads CSV data, creates a 'PointKey', and sets it as the index.\"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    pointkey_arr = [f\"X{int(x*1000)}Y{int(y*1000)}\" for x, y in zip(df[\"X_TWD97\"], df[\"Y_TWD97\"])]\n",
    "    df.insert(loc=0, column=\"PointKey\", value=pointkey_arr)\n",
    "    df.set_index(\"PointKey\", inplace=True)\n",
    "    return df\n",
    "\n",
    "def get_time_series_for_point(df: pd.DataFrame, point_key: str, start_date: pd.Timestamp) -> Tuple[pd.Series, np.ndarray]:\n",
    "    \"\"\"Extracts and prepares the time series and cumulative days for a single point.\"\"\"\n",
    "    df_point = df.loc[point_key].copy()\n",
    "    time_arr = [start_date + relativedelta(months=int(t)) for t in df_point[\"time_stamp\"]]\n",
    "    df_point[\"datetime\"] = time_arr\n",
    "    df_point = df_point.set_index(\"datetime\").sort_index()\n",
    "    coefficient_series = df_point[\"CUMDISP\"].asfreq(\"MS\")\n",
    "    time_days = pd.Series(coefficient_series.index).diff().apply(lambda x: x.days).fillna(0).cumsum().values\n",
    "    return coefficient_series, time_days\n",
    "\n",
    "def fit_exponential_model(series: pd.Series, time_days: np.ndarray) -> Tuple[np.ndarray, pd.Series]:\n",
    "    \"\"\"Fits an exponential model using the original, correct logic.\"\"\"\n",
    "    valid_mask = ~np.isnan(series)\n",
    "    y_data = series[valid_mask]\n",
    "    x_data = time_days[valid_mask]\n",
    "\n",
    "    if len(y_data) < 3:\n",
    "        raise ValueError(\"Not enough valid data points to fit model.\")\n",
    "\n",
    "    parameter_bounds = (\n",
    "        [np.min(x_data), np.min(y_data), np.min(y_data)],\n",
    "        [np.max(x_data), np.max(y_data), np.max(y_data)],\n",
    "    )\n",
    "    initial_guess = [np.median(x_data), np.median(y_data), y_data.iloc[0]]\n",
    "\n",
    "    params, _ = curve_fit(exponential, x_data, y_data, p0=initial_guess, bounds=parameter_bounds)\n",
    "    predictions = pd.Series(data=exponential(time_days, *params), index=series.index)\n",
    "    return params, predictions\n",
    "\n",
    "def plot_and_save_figure(original_series: pd.Series, predicted_series: pd.Series, title: str, params: np.ndarray, output_path: Path):\n",
    "    \"\"\"\n",
    "    Generates a plot with a parameter panel, saves it to a file, and closes it.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots() # Use subplots to get access to the axes object\n",
    "    \n",
    "    original_series.plot(ax=ax, marker='o', linestyle='-', label='Original Data', markerfacecolor='none', color='gray', alpha=0.8)\n",
    "    predicted_series.plot(ax=ax, label='Fitted Exponential Model', color='red', linestyle='--')\n",
    "    \n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    ax.set_ylabel(\"Cumulative Displacement (CUMDISP)\")\n",
    "    ax.legend(loc='lower right') # Move legend to not overlap with text box\n",
    "    ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "    \n",
    "    # --- ENHANCEMENT: Create and add the parameter panel ---\n",
    "    # 1. Format the parameter values into a readable string.\n",
    "    r, c0, b = params\n",
    "    param_text = (\n",
    "        f\"Model Parameters\\n\"\n",
    "        f\"------------------\\n\"\n",
    "        f\"Range: {r:.2f}\\n\"\n",
    "        f\"Sill: {c0:.4f}\\n\"\n",
    "        f\"Nugget: {b:.4f}\"\n",
    "    )\n",
    "    \n",
    "    # 2. Define the appearance of the text box (the \"panel\").\n",
    "    props = dict(boxstyle='round,pad=0.5', facecolor='white', alpha=0.8)\n",
    "    \n",
    "    # 3. Place the text box in the top-left corner of the plot.\n",
    "    # transform=ax.transAxes uses relative coordinates (0,0 is bottom-left, 1,1 is top-right).\n",
    "    ax.text(0.03, 0.97, param_text, transform=ax.transAxes, fontsize=10,\n",
    "            verticalalignment='top', bbox=props, fontfamily='monospace')\n",
    "    # ---------------------------------------------------------\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    \n",
    "    # Save the figure to the specified path with high resolution\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    # Close the plot to free up memory\n",
    "    plt.close(fig)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffbd8df-ca59-4a1b-9a03-af4987181aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 3. MAIN BATCH PROCESSING WORKFLOW\n",
    "# =============================================================================\n",
    "def main():\n",
    "    \"\"\"Main function to run the batch processing workflow.\"\"\"\n",
    "    print(\"--- Starting Batch Analysis ---\")\n",
    "\n",
    "    Config.OUTPUT_FOLDER.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"Output figures will be saved to: {Config.OUTPUT_FOLDER}\")\n",
    "\n",
    "    output_files = sorted(list(Config.MODEL_FOLDER.glob(f\"*{Config.KERNEL_NAME}*.csv\")))\n",
    "    if not output_files:\n",
    "        raise FileNotFoundError(f\"No files with kernel '{Config.KERNEL_NAME}' found in {Config.MODEL_FOLDER}\")\n",
    "    \n",
    "    selected_file = output_files[0]\n",
    "    df_processed = load_and_prepare_data(selected_file)\n",
    "    mlcw_gdf = gpd.read_file(Config.SHAPEFILE_PATH)\n",
    "    \n",
    "    unique_point_keys = sorted(df_processed.index.unique())\n",
    "    total_points = len(unique_point_keys)\n",
    "    print(f\"Found {total_points} unique points to process.\\n\")\n",
    "\n",
    "    for i, point_key in enumerate(unique_point_keys):\n",
    "        station_name = \"Unknown\" # Default name in case of error\n",
    "        try:\n",
    "            station_name = mlcw_gdf.query(\"PointKey == @point_key\").STATION.values[0]\n",
    "            print(f\"[{i+1}/{total_points}] Processing Station: {station_name} ({point_key})\")\n",
    "            \n",
    "            coefficient_series, time_days = get_time_series_for_point(df_processed, point_key, Config.START_DATE)\n",
    "            \n",
    "            fitted_params, predicted_values = fit_exponential_model(coefficient_series, time_days)\n",
    "            \n",
    "            plot_title = f\"Exponential Model Fit for Station: {station_name}\"\n",
    "            safe_station_name = \"\".join(c for c in station_name if c.isalnum() or c in (' ', '_')).rstrip()\n",
    "            output_filename = f\"{safe_station_name}_{point_key}.png\"\n",
    "            output_path = Config.OUTPUT_FOLDER / output_filename\n",
    "            \n",
    "            # ** Pass the fitted_params to the plotting function **\n",
    "            plot_and_save_figure(coefficient_series, predicted_values, plot_title, fitted_params, output_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  -> FAILED for station {station_name} ({point_key}). Reason: {e}\")\n",
    "            continue\n",
    "\n",
    "    print(\"\\n--- Batch Analysis Complete ---\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
