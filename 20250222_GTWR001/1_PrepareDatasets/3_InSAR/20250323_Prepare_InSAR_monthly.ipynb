{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336b5349-4bf7-4801-a1f7-530786a72f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from appgeopy import *\n",
    "from my_packages import *"
   ]
  },
  {
   "cell_type": "raw",
   "id": "10916f9d-64ab-4316-8f8f-b9a93fd8eed6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T14:15:10.094714Z",
     "iopub.status.busy": "2025-03-23T14:15:10.094714Z",
     "iopub.status.idle": "2025-03-23T14:15:40.485121Z",
     "shell.execute_reply": "2025-03-23T14:15:40.484626Z",
     "shell.execute_reply.started": "2025-03-23T14:15:10.094714Z"
    }
   },
   "source": [
    "# 2025/3/23 : After 2 days struggling, ChatGPT do help me resolve the issues\n",
    "# code for select overlapped point\n",
    "import geopandas as gpd\n",
    "\n",
    "# Filter points within the subsidence_bbox\n",
    "# points_a = asc_timeseries_full[asc_timeseries_full.geometry.within(subsidence_bbox)]\n",
    "# points_b = desc_timeseries_full[desc_timeseries_full.geometry.within(subsidence_bbox)]\n",
    "\n",
    "points_a = asc_timeseries_full.copy()\n",
    "points_b = desc_timeseries_full.copy()\n",
    "\n",
    "points_a = points_a.to_crs(\"EPSG:3826\")\n",
    "points_b = points_b.to_crs(\"EPSG:3826\")\n",
    "\n",
    "# Ensure both GeoDataFrames use the same CRS\n",
    "if points_a.crs != points_b.crs:\n",
    "    points_b = points_b.to_crs(points_a.crs)\n",
    "\n",
    "# Define the matching tolerance (in the same CRS units)\n",
    "tolerance = 1  # Adjust as needed\n",
    "\n",
    "# Perform a nearest neighbor spatial join with a maximum distance tolerance.\n",
    "# This returns all points in A that have a point in B within the specified tolerance.\n",
    "a_matches_b = gpd.sjoin_nearest(points_a, points_b, max_distance=tolerance, how=\"inner\", distance_col=\"dist\")\n",
    "\n",
    "# Optionally, get unique points from A that had a match\n",
    "a_match = points_a.loc[a_matches_b.index.unique()]\n",
    "\n",
    "\n",
    "b_matches_a = gpd.sjoin_nearest(points_b, points_a, max_distance=tolerance, how=\"inner\", distance_col=\"dist\")\n",
    "\n",
    "b_match = points_b.loc[b_matches_a.index.unique()]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5b9346b5-936b-4359-83dd-b919d9ec30ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T14:28:02.888494Z",
     "iopub.status.busy": "2025-03-23T14:28:02.887998Z",
     "iopub.status.idle": "2025-03-23T14:28:02.891471Z",
     "shell.execute_reply": "2025-03-23T14:28:02.891471Z",
     "shell.execute_reply.started": "2025-03-23T14:28:02.888494Z"
    }
   },
   "source": [
    "# 2025/3/23\n",
    "# add PointKey to each data frame\n",
    "# easy to match the point for LOS conversion (to vertical and horizontal)\n",
    "\n",
    "def get_pointkey(coordinates):\n",
    "    long = coordinates.x\n",
    "    lat = coordinates.y\n",
    "    int_long = int(long)\n",
    "    int_lat = int(lat)\n",
    "    int_long_str = str(int_long)\n",
    "    int_lat_str = str(int_lat)\n",
    "    return f\"X{int_long_str}Y{int_lat_str}\"\n",
    "\n",
    "asc_timeseries_full.insert(loc=1, column=\"PointKey\", value=asc_timeseries_full.geometry.apply(get_pointkey))\n",
    "desc_timeseries_full.insert(loc=1, column=\"PointKey\", value=desc_timeseries_full.geometry.apply(get_pointkey))\n",
    "\n",
    "asc_timeseries_full.sort_values(by=\"PointKey\").reset_index(drop=True).to_pickle(r\"ASC_overlap_desc_+pointkey_TWD97.pkl\", compression='zip')\n",
    "desc_timeseries_full.sort_values(by=\"PointKey\").reset_index(drop=True).to_pickle(r\"DESC_overlap_asc_+pointkey_TWD97.pkl\", compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e642506d-b64b-4a63-94c9-8796aba6faf0",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2824709791.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    **2025/3/24**\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# **2025/3/24**\n",
    "\n",
    "Prepare monthly data, ready for LOS decomposition\n",
    "\n",
    "# ```{python}\n",
    "\"\"\"\n",
    "General Description:\n",
    "This snippet reads a pickled time-series dataset, filters displacement columns,\n",
    "resamples them to monthly intervals, and re-combines the results with ancillary\n",
    "information and geometry data.\n",
    "\"\"\"\n",
    "\n",
    "# Specify the path to the pickled DataFrame\n",
    "pickle_fpath = r\"DESC_overlap_asc_+pointkey_TWD97.pkl\"\n",
    "\n",
    "# Load the DataFrame with zip compression\n",
    "timeseries_full = pd.read_pickle(pickle_fpath, compression=\"zip\")\n",
    "\n",
    "# Collect displacement columns (those that start with 'D')\n",
    "cumdisp_columns = [col for col in timeseries_full.columns if col.startswith(\"D\")]\n",
    "# Extract only displacement columns\n",
    "cumdisp_timeseries = timeseries_full.loc[:, cumdisp_columns]\n",
    "# Convert displacement columns to DateTime objects (removing the \"D\" prefix)\n",
    "cumdisp_timeseries.columns = [pd.to_datetime(col[1:]) for col in cumdisp_timeseries.columns]\n",
    "# Resample displacement data monthly and compute mean\n",
    "monthly_resampled_cumdisp_timeseries = cumdisp_timeseries.resample(\"MS\", axis=1).mean()\n",
    "# Rename columns with \"D\" prefix and YYYYMMDD format\n",
    "monthly_resampled_cumdisp_timeseries.columns = [\n",
    "    \"D\" + col.strftime(\"%Y%m%d\") for col in monthly_resampled_cumdisp_timeseries.columns\n",
    "]\n",
    "\n",
    "# Separate non-displacement columns\n",
    "info_df = timeseries_full.loc[:, [col for col in timeseries_full.columns if not col.startswith(\"D\")]]\n",
    "\n",
    "# Concatenate info (excluding the last column), resampled displacements, and geometry\n",
    "final_timeseries_full = pd.concat(\n",
    "    [\n",
    "        info_df.iloc[:, :-1],\n",
    "        monthly_resampled_cumdisp_timeseries,\n",
    "        info_df.loc[:, [\"geometry\"]],\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "# Display the final DataFrame\n",
    "# final_timeseries_full.to_pickle(\"MonthlyResample\"+pickle_fpath, compression='zip')\n",
    "# ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d33707b-da61-47f0-a16f-d9604f70b70f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T04:00:04.352153Z",
     "iopub.status.busy": "2025-03-24T04:00:04.351656Z",
     "iopub.status.idle": "2025-03-24T04:00:59.664197Z",
     "shell.execute_reply": "2025-03-24T04:00:59.664197Z",
     "shell.execute_reply.started": "2025-03-24T04:00:04.352153Z"
    }
   },
   "source": [
    "**2025/3/24**\n",
    "\n",
    "Extract the incidence and azimuth angles for ASC and DESC, respectively\n",
    "\n",
    "```{python}\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio.transform import rowcol\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Load point shapefile\n",
    "point_fpath = r\"D:\\1000_SCRIPTS\\003_Project002\\20250222_GTWR001\\1_PrepareDatasets\\3_InSAR\\asc_run003L\\output_shp\\ASC_overlap_desc_+pointkey_TWD97.shp\"\n",
    "direction = os.path.basename(point_fpath).split(\"_\")[0]\n",
    "\n",
    "raster_filelist = [\n",
    "    r\"D:\\1000_SCRIPTS\\003_Project002\\20250222_GTWR001\\1_PrepareDatasets\\3_InSAR\\asc_run003L\\raster_output\\asc_inc_twd97.tif\",\n",
    "    r\"D:\\1000_SCRIPTS\\003_Project002\\20250222_GTWR001\\1_PrepareDatasets\\3_InSAR\\asc_run003L\\raster_output\\asc_azim_twd97.tif\"\n",
    "]\n",
    "\n",
    "# Load point shapefile\n",
    "points = gpd.read_file(point_fpath)\n",
    "\n",
    "for raster_fpath in raster_filelist:\n",
    "    raster_base = os.path.basename(raster_fpath)\n",
    "\n",
    "    if \"inc\" in raster_base:\n",
    "        colname = f\"{direction}_INC\"\n",
    "    elif \"azim\" in raster_base:\n",
    "        colname = f\"{direction}_AZIM\"\n",
    "    else:\n",
    "        raise ValueError(\"No specific keyword in raster filename\")\n",
    "\n",
    "    # Read the raster into memory\n",
    "    with rasterio.open(raster_fpath) as src:\n",
    "        raster_array = src.read(1)\n",
    "        transform = src.transform\n",
    "\n",
    "    def get_raster_value(geom):\n",
    "        try:\n",
    "            row, col = rowcol(transform, geom.x, geom.y)\n",
    "            if 0 <= row < raster_array.shape[0] and 0 <= col < raster_array.shape[1]:\n",
    "                return raster_array[row, col]\n",
    "        except:\n",
    "            pass\n",
    "        return np.nan\n",
    "\n",
    "    # Parallel extraction using joblib\n",
    "    raster_vals = Parallel(n_jobs=-1)(delayed(get_raster_value)(geom) for geom in points.geometry)\n",
    "\n",
    "    # Assign results\n",
    "    points[colname] = raster_vals\n",
    "\n",
    "end = time.time()\n",
    "elapsed_time_seconds = round((end - start), 2)\n",
    "elapsed_time_minutes = round((elapsed_time_seconds / 60), 2)\n",
    "\n",
    "print(\"\\n\\n\" + \"-\" * 50)\n",
    "print(\"Processing time (seconds): {}\".format(elapsed_time_seconds))\n",
    "print(\"Processing time (minutes): {}\".format(elapsed_time_minutes))\n",
    "```"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3c0de7ca-fdbf-4527-9c2d-47ea25bbc90c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T03:24:11.044407Z",
     "iopub.status.busy": "2025-03-24T03:24:11.044407Z",
     "iopub.status.idle": "2025-03-24T03:24:27.365906Z",
     "shell.execute_reply": "2025-03-24T03:24:27.365410Z",
     "shell.execute_reply.started": "2025-03-24T03:24:11.044407Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "fig = plt.figure(figsize=(18,6))\n",
    "ax1 = fig.add_subplot(311)\n",
    "ax2 = fig.add_subplot(312)\n",
    "ax3 = fig.add_subplot(313)\n",
    "\n",
    "sub_disp_timeseries = disp_timeseries.loc[:, :\"2018\"]\n",
    "\n",
    "random_indexes = np.random.choice(a=sub_disp_timeseries.index, size=200, replace=False)\n",
    "\n",
    "alpha_val = 0.01\n",
    "\n",
    "for i in tqdm(random_indexes):\n",
    "    select_disp_array = sub_disp_timeseries.iloc[i, :]\n",
    "    select_disp_array.plot(marker='o', linestyle='--', ax=ax1, color='lightgrey', alpha=alpha_val)\n",
    "    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
    "    monthly_resample = select_disp_array.resample(\"M\").mean()\n",
    "    monthly_resample.plot(marker='s', linestyle='--', ax=ax1, color='red', alpha=alpha_val)\n",
    "    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
    "    select_disp_array.cumsum().plot(marker='o', linestyle='--', ax=ax2, color='lightgrey', alpha=alpha_val)\n",
    "    select_disp_array.cumsum().resample(\"M\").mean().plot(marker='^', linestyle='--', ax=ax2, color='blue', alpha=alpha_val)\n",
    "    monthly_resample.cumsum().plot(marker='s', linestyle='--', ax=ax2, color='red', alpha=alpha_val)\n",
    "    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
    "    \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876135ba-5654-4b6b-a73f-374fee92bbef",
   "metadata": {},
   "source": [
    "**2025/3/25**\n",
    "\n",
    "Combine incidence and azimuth angles from ascending & descending into one file\n",
    "\n",
    "```{python}\n",
    "asc_inc_azim = pd.read_pickle(\"ASC_inc_azim.pkl\", compression='zip')\n",
    "desc_inc_azim = pd.read_pickle(\"DESC_inc_azim.pkl\", compression='zip')\n",
    "\n",
    "asc_inc_azim = asc_inc_azim.sort_values(by=\"PointKey\").reset_index(drop=True)\n",
    "desc_inc_azim = desc_inc_azim.sort_values(by=\"PointKey\").reset_index(drop=True)\n",
    "\n",
    "combined = asc_inc_azim.copy()\n",
    "combined.set_index(\"PointKey\", inplace=True)\n",
    "desc_inc_azim.set_index(\"PointKey\",inplace=True)\n",
    "\n",
    "for col in [\"DESC_INC\", \"DESC_AZIM\"]:\n",
    "    combined[col] = combined.index.map(desc_inc_azim[col])\n",
    "\n",
    "columns = combined.columns\n",
    "new_cols = [columns[0]] + list(columns[1:][::-1])\n",
    "combined = combined[new_cols]\n",
    "\n",
    "combined.to_pickle(r\"ASC_DESC_inc_azim.xz\")\n",
    "```"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d8253491-6ea0-4f6d-be5c-16725b382707",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T08:24:23.916266Z",
     "iopub.status.busy": "2025-06-12T08:24:23.916266Z",
     "iopub.status.idle": "2025-06-12T08:24:36.607429Z",
     "shell.execute_reply": "2025-06-12T08:24:36.607429Z",
     "shell.execute_reply.started": "2025-06-12T08:24:23.916266Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "asc_fpath = r\"asc_run003L/asc_timeseries_demErr_tropHgt_ERA5_SET.pkl\"\n",
    "asc_df = pd.read_pickle(asc_fpath, compression='zip')\n",
    "asc_total_scenes = sum([[ele for ele in asc_df.columns.tolist() if ele.startswith(f\"D{year}\")] for year in range(2016, 2022)], [])\n",
    "asc_total_scenes[:5], asc_total_scenes[-10:], len(asc_total_scenes)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "415958a2-d81a-415a-9a57-f59839dd49fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T08:24:39.041799Z",
     "iopub.status.busy": "2025-06-12T08:24:39.041799Z",
     "iopub.status.idle": "2025-06-12T08:24:58.866930Z",
     "shell.execute_reply": "2025-06-12T08:24:58.866930Z",
     "shell.execute_reply.started": "2025-06-12T08:24:39.041799Z"
    }
   },
   "source": [
    "desc_fpath = r\"desc_run003L/desc_timeseries_demErr_tropHgt_ERA5_SET.pkl\"\n",
    "desc_df = pd.read_pickle(desc_fpath, compression='zip')\n",
    "desc_total_scenes = sum([[ele for ele in desc_df.columns.tolist() if ele.startswith(f\"D{year}\")] for year in range(2016, 2022)], [])\n",
    "desc_total_scenes[:5], desc_total_scenes[-10:], len(desc_total_scenes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2ec541-b081-4164-9c25-4c32be89ab28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
