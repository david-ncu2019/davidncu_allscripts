{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a80fc3c1-2220-46c9-a7f5-dda0367928cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T14:50:54.667757Z",
     "iopub.status.busy": "2025-03-08T14:50:54.667262Z",
     "iopub.status.idle": "2025-03-08T14:50:57.404683Z",
     "shell.execute_reply": "2025-03-08T14:50:57.404187Z",
     "shell.execute_reply.started": "2025-03-08T14:50:54.667757Z"
    }
   },
   "outputs": [],
   "source": [
    "from appgeopy import *\n",
    "from my_packages import *\n",
    "from tools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5967e6ee-87ec-4cc8-9e26-db96c5344b91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T14:50:57.405675Z",
     "iopub.status.busy": "2025-03-08T14:50:57.405179Z",
     "iopub.status.idle": "2025-03-08T14:50:57.412123Z",
     "shell.execute_reply": "2025-03-08T14:50:57.412123Z",
     "shell.execute_reply.started": "2025-03-08T14:50:57.405675Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_seasonal_and_trend_data(series):\n",
    "    \"\"\"\n",
    "    Extract trend and seasonal components from time series data.\n",
    "\n",
    "    This function performs time series decomposition by:\n",
    "    1. Creating a complete timeline (filling gaps)\n",
    "    2. Extracting the long-term trend\n",
    "    3. Removing trend to identify repeating cycles\n",
    "    4. Filtering meaningful seasonal patterns\n",
    "\n",
    "    Args:\n",
    "        series: Input time series with datetime index (possibly with gaps)\n",
    "\n",
    "    Returns:\n",
    "        trend: Long-term linear trend component\n",
    "        detrended_series: Series with trend removed\n",
    "        seasonality_info: DataFrame with identified seasonal patterns\n",
    "    \"\"\"\n",
    "    # Generate continuous timeline covering the entire data period\n",
    "    # (Creates dates for every day even if original data has gaps)\n",
    "    fulltime_arr = datetime_handle.get_fulltime(series.index)\n",
    "\n",
    "    # Fill gaps in original data to create complete time series\n",
    "    # (This helps identify patterns that might be obscured by missing values)\n",
    "    complete_series = datetime_handle.fulltime_table(series, fulltime_arr)\n",
    "\n",
    "    # Calculate linear trend component (general upward/downward movement)\n",
    "    # First returned value is trend, second (ignored) is coefficients\n",
    "    trend, _ = analysis.get_linear_trend(complete_series)\n",
    "    trend.index = complete_series.index  # Ensure trend has same timeline as data\n",
    "\n",
    "    # Remove trend from data to isolate cyclical components\n",
    "    # (Subtract trend line from data to see repeating patterns more clearly)\n",
    "    detrended_series = complete_series - trend\n",
    "\n",
    "    # Identify repeating cycles in the detrended data\n",
    "    # (Uses Fourier analysis to find frequencies, periods, and amplitudes)\n",
    "    seasonality_info = analysis.find_seasonality(time_series_data=detrended_series)\n",
    "\n",
    "    # Filter out noise and keep only meaningful seasonal patterns:\n",
    "    # 1. Keep cycles longer than weekly (> 7 days)\n",
    "    # 2. Remove infinite periods (non-cycles)\n",
    "    # 3. Remove zero-frequency components (constants)\n",
    "    seasonality_info = seasonality_info[\n",
    "        (seasonality_info[\"Period (days)\"] > 7)\n",
    "        & (seasonality_info[\"Period (days)\"] != np.inf)\n",
    "        & (seasonality_info[\"Frequency\"] != 0)\n",
    "    ]\n",
    "\n",
    "    # Round values for cleaner results\n",
    "    seasonality_info[\"Amplitude\"] = seasonality_info[\"Amplitude\"].round(2)  # Size of cycle\n",
    "    seasonality_info[\"Period (days)\"] = seasonality_info[\"Period (days)\"].round(0)  # Length of cycle\n",
    "    seasonality_info[\"Phase\"] = seasonality_info[\"Phase\"].round(2)  # Starting position of cycle\n",
    "\n",
    "    # Keep only the 50 strongest seasonal patterns (by amplitude)\n",
    "    seasonality_info = seasonality_info.nlargest(n=50, columns=\"Amplitude\")\n",
    "\n",
    "    return trend, detrended_series, seasonality_info\n",
    "\n",
    "\n",
    "def model_timeseries(timeseries):\n",
    "    \"\"\"\n",
    "    Create a mathematical model of a time series by decomposing it into trend and seasonal components.\n",
    "\n",
    "    This function takes raw time series data, separates trend from cycles,\n",
    "    applies sinusoidal modeling, and performs phase correction to create\n",
    "    an accurate mathematical representation of the data.\n",
    "    \"\"\"\n",
    "    # Decompose time series into trend, detrended data, and seasonality information\n",
    "    trend, detrend, seasonality_info = get_seasonal_and_trend_data(timeseries)\n",
    "\n",
    "    # Extract parameters needed for sinusoidal modeling from detrended data\n",
    "    # (time points, observed values, amplitudes of cycles, periods, phase shifts, and baseline)\n",
    "    (\n",
    "        time_values,\n",
    "        observed_values,\n",
    "        amplitudes,\n",
    "        periods,\n",
    "        phase_shifts,\n",
    "        baseline,\n",
    "    ) = modeling.prepare_sinusoidal_model_inputs(\n",
    "        time_series_data=detrend,\n",
    "        seasonality_info=seasonality_info,\n",
    "    )\n",
    "\n",
    "    # Fit combined sinusoidal waves to the detrended data\n",
    "    # This creates a mathematical representation of all cyclical patterns\n",
    "    fitted = modeling.fit_sinusoidal_model(\n",
    "        time_values=time_values,\n",
    "        observed_values=observed_values,\n",
    "        amplitudes=amplitudes,\n",
    "        periods=periods,\n",
    "        phase_shifts=phase_shifts,\n",
    "        baseline=baseline,\n",
    "        predict_time=np.arange(len(detrend)),  # Generate predictions for all time points\n",
    "    )\n",
    "\n",
    "    # Adjust the timing of cycles to better match actual data patterns\n",
    "    # Creates a pandas Series with corrected phase shifts using the same index as detrend\n",
    "    corrected_phase = pd.Series(\n",
    "        analysis.correct_phase_shift(detrend, fitted),\n",
    "        index=detrend.index,\n",
    "    )\n",
    "\n",
    "    # Combine the long-term trend with phase-corrected cycles to create complete model\n",
    "    modeled = trend + corrected_phase\n",
    "\n",
    "    # Subset the modeled data to match the original time series timepoints\n",
    "    # (This handles cases where the original data might have missing values)\n",
    "    modeled_timeseries = modeled.loc[timeseries.index]\n",
    "\n",
    "    return modeled_timeseries\n",
    "\n",
    "\n",
    "def show_elapsed_time(start, end):\n",
    "    elapsed_seconds = round(end - start, 2)  # Compute total elapsed time in seconds\n",
    "    hours = int(elapsed_seconds // 3600)\n",
    "    minutes = int((elapsed_seconds % 3600) // 60)\n",
    "    seconds = int(elapsed_seconds % 60)\n",
    "    print(f\"Processing Time: {hours} hours {minutes} minutes {seconds} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fc04c2d-e294-4e22-b013-4e9c4fa5afee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T14:50:57.413612Z",
     "iopub.status.busy": "2025-03-08T14:50:57.413115Z",
     "iopub.status.idle": "2025-03-08T14:50:58.241934Z",
     "shell.execute_reply": "2025-03-08T14:50:58.241434Z",
     "shell.execute_reply.started": "2025-03-08T14:50:57.413612Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to synchronously open file (unable to open file: name = '220250307_MLCW_CRFP_v7.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m h5_fpath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m220250307_MLCW_CRFP_v7.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# initiate MLCW class object\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m mlcw_obj \u001b[38;5;241m=\u001b[39m \u001b[43mMLCW\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh5_fpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mh5_fpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m mlcw_data, mlcw_metadata \u001b[38;5;241m=\u001b[39m mlcw_obj\u001b[38;5;241m.\u001b[39mget_data()\n\u001b[0;32m      5\u001b[0m available_stations \u001b[38;5;241m=\u001b[39m mlcw_obj\u001b[38;5;241m.\u001b[39mlist_stations()\n",
      "File \u001b[1;32mD:\\VENV_PYTHON\\appgeopy\\mlcwtools\\mlcwbox.py:22\u001b[0m, in \u001b[0;36mMLCW.__init__\u001b[1;34m(self, h5_fpath)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03mInitialize with the path to your HDF5 file. \u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03mActual data is loaded on demand, not at __init__ time, for flexibility.\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh5_fpath \u001b[38;5;241m=\u001b[39m h5_fpath\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlcw_data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlcw_metadata \u001b[38;5;241m=\u001b[39m \u001b[43mh5pytools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_HDF5\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mh5_fpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\VENV_PYTHON\\appgeopy\\gwatertools\\h5pytools.py:242\u001b[0m, in \u001b[0;36mopen_HDF5\u001b[1;34m(fpath)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;124;03mQuickly open HDF5 file and extract the information.\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;66;03m# Extract existing data and metadata\u001b[39;00m\n\u001b[1;32m--> 242\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m hdf5_file:\n\u001b[0;32m    243\u001b[0m     data_dict \u001b[38;5;241m=\u001b[39m hdf5_to_data_dict(hdf5_file)\n\u001b[0;32m    244\u001b[0m     metadata_dict \u001b[38;5;241m=\u001b[39m hdf5_to_metadata_dict(hdf5_file)\n",
      "File \u001b[1;32mD:\\Programs\\miniconda3\\Library\\envs\\fafalab\\Lib\\site-packages\\h5py\\_hl\\files.py:564\u001b[0m, in \u001b[0;36mFile.__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[0;32m    555\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[0;32m    556\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[0;32m    557\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[0;32m    558\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[0;32m    559\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[0;32m    560\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    561\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[0;32m    562\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[0;32m    563\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[1;32m--> 564\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    567\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[1;32mD:\\Programs\\miniconda3\\Library\\envs\\fafalab\\Lib\\site-packages\\h5py\\_hl\\files.py:238\u001b[0m, in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[0;32m    237\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[1;32m--> 238\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    240\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to synchronously open file (unable to open file: name = '220250307_MLCW_CRFP_v7.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "h5_fpath = \"20250307_MLCW_CRFP_v7.h5\"\n",
    "# initiate MLCW class object\n",
    "mlcw_obj = MLCW(h5_fpath=h5_fpath)\n",
    "mlcw_data, mlcw_metadata = mlcw_obj.get_data()\n",
    "available_stations = mlcw_obj.list_stations()\n",
    "available_stations[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2123ac3d-2ae1-425a-b183-df5434670454",
   "metadata": {},
   "source": [
    "#### Modeling MLCW data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e022a382-2569-464d-8280-86534c3bb010",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-08T14:50:58.242427Z",
     "iopub.status.idle": "2025-03-08T14:50:58.242922Z",
     "shell.execute_reply": "2025-03-08T14:50:58.242922Z",
     "shell.execute_reply.started": "2025-03-08T14:50:58.242922Z"
    }
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "# select_station = available_stations[0]\n",
    "for select_station in tqdm(available_stations, desc=\"Modeling ring records\", position=0, leave=True):\n",
    "\n",
    "    # Extract station code from metadata using split operation\n",
    "    station_wellcode = mlcw_metadata[select_station][\"LandSubsidenceMonitoringWellIdentifier\"].split(\"_\")[-1]\n",
    "    \n",
    "    original_mlcw = mlcw_obj.build_dataframe(station=select_station, value_type=\"original\")\n",
    "    original_mlcw = original_mlcw.T * 1000\n",
    "    original_mlcw = original_mlcw.sort_index()\n",
    "    \n",
    "    original_mlcw = original_mlcw.loc[:\"2022\", :]\n",
    "    \n",
    "    colnames = original_mlcw.columns\n",
    "    \n",
    "    model_original_mlcw = pd.DataFrame(data=None, index=original_mlcw.index)\n",
    "    \n",
    "    for col in tqdm(colnames, desc=f\"Processing {select_station}\", position=1, leave=False):\n",
    "        original_mlcw_byRing = original_mlcw.loc[:, col]\n",
    "    \n",
    "        start_idx = original_mlcw_byRing.first_valid_index()\n",
    "        end_idx = original_mlcw_byRing.last_valid_index()\n",
    "    \n",
    "        original_mlcw_byRing = original_mlcw_byRing.loc[start_idx:end_idx]\n",
    "    \n",
    "        modeled_original_mlcw_byRing = model_timeseries(original_mlcw_byRing)\n",
    "        modeled_original_mlcw_byRing.name = col\n",
    "        modeled_original_mlcw_byRing = modeled_original_mlcw_byRing / 1000\n",
    "        model_original_mlcw[col] = model_original_mlcw.index.map(modeled_original_mlcw_byRing)\n",
    "    \n",
    "    mlcw_data[select_station][\"values\"][\"model_original\"] = model_original_mlcw.T.to_numpy()\n",
    "\n",
    "end = time.time()\n",
    "show_elapsed_time(start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badf3339-c25b-42bf-8218-448f58066b2a",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-08T14:50:58.243419Z",
     "iopub.status.idle": "2025-03-08T14:50:58.243915Z",
     "shell.execute_reply": "2025-03-08T14:50:58.243915Z",
     "shell.execute_reply.started": "2025-03-08T14:50:58.243915Z"
    }
   },
   "outputs": [],
   "source": [
    "today_string = datetime.now().strftime(\"%Y%m%d\")\n",
    "\n",
    "mlcw_metadata[\"Description_3\"] = (\n",
    "    \"2025/03/08: Model the ring readings using sinusoidal fitting function because they also show the sinusoidal patterns\"\n",
    ")\n",
    "\n",
    "# Write updated data and metadata back to the HDF5 file\n",
    "with h5py.File(f\"{today_string}_MLCW_CRFP_v8.h5\", \"w\") as hdf5_file:\n",
    "    gwatertools.h5pytools.data_to_hdf5(hdf5_file, mlcw_data)\n",
    "    gwatertools.h5pytools.metadata_to_hdf5(hdf5_file, mlcw_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad86262-a4c7-49af-8c3d-c5ab3b8077a2",
   "metadata": {},
   "source": [
    "#### Plot MLCW data ring by ring"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a0d8e2b7-aa80-4084-8a7f-25decc702df7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-07T07:20:10.832018Z",
     "iopub.status.busy": "2025-03-07T07:20:10.831022Z",
     "iopub.status.idle": "2025-03-07T07:23:23.493624Z",
     "shell.execute_reply": "2025-03-07T07:23:23.493624Z",
     "shell.execute_reply.started": "2025-03-07T07:20:10.832018Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# ==== DATA PREPARATION ====\n",
    "# Select the first station from available stations\n",
    "# select_station = available_stations[0]\n",
    "\n",
    "for select_station in tqdm(available_stations):\n",
    "    \n",
    "    # Extract station code from metadata using split operation\n",
    "    station_wellcode = mlcw_metadata[select_station][\"LandSubsidenceMonitoringWellIdentifier\"].split(\"_\")[-1]\n",
    "    \n",
    "    # Build original dataset for selected station and convert units to millimeters\n",
    "    original_mlcw = mlcw_obj.build_dataframe(station=select_station, value_type=\"original\")\n",
    "    original_mlcw = original_mlcw.T*1000  # Unit conversion: m to mm\n",
    "    \n",
    "    # ==== DATA PROCESSING ====\n",
    "    # Calculate temporal differences between consecutive columns\n",
    "    cols_difference = original_mlcw.diff(axis=1)\n",
    "    cols_difference.iloc[:, 0] = original_mlcw.iloc[:, 0]  # Preserve initial values\n",
    "    \n",
    "    # Calculate cumulative differences relative to first time period\n",
    "    differ_to_ref = lambda series: np.array(series-series[0], dtype=np.float16)\n",
    "    cols_difference_ref2first = cols_difference.apply(differ_to_ref, axis=0)\n",
    "    \n",
    "    # Resample data to monthly frequency using calendar month starts\n",
    "    # monthly_cols_difference_ref2first = cols_difference_ref2first.resample(\"MS\").mean()\n",
    "    \n",
    "    # ==== VISUALIZATION SETUP ====\n",
    "    # Create 30-axes grid (10 rows x 3 columns) for time series visualization\n",
    "    \n",
    "    # colnames = monthly_cols_difference_ref2first.columns\n",
    "    colnames = cols_difference_ref2first.columns\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=10, ncols=3, figsize=(16.5, 11.7))\n",
    "    axes = axes.flatten()  # Flatten axes array for easier iteration\n",
    "    \n",
    "    # Determine temporal range for vertical year markers\n",
    "    # start_year = monthly_cols_difference_ref2first.first_valid_index().year\n",
    "    # end_year = monthly_cols_difference_ref2first.last_valid_index().year\n",
    "    start_year = cols_difference_ref2first.first_valid_index().year\n",
    "    end_year = cols_difference_ref2first.last_valid_index().year\n",
    "    \n",
    "    # ==== PLOTTING LOOP ====\n",
    "    # Generate time series plot for each column in resampled dataframe\n",
    "    for ax, col in zip(axes, colnames):\n",
    "        \n",
    "        # Plot gray line with transparent effect\n",
    "        # ax.plot(monthly_cols_difference_ref2first.loc[:, col], linestyle=\"-\", color=\"gray\", lw=1, alpha=0.75)\n",
    "        ax.plot(cols_difference_ref2first.loc[:, col], linestyle=\"-\", color=\"gray\", lw=1, alpha=0.75)\n",
    "        \n",
    "        # Add empty markers with red edges for data points\n",
    "        # ax.plot(monthly_cols_difference_ref2first.loc[:, col], linestyle=\" \", marker='o', \n",
    "        #         markeredgecolor='red', markerfacecolor='none', markeredgewidth=0.5, ms=5)\n",
    "        ax.plot(cols_difference_ref2first.loc[:, col], linestyle=\" \", marker='o', \n",
    "                markeredgecolor='red', markerfacecolor='none', markeredgewidth=0.5, ms=5)\n",
    "        \n",
    "        # Remove right/top plot borders\n",
    "        for side in [\"right\", \"top\"]:\n",
    "            ax.spines[side].set_visible(False)\n",
    "        \n",
    "        # Add vertical year markers with subtle styling\n",
    "        for year in range(start_year, end_year+1):\n",
    "            ax.axvline(x=pd.Timestamp(year, 1, 1), lw=1, color='lightgrey', alpha=0.5)\n",
    "        \n",
    "        # Add column identifier in bottom-left corner\n",
    "        ax.text(x=0.015, y=0.05, s=str(round(col, 3)), transform=ax.transAxes, \n",
    "                fontsize=10, fontweight='bold', color='blue', alpha=0.75)\n",
    "    \n",
    "    # ==== FINAL TOUCHES ====\n",
    "    # Hide unused axes in grid layout\n",
    "    for i in range(len(colnames), len(axes)):\n",
    "        axes[i].axis(\"off\")\n",
    "    \n",
    "    # Add primary title with station metadata\n",
    "    fig.suptitle(t=f\"{select_station} ({station_wellcode})\", fontsize=18, fontweight='bold')\n",
    "    \n",
    "    # Adjust layout spacing and display plot\n",
    "    fig.tight_layout()\n",
    "    visualize.save_figure(fig, savepath=f\"figs\\\\{select_station}.png\", dpi=600)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94421880-3db8-46f5-a0bd-c9f82a78e488",
   "metadata": {},
   "source": [
    "#### Plot MLCW measurent differecing --> detect weird changes"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b1cc93b5-9f31-4d6a-979d-b914fb5d9300",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# ==== DATA PREPARATION ====\n",
    "# Select the first station from available stations\n",
    "# select_station = available_stations[0]\n",
    "\n",
    "for select_station in tqdm(available_stations[:1]):\n",
    "\n",
    "    # Extract station code from metadata using split operation\n",
    "    station_wellcode = mlcw_metadata[select_station][\"LandSubsidenceMonitoringWellIdentifier\"].split(\"_\")[-1]\n",
    "\n",
    "    # Build original dataset for selected station and convert units to millimeters\n",
    "    original_mlcw = mlcw_obj.build_dataframe(station=select_station, value_type=\"original\")\n",
    "    original_mlcw = original_mlcw.T * 1000  # Unit conversion: m to mm\n",
    "\n",
    "    # ==== DATA PROCESSING ====\n",
    "    # Calculate temporal differences between consecutive columns\n",
    "    cols_difference = original_mlcw.diff(axis=1)\n",
    "    cols_difference.iloc[:, 0] = original_mlcw.iloc[:, 0]  # Preserve initial values\n",
    "\n",
    "    # Calculate cumulative differences relative to first time period\n",
    "    differ_to_ref = lambda series: np.array(series - series[0], dtype=np.float16)\n",
    "    cols_difference_ref2first = cols_difference.apply(differ_to_ref, axis=0)\n",
    "\n",
    "    # Resample data to monthly frequency using calendar month starts\n",
    "    # monthly_cols_difference_ref2first = cols_difference_ref2first.resample(\"MS\").mean()\n",
    "\n",
    "    # ==== VISUALIZATION SETUP ====\n",
    "    # Create 30-axes grid (10 rows x 3 columns) for time series visualization\n",
    "\n",
    "    # colnames = monthly_cols_difference_ref2first.columns\n",
    "    colnames = cols_difference_ref2first.columns\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=10, ncols=3, figsize=(16.5, 11.7))\n",
    "    axes = axes.flatten()  # Flatten axes array for easier iteration\n",
    "\n",
    "    # Determine temporal range for vertical year markers\n",
    "    # start_year = monthly_cols_difference_ref2first.first_valid_index().year\n",
    "    # end_year = monthly_cols_difference_ref2first.last_valid_index().year\n",
    "    start_year = cols_difference_ref2first.first_valid_index().year\n",
    "    end_year = cols_difference_ref2first.last_valid_index().year\n",
    "\n",
    "    # ==== PLOTTING LOOP ====\n",
    "    # Generate time series plot for each column in resampled dataframe\n",
    "    for ax, col in zip(axes, colnames):\n",
    "\n",
    "        cols_difference_ref2first_byCol = cols_difference_ref2first.loc[:, col]\n",
    "        cols_difference_ref2first_byCol_diff = cols_difference_ref2first_byCol.diff()\n",
    "\n",
    "        differencing_mean = np.nanmean(cols_difference_ref2first_byCol_diff)\n",
    "        differencing_stdev = np.nanstd(cols_difference_ref2first_byCol_diff)\n",
    "\n",
    "        upper_bound = differencing_mean + 3 * differencing_stdev\n",
    "        lower_bound = differencing_mean - 3 * differencing_stdev\n",
    "\n",
    "        # Plot gray line with transparent effect\n",
    "        # ax.plot(monthly_cols_difference_ref2first.loc[:, col], linestyle=\"-\", color=\"gray\", lw=1, alpha=0.75)\n",
    "        ax.plot(cols_difference_ref2first_byCol_diff, linestyle=\"-\", color=\"gray\", lw=1, alpha=0.75)\n",
    "\n",
    "        # Add empty markers with red edges for data points\n",
    "        # ax.plot(monthly_cols_difference_ref2first.loc[:, col], linestyle=\" \", marker='o',\n",
    "        #         markeredgecolor='red', markerfacecolor='none', markeredgewidth=0.5, ms=5)\n",
    "        ax.plot(\n",
    "            cols_difference_ref2first_byCol_diff,\n",
    "            linestyle=\" \",\n",
    "            marker=\"o\",\n",
    "            markeredgecolor=\"blue\",\n",
    "            markerfacecolor=\"none\",\n",
    "            markeredgewidth=0.5,\n",
    "            ms=5,\n",
    "        )\n",
    "\n",
    "        # Remove right/top plot borders\n",
    "        for side in [\"right\", \"top\"]:\n",
    "            ax.spines[side].set_visible(False)\n",
    "\n",
    "        # Add vertical year markers with subtle styling\n",
    "        for year in range(start_year, end_year + 1):\n",
    "            ax.axvline(x=pd.Timestamp(year, 1, 1), lw=1, color=\"lightgrey\", alpha=0.5)\n",
    "\n",
    "        # Add column identifier in bottom-left corner\n",
    "        ax.text(\n",
    "            x=0.015,\n",
    "            y=0.05,\n",
    "            s=str(round(col, 3)),\n",
    "            transform=ax.transAxes,\n",
    "            fontsize=10,\n",
    "            fontweight=\"bold\",\n",
    "            color=\"blue\",\n",
    "            alpha=0.75,\n",
    "        )\n",
    "\n",
    "        ax.axhline(y=differencing_mean, color=\"green\", alpha=0.5)\n",
    "        ax.axhline(y=upper_bound, color=\"magenta\", alpha=0.5)\n",
    "        ax.axhline(y=lower_bound, color=\"magenta\", alpha=0.5)\n",
    "\n",
    "    # ==== FINAL TOUCHES ====\n",
    "    # Hide unused axes in grid layout\n",
    "    for i in range(len(colnames), len(axes)):\n",
    "        axes[i].axis(\"off\")\n",
    "\n",
    "    # Add primary title with station metadata\n",
    "    fig.suptitle(t=f\"{select_station} ({station_wellcode})\", fontsize=18, fontweight=\"bold\")\n",
    "\n",
    "    # Adjust layout spacing and display plot\n",
    "    fig.tight_layout()\n",
    "    visualize.save_figure(fig, savepath=f\"figs_differencing\\\\{select_station}.png\", dpi=600)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d46281-a893-45ac-9647-9d23b4e02278",
   "metadata": {},
   "source": [
    "#### Export original file to Excel"
   ]
  },
  {
   "cell_type": "raw",
   "id": "df6af7e1-bb8c-4097-8738-4f43fcc8be42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-07T08:38:41.037114Z",
     "iopub.status.busy": "2025-03-07T08:38:41.037114Z",
     "iopub.status.idle": "2025-03-07T08:40:48.489969Z",
     "shell.execute_reply": "2025-03-07T08:40:48.489969Z",
     "shell.execute_reply.started": "2025-03-07T08:38:41.037114Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# select_station = available_stations[0]\n",
    "for select_station in tqdm(available_stations):\n",
    "\n",
    "    # Extract station code from metadata using split operation\n",
    "    station_wellcode = mlcw_metadata[select_station][\"LandSubsidenceMonitoringWellIdentifier\"].split(\"_\")[-1]\n",
    "    \n",
    "    original_mlcw = mlcw_obj.build_dataframe(station=select_station, value_type=\"original\")\n",
    "    original_mlcw = original_mlcw.T * 1000\n",
    "    original_mlcw = original_mlcw.sort_index()\n",
    "    original_mlcw = original_mlcw.loc[\"2014\":\"2021\", :]\n",
    "    \n",
    "    colnames = original_mlcw.columns\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=10, ncols=3, figsize=(16.5, 11.7))\n",
    "    axes = axes.flatten()  # Flatten axes array for easier iteration\n",
    "    \n",
    "    start_year = original_mlcw.first_valid_index().year\n",
    "    end_year = original_mlcw.last_valid_index().year\n",
    "    \n",
    "    # ==== PLOTTING LOOP ====\n",
    "    # Generate time series plot for each column in resampled dataframe\n",
    "    for ax, col in zip(axes, colnames):\n",
    "        mlcw_byCol = original_mlcw.loc[:, col]\n",
    "        trend, coeffs = analysis.get_linear_trend(mlcw_byCol)\n",
    "        # trend, coeffs = analysis.get_polynomial_trend(mlcw_byCol, order=2)\n",
    "        detrend = mlcw_byCol - trend\n",
    "        mean = np.nanmean(detrend)\n",
    "        stdev = np.nanstd(detrend)\n",
    "    \n",
    "        upper_bound = mean + 3 * stdev\n",
    "        lower_bound = mean - 3 * stdev\n",
    "    \n",
    "        ax.plot(detrend, linestyle=\"-\", color=\"gray\", lw=1, alpha=0.75)\n",
    "    \n",
    "        ax.plot(\n",
    "            detrend, linestyle=\" \", marker=\"o\", markeredgecolor=\"blue\", markerfacecolor=\"none\", markeredgewidth=0.5, ms=5\n",
    "        )\n",
    "    \n",
    "        # Remove right/top plot borders\n",
    "        for side in [\"right\", \"top\"]:\n",
    "            ax.spines[side].set_visible(False)\n",
    "    \n",
    "        # Add vertical year markers with subtle styling\n",
    "        for year in range(start_year, end_year + 1):\n",
    "            ax.axvline(x=pd.Timestamp(year, 1, 1), lw=1, color=\"lightgrey\", alpha=0.5)\n",
    "    \n",
    "        # Add column identifier in bottom-left corner\n",
    "        ax.text(\n",
    "            x=0.015,\n",
    "            y=0.05,\n",
    "            s=str(round(col, 3)),\n",
    "            transform=ax.transAxes,\n",
    "            fontsize=10,\n",
    "            fontweight=\"bold\",\n",
    "            color=\"blue\",\n",
    "            alpha=0.75,\n",
    "        )\n",
    "    \n",
    "        ax.axhline(y=mean, color=\"green\", alpha=0.5)\n",
    "        ax.axhline(y=upper_bound, color=\"magenta\", alpha=0.5)\n",
    "        ax.axhline(y=lower_bound, color=\"magenta\", alpha=0.5)\n",
    "    \n",
    "    # ==== FINAL TOUCHES ====\n",
    "    # Hide unused axes in grid layout\n",
    "    for i in range(len(colnames), len(axes)):\n",
    "        axes[i].axis(\"off\")\n",
    "\n",
    "    # Add primary title with station metadata\n",
    "    fig.suptitle(t=f\"{select_station} ({station_wellcode})\", fontsize=18, fontweight=\"bold\")\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    visualize.save_figure(fig, savepath=f\"figs2\\\\{select_station}.png\", dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7929ba4e-2781-4436-9219-f44c428462b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-07T05:12:50.718975Z",
     "iopub.status.busy": "2025-03-07T05:12:50.718975Z",
     "iopub.status.idle": "2025-03-07T05:12:51.421362Z",
     "shell.execute_reply": "2025-03-07T05:12:51.421362Z",
     "shell.execute_reply.started": "2025-03-07T05:12:50.718975Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "source": [
    "# ==============================================================\n",
    "# STEP 1: CHOOSE MONITORING STATION AND GET ITS IDENTIFICATION CODE\n",
    "# ==============================================================\n",
    "# Select the first station from the available list\n",
    "# (This is like picking the first item from a list of weather stations)\n",
    "select_station = available_stations[0]\n",
    "\n",
    "# Extract a unique code from the station's metadata\n",
    "# (Example: If metadata is \"Station_1234_SensorA\", split to get \"SensorA\")\n",
    "station_wellcode = mlcw_metadata[select_station][\"LandSubsidenceMonitoringWellIdentifier\"].split(\"_\")[-1]\n",
    "\n",
    "# ==============================================================\n",
    "# STEP 2: LOAD DATA AND CONVERT UNITS\n",
    "# ==============================================================\n",
    "# Get the original ground movement data for the selected station\n",
    "# (Imagine opening a spreadsheet with dates and measurements)\n",
    "original_mlcw = mlcw_obj.build_dataframe(station=select_station, value_type=\"original\")\n",
    "\n",
    "# Convert measurements from meters to millimeters (1m = 1000mm)\n",
    "original_mlcw = original_mlcw.T * 1000\n",
    "\n",
    "# ==============================================================\n",
    "# STEP 3: ANALYZE CHANGES OVER TIME\n",
    "# ==============================================================\n",
    "# Calculate differences between consecutive measurements\n",
    "# (Like tracking daily changes in temperature)\n",
    "cols_difference = original_mlcw.diff(axis=1)\n",
    "\n",
    "# Ensure the first column remains unchanged (baseline for comparison)\n",
    "cols_difference.iloc[:, 0] = original_mlcw.iloc[:, 0]\n",
    "\n",
    "# ==============================================================\n",
    "# STEP 4: NORMALIZE TO A STARTING POINT\n",
    "# ==============================================================\n",
    "# Adjust all values to start from zero at the initial time\n",
    "# (Example: A series like [100, 150, 200] becomes [0, 50, 100])\n",
    "differ_to_ref = lambda series: np.array(series - series[0], dtype=np.float16)\n",
    "cols_difference_ref2first = cols_difference.apply(differ_to_ref, axis=0)\n",
    "\n",
    "# ==============================================================\n",
    "# STEP 5: RESAMPLE TO REGULAR MONTHLY INTERVALS\n",
    "# ==============================================================\n",
    "# Combine data into monthly averages (like monthly weather reports)\n",
    "monthly_cols_difference_ref2first = cols_difference_ref2first.resample(\"MS\").mean()\n",
    "\n",
    "# Get column names for later analysis (like \"SensorA\", \"SensorB\", etc.)\n",
    "colnames = monthly_cols_difference_ref2first.columns\n",
    "\n",
    "# ==============================================================\n",
    "# STEP 6: CREATE A COMPLETE TIMELINE\n",
    "# ==============================================================\n",
    "# Generate a full list of dates from start to end (no gaps)\n",
    "fulltime_arr = datetime_handle.get_fulltime(monthly_cols_difference_ref2first.index)\n",
    "\n",
    "# ==============================================================\n",
    "# STEP 7: ANALYZE SPECIFIC DEPTHS (ONE SENSOR AT A TIME)\n",
    "# ==============================================================\n",
    "# Choose the 8th sensor in the list (index 7)\n",
    "col = colnames[7]\n",
    "\n",
    "# Extract data only for this sensor\n",
    "timeseries = monthly_cols_difference_ref2first.loc[:, col].copy()\n",
    "\n",
    "# ==============================================================\n",
    "# STEP 8: HANDLE ABNORMAL DATA POINTS\n",
    "# ==============================================================\n",
    "# Find unusual values (e.g., sudden spikes/drops)\n",
    "# detected_outliers, _trend, _residuals = get_outliers(timeseries)\n",
    "detected_outliers, _trend, _nscore_series, _transform_table = get_outliers(timeseries)\n",
    "\n",
    "# Replace unusual values with blank (NaN) for later fixing\n",
    "timeseries.loc[detected_outliers.index] = np.nan\n",
    "\n",
    "# ==============================================================\n",
    "# STEP 9: EXPAND TO DAILY INTERVALS\n",
    "# ==============================================================\n",
    "# Convert monthly data into daily entries (filling missing days with NaN)\n",
    "fulltime_timeseries = datetime_handle.fulltime_table(timeseries, fulltime_arr)\n",
    "\n",
    "# ==============================================================\n",
    "# STEP 10: REPAIR AND RECONSTRUCT MISSING DATA\n",
    "# ==============================================================\n",
    "# Separate long-term trends and seasonal patterns (like separating daily weather from yearly seasons)\n",
    "trend, phase_corrected = regenerate_timeseries(fulltime_timeseries)\n",
    "\n",
    "# Combine trend and corrected patterns to create a complete model\n",
    "modeled_timeseries = trend + phase_corrected\n",
    "\n",
    "# Replace previously blank (NaN) values with model predictions\n",
    "null_value_index = timeseries[timeseries.isnull()].index\n",
    "timeseries.loc[null_value_index] = modeled_timeseries.resample(\"MS\").mean()[null_value_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460d4579-0451-41fb-980d-f7d73adcaa36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
