{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63b902eb-8da0-4127-a39c-4e0233d25312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 file pairs\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 146\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;66;03m# = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;66;03m# EXECUTION\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;66;03m# = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \n\u001b[0;32m    144\u001b[0m \u001b[38;5;66;03m# Initialize processor\u001b[39;00m\n\u001b[0;32m    145\u001b[0m processor \u001b[38;5;241m=\u001b[39m GTWRProcessor()\n\u001b[1;32m--> 146\u001b[0m \u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_all_points\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;66;03m# # Process specific pair and pointkey\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;66;03m# processor.load_pair(0)\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;66;03m# single_result, station_name = processor.process_single_point(\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# print(f\"Processed station: {station_name}\")\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;66;03m# single_result\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[1], line 127\u001b[0m, in \u001b[0;36mGTWRProcessor.process_all_points\u001b[1;34m(self, include_mlcw)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Process all pointkeys for current pair.\"\"\"\u001b[39;00m\n\u001b[0;32m    126\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 127\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, pointkey \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpointkeys\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m         result, station \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_single_point(i, include_mlcw)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "GTWR Model Output Integration with Predicted Coefficients and MLCW Data\n",
    "Streamlined workflow for processing coefficient predictions with GTWR outputs and MLCW time series.\n",
    "\"\"\"\n",
    "\n",
    "from appgeopy import *\n",
    "from my_packages import *\n",
    "\n",
    "# = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =\n",
    "# CONFIGURATION\n",
    "# = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =\n",
    "\n",
    "# File paths\n",
    "GTWR_DIR = r\"D:\\1000_SCRIPTS\\003_Project002\\20250222_GTWR001\\5_GTWR_Prediction\"\n",
    "MLCW_H5_PATH = r\"D:\\1000_SCRIPTS\\003_Project002\\20250222_GTWR001\\1_PrepareDatasets\\1_MLCWs\\20250415_MLCW_CRFP_monthly_v2.h5\"\n",
    "\n",
    "# = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =\n",
    "# UTILITY FUNCTIONS\n",
    "# = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =\n",
    "\n",
    "\n",
    "def discover_file_pairs():\n",
    "    \"\"\"Discover and pair coefficient and GTWR model files.\"\"\"\n",
    "    predict_coeffs_files = glob(\"*Predicted_Coeffs*.csv\")\n",
    "    gtwr_model_files = glob(os.path.join(GTWR_DIR, \"*gtwr_Layer*.csv\"))\n",
    "    return list(zip(predict_coeffs_files, gtwr_model_files))\n",
    "\n",
    "\n",
    "def load_and_prepare_data(coeffs_file, gtwr_file):\n",
    "    \"\"\"Load and prepare data from file pair.\"\"\"\n",
    "    predicted_coeffs_df = pd.read_csv(coeffs_file)\n",
    "    gtwr_model_output_df = pd.read_csv(gtwr_file)\n",
    "\n",
    "    # Generate PointKey for GTWR data\n",
    "    gtwr_model_output_df[\"PointKey\"] = [\n",
    "        f\"X{int(x*1000)}Y{int(y*1000)}\"\n",
    "        for x, y in zip(\n",
    "            gtwr_model_output_df[\"X_TWD97\"], gtwr_model_output_df[\"Y_TWD97\"]\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    unique_pointkeys = predicted_coeffs_df[\"PointKey\"].unique()\n",
    "    return predicted_coeffs_df, gtwr_model_output_df, unique_pointkeys\n",
    "\n",
    "\n",
    "def process_pointkey(pointkey, predicted_coeffs_df, gtwr_model_output_df):\n",
    "    \"\"\"Process single pointkey by merging coefficients with GTWR outputs.\"\"\"\n",
    "    coeffs_data = predicted_coeffs_df.query(\"PointKey==@pointkey\").copy()\n",
    "    gtwr_data = gtwr_model_output_df.query(\"PointKey==@pointkey\").copy()\n",
    "\n",
    "    coeffs_data = coeffs_data.set_index(\"monthly\")\n",
    "    gtwr_data = gtwr_data.set_index(\"time_stamp\")\n",
    "\n",
    "    # Map GTWR values to coefficient timepoints\n",
    "    for colname in [\"y\", \"yhat\"]:\n",
    "        coeffs_data[colname] = coeffs_data.index.map(gtwr_data[colname])\n",
    "\n",
    "    return coeffs_data.reset_index()\n",
    "\n",
    "\n",
    "def load_mlcw_data(station_name, layer_idx):\n",
    "    \"\"\"Load MLCW data for specific station and layer.\"\"\"\n",
    "    mlcw_data, _ = gwatertools.h5pytools.open_HDF5(MLCW_H5_PATH)\n",
    "    station_data = mlcw_data[station_name]\n",
    "\n",
    "    values = station_data[\"monthly_values\"][\"compactbylayer_PCA\"][layer_idx]\n",
    "    dates = pd.to_datetime(\n",
    "        [x.decode(\"utf-8\") for x in station_data[\"monthly_date\"]]\n",
    "    )\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        data=values, index=dates, columns=[f\"MLCW_Layer_{layer_idx+1}\"]\n",
    "    )\n",
    "\n",
    "\n",
    "# = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =\n",
    "# MAIN PROCESSING CLASS\n",
    "# = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =\n",
    "\n",
    "\n",
    "class GTWRProcessor:\n",
    "    def __init__(self):\n",
    "        self.file_pairs = discover_file_pairs()\n",
    "        print(f\"Found {len(self.file_pairs)} file pairs\")\n",
    "\n",
    "        self.current_pair_idx = None\n",
    "        self.coeffs_df = None\n",
    "        self.gtwr_df = None\n",
    "        self.pointkeys = None\n",
    "\n",
    "    def load_pair(self, pair_idx):\n",
    "        \"\"\"Load specific file pair.\"\"\"\n",
    "        self.current_pair_idx = pair_idx\n",
    "        self.coeffs_df, self.gtwr_df, self.pointkeys = load_and_prepare_data(\n",
    "            *self.file_pairs[pair_idx]\n",
    "        )\n",
    "        print(f\"Loaded pair {pair_idx}: {len(self.pointkeys)} pointkeys\")\n",
    "\n",
    "    def process_single_point(self, pointkey_idx, include_mlcw=True):\n",
    "        \"\"\"Process single pointkey with optional MLCW integration.\"\"\"\n",
    "        if self.coeffs_df is None:\n",
    "            raise ValueError(\"No data loaded. Call load_pair() first.\")\n",
    "\n",
    "        pointkey = self.pointkeys[pointkey_idx]\n",
    "        station_name = self.coeffs_df.query(\"PointKey==@pointkey\").STATION.iloc[\n",
    "            0\n",
    "        ]\n",
    "\n",
    "        # Process GTWR data\n",
    "        result = process_pointkey(pointkey, self.coeffs_df, self.gtwr_df)\n",
    "        result = result.set_index(\"time\")\n",
    "\n",
    "        # Add MLCW data if requested\n",
    "        if include_mlcw:\n",
    "            mlcw_df = load_mlcw_data(station_name, self.current_pair_idx)\n",
    "            layer_col = f\"MLCW_Layer_{self.current_pair_idx+1}\"\n",
    "\n",
    "            result[layer_col] = result.index.map(mlcw_df[layer_col])\n",
    "            # Apply relative displacement (subtract first value)\n",
    "            result[layer_col] = result[layer_col] - result[layer_col].iloc[0]\n",
    "\n",
    "        return result, station_name\n",
    "\n",
    "    def process_all_points(self, include_mlcw=True):\n",
    "        \"\"\"Process all pointkeys for current pair.\"\"\"\n",
    "        results = []\n",
    "        for i, pointkey in enumerate(self.pointkeys):\n",
    "            try:\n",
    "                result, station = self.process_single_point(i, include_mlcw)\n",
    "                result[\"station\"] = station\n",
    "                results.append(result.reset_index())\n",
    "            except (KeyError, IndexError):\n",
    "                continue\n",
    "\n",
    "        return (\n",
    "            pd.concat(results, ignore_index=True) if results else pd.DataFrame()\n",
    "        )\n",
    "\n",
    "\n",
    "# = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =\n",
    "# EXECUTION\n",
    "# = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =\n",
    "\n",
    "# Initialize processor\n",
    "today_string = datetime.now().strftime(\"%Y%m%d\")\n",
    "\n",
    "processor = GTWRProcessor()\n",
    "for pair_idx in range(4):\n",
    "    processor.load_pair(pair_idx)\n",
    "    output_table = processor.process_all_points()\n",
    "    output_table.to_csv(\n",
    "        f\"{today_string}_Future_and_Predicted_MLCW_Layer_{pair_idx+1}.csv\",\n",
    "        index=False,\n",
    "    )\n",
    "# # Process specific pair and pointkey\n",
    "# processor.load_pair(0)\n",
    "# single_result, station_name = processor.process_single_point(\n",
    "#     10, include_mlcw=True\n",
    "# )\n",
    "\n",
    "# print(f\"Processed station: {station_name}\")\n",
    "# single_result"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4ab5acff-6cc3-4662-8dcd-a0ba528a9a41",
   "metadata": {},
   "source": [
    "# Option 2: Process all pointkeys for current file pair\n",
    "# final_output = process_all_pointkeys(\n",
    "#     predicted_coeffs_df, gtwr_model_output_df, unique_pointkeys\n",
    "# )\n",
    "\n",
    "# Option 3: Loop through multiple pointkeys (customizable)\n",
    "# final_output = pd.DataFrame()\n",
    "# for pointkey in unique_pointkeys[:5]:  # First 5 pointkeys\n",
    "#     result = process_pointkey(pointkey, predicted_coeffs_df, gtwr_model_output_df)\n",
    "#     final_output = pd.concat([final_output, result], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4ad379-ee8e-472e-847a-afd685241c00",
   "metadata": {},
   "source": [
    "# GTWR Processor System Architecture\n",
    "\n",
    "## Overview\n",
    "The GTWR processor implements a modular workflow for integrating coefficient predictions with GTWR model outputs and MLCW time series data. The system follows a class-based architecture that maintains state across processing operations.\n",
    "\n",
    "## Component Relationships\n",
    "\n",
    "### Configuration Layer\n",
    "```\n",
    "CONFIGURATION\n",
    "├── GTWR_DIR (file path)\n",
    "└── MLCW_H5_PATH (file path)\n",
    "```\n",
    "\n",
    "### Utility Function Dependencies\n",
    "```\n",
    "discover_file_pairs()\n",
    "├── Searches for \"*Predicted_Coeffs*.csv\"\n",
    "├── Searches for \"*gtwr_Layer*.csv\" in GTWR_DIR\n",
    "└── Returns paired file tuples\n",
    "\n",
    "load_and_prepare_data(coeffs_file, gtwr_file)\n",
    "├── Loads coefficient predictions DataFrame\n",
    "├── Loads GTWR model outputs DataFrame\n",
    "├── Generates PointKey identifiers\n",
    "└── Returns (coeffs_df, gtwr_df, unique_pointkeys)\n",
    "\n",
    "process_pointkey(pointkey, coeffs_df, gtwr_df)\n",
    "├── Filters data by PointKey\n",
    "├── Sets indices for temporal alignment\n",
    "├── Maps GTWR values to coefficient timepoints\n",
    "└── Returns merged DataFrame\n",
    "\n",
    "load_mlcw_data(station_name, layer_idx)\n",
    "├── Opens HDF5 file using MLCW_H5_PATH\n",
    "├── Extracts station-specific data\n",
    "├── Processes temporal and value arrays\n",
    "└── Returns formatted MLCW DataFrame\n",
    "```\n",
    "\n",
    "### Main Processing Class Workflow\n",
    "```\n",
    "GTWRProcessor.__init__()\n",
    "├── Calls discover_file_pairs()\n",
    "├── Initializes state variables\n",
    "└── Displays file pair count\n",
    "\n",
    "GTWRProcessor.load_pair(pair_idx)\n",
    "├── Calls load_and_prepare_data()\n",
    "├── Updates current_pair_idx state\n",
    "├── Stores coeffs_df, gtwr_df, pointkeys\n",
    "└── Displays loading confirmation\n",
    "\n",
    "GTWRProcessor.process_single_point(pointkey_idx, include_mlcw)\n",
    "├── Validates data loading state\n",
    "├── Extracts pointkey and station information\n",
    "├── Calls process_pointkey() for GTWR integration\n",
    "├── Conditionally calls load_mlcw_data()\n",
    "├── Applies relative displacement calculation\n",
    "└── Returns (result_df, station_name)\n",
    "\n",
    "GTWRProcessor.process_all_points(include_mlcw)\n",
    "├── Iterates through all pointkeys\n",
    "├── Calls process_single_point() for each\n",
    "├── Handles exceptions gracefully\n",
    "├── Concatenates results\n",
    "└── Returns consolidated DataFrame\n",
    "```\n",
    "\n",
    "## Data Flow Architecture\n",
    "\n",
    "### Input Sources\n",
    "The system processes three primary data sources that flow through the processing pipeline:\n",
    "\n",
    "**Coefficient Files** → **GTWR Model Files** → **MLCW HDF5 Data**\n",
    "\n",
    "### Processing Pipeline\n",
    "```\n",
    "File Discovery → Data Loading → Point Processing → Result Consolidation\n",
    "```\n",
    "\n",
    "The coefficient predictions serve as the primary temporal framework, with GTWR model outputs providing observed and predicted values that are temporally aligned through index mapping. MLCW data integration occurs optionally as an enhancement layer, applying relative displacement calculations to normalize the time series data.\n",
    "\n",
    "### State Management\n",
    "The GTWRProcessor class maintains processing state through instance variables that track the current file pair index, loaded DataFrames, and available pointkeys. This design enables efficient batch processing while preserving the ability to process individual points interactively.\n",
    "\n",
    "### Error Handling Strategy\n",
    "The system implements defensive programming practices with validation checks for data loading states and exception handling during point processing iterations. Missing pointkeys or data inconsistencies are handled gracefully without terminating the entire processing workflow.\n",
    "\n",
    "## Integration Points\n",
    "\n",
    "The architecture supports both single-point processing for interactive analysis and batch processing for comprehensive dataset processing. The modular function design allows individual components to be tested and utilized independently, while the class-based wrapper provides a cohesive interface for complex workflows involving multiple data sources and processing steps."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
