{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa80254b-16f7-4de1-91bb-0c98993f00b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from appgeopy import *\n",
    "from my_packages import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1268e9c4-31b0-448c-92c2-c6f5431617ee",
   "metadata": {},
   "source": [
    "after getting the available MLCW stations located within the InSAR coverage (from `SideWork_1`),\n",
    "\n",
    "I need to check which stations having available data set.\n",
    "\n",
    "Then I can apply kriging interpolation to get the InSAR measurements at those stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bb357e3-6f84-4eb4-95f1-268479a73277",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_fpath = r\"D:\\1000_SCRIPTS\\003_Project002\\20251111_GTWR003\\1_PrepareDatasets\\MLCW\\20251113_MLCW_monthly_Nov2025_v2.h5\"\n",
    "data, metadata = h5pytools.open_HDF5(hdf5_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a7510e1-52a8-4d71-bc8b-182213a656e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ANHE', 'ANNAN', 'BEICHEN', 'CANLIN', 'DONGGUANG']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "available_stations = [station for station in metadata.keys() if isinstance(metadata[station], dict)]\n",
    "available_stations[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48801fc9-44a1-4fa0-9d9d-fd536aee2b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = r\"\"D:\\1000_SCRIPTS\\003_Project002\\20251111_GTWR003\\1_PrepareDatasets\\MLCW\\shapefiles\\mlcw_Nov2025_twd97.shp\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd0324c-af59-4e56-9058-d25ae3dd67d5",
   "metadata": {},
   "source": [
    "### side work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fcc1dd-aecc-4a90-83a0-fbe54d0ad905",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518c1f76-9f8c-497e-a389-20987c177483",
   "metadata": {},
   "source": [
    "from `all_MLCW_WGS84.shp`, export to `mlcw_Nov2025_twd97.shp`, then export to excel,\n",
    "then change the column names manually, and convert it to geodata again for further processing"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9fb1c31d-fd27-421e-8804-22668efdbdda",
   "metadata": {},
   "source": [
    "fpath = r\"D:\\1000_SCRIPTS\\003_Project002\\20251111_GTWR003\\1_PrepareDatasets\\MLCW\\shapefiles\\mlcw_Nov2025_twd97.shp\"\n",
    "mlcw_df = gpd.read_file(fpath, read_geometry=False)\n",
    "\n",
    "exclude_cols = [\"Field1\", \"Administra\", 'LocationBy', 'Location_1', 'Location_2', 'Location_3']\n",
    "\n",
    "select_cols = [col for col in mlcw_df.columns if col not in exclude_cols]\n",
    "new_mlcw_df = mlcw_df.loc[:, select_cols]\n",
    "\n",
    "new_mlcw_df = new_mlcw_df.query(\"Stutas=='T' & GroundWate in [50, 60]\")\n",
    "\n",
    "new_mlcw_df[\"SetTime\"] = pd.to_datetime(new_mlcw_df[\"SetTime\"])\n",
    "\n",
    "new_mlcw_df = new_mlcw_df.sort_values(by=[\"GroundWate\", \"SetTime\"]).reset_index(drop=True)\n",
    "\n",
    "# new_mlcw_df.to_excel(r\"D:\\1000_SCRIPTS\\003_Project002\\20251111_GTWR003\\1_PrepareDatasets\\MLCW\\shapefiles\\temp.xlsx\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5dc461f3-3e93-43a9-b6ca-3bb515e36e62",
   "metadata": {},
   "source": [
    "df = pd.read_excel(r\"D:\\1000_SCRIPTS\\003_Project002\\20251111_GTWR003\\1_PrepareDatasets\\MLCW\\shapefiles\\temp.xlsx\")\n",
    "gdf = geospatial.convert_to_geodata(df=df, xcoord_col=\"X_WGS84\", ycoord_col=\"Y_WGS84\", crs_epsg=\"EPSG:4326\")\n",
    "gdf.to_file(r\"D:\\1000_SCRIPTS\\003_Project002\\20251111_GTWR003\\1_PrepareDatasets\\MLCW\\shapefiles\\mlcw_Nov2025_wgs84.shp\")\n",
    "gdf.explore(color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ab1bc6-865f-45ec-95c3-7fd0e077172a",
   "metadata": {},
   "source": [
    "after this I create `mlcw_Nov2025_wgs84`, then reproject to `mlcw_Nov2025_twd97`, and create a 200 m buffer, then select InSAR points within the buffer for further processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a76cd2-dd69-4acf-b387-7bcfeac544c8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7203b3d9-9823-4a97-8213-be0f9c938df3",
   "metadata": {},
   "source": [
    "I need to translate the Chinese words into English for use"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c8fdf1ab-234c-48ea-988f-2ac55165762c",
   "metadata": {},
   "source": [
    "from pypinyin import Style, pinyin\n",
    "\n",
    "\n",
    "def convert_to_pinyin_without_tones(text):\n",
    "    \"\"\"\n",
    "    Converts the given Chinese text to Pinyin without tone marks.\n",
    "\n",
    "    Args:\n",
    "        text (str): The Chinese text to convert.\n",
    "\n",
    "    Returns:\n",
    "        str: The Pinyin representation without tones.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert to Pinyin without tones (Style.NORMAL) and handle as words\n",
    "        pinyin_list = pinyin(text, style=Style.NORMAL, heteronym=False)\n",
    "\n",
    "        # Extract the first (and usually only) pinyin syllable from each inner list\n",
    "        # This gets the complete syllable, not just the first character\n",
    "        return \"\".join([sublist[0] for sublist in pinyin_list])\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Conversion error: {str(e)}\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "c5671978-bec0-4539-8f76-0c8b0c8f529d",
   "metadata": {},
   "source": [
    "fpath = r\"D:\\1000_SCRIPTS\\003_Project002\\20251111_GTWR003\\1_PrepareDatasets\\MLCW\\shapefiles\\mlcw_Nov2025_twd97.shp\"\n",
    "gdf = gpd.read_file(fpath)\n",
    "gdf.head(5)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "06260c9e-0431-4ca6-944d-81887e06876a",
   "metadata": {},
   "source": [
    "translated_wellname = gdf.loc[:, \"Cname\"].apply(convert_to_pinyin_without_tones)\n",
    "translated_wellname = translated_wellname.apply(lambda x: x.upper())\n",
    "\n",
    "translated_towname = gdf.loc[:, \"Town\"].apply(convert_to_pinyin_without_tones)\n",
    "translated_towname = translated_towname.apply(lambda x: x.capitalize())\n",
    "\n",
    "gdf.insert(\n",
    "    loc=gdf.columns.get_loc(\"Cname\") + 1,\n",
    "    column=\"Ename\",\n",
    "    value=translated_wellname,\n",
    ")\n",
    "\n",
    "gdf.insert(\n",
    "    loc=gdf.columns.get_loc(\"Town\") + 1,\n",
    "    column=\"Town_EN\",\n",
    "    value=translated_towname,\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ba66262f-1cf9-4e59-9e98-086a18aa20a2",
   "metadata": {},
   "source": [
    "gdf.to_file(fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068ccbc7-81d1-475c-9a9b-46ff8ffea4c0",
   "metadata": {},
   "source": [
    "#### 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b056bf0-c901-41f4-b684-0a7a86b4045e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0c6538-1ef9-4a3b-bec4-62ab0199f288",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80149aa3-450a-4470-a426-fbfc47c92c4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a932ff-1d71-49cb-9dce-f1dd2ea1a4d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
