{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8e25470-d74a-48fa-8c39-477a2320737f",
   "metadata": {},
   "source": [
    "**2024/10/22**\n",
    "\n",
    "- Part 1: This script generates HDF5 file which contains measurement values from MLCWs\n",
    "- Part 2: Add metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b2d22f3-55f1-4ddb-8dff-39c7eb7fbd6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T08:52:31.486516Z",
     "iopub.status.busy": "2024-10-22T08:52:31.486516Z",
     "iopub.status.idle": "2024-10-22T08:52:48.760052Z",
     "shell.execute_reply": "2024-10-22T08:52:48.759978Z",
     "shell.execute_reply.started": "2024-10-22T08:52:31.486516Z"
    }
   },
   "outputs": [],
   "source": [
    "import pinyin\n",
    "from appgeopy import *\n",
    "from my_packages import *\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.set_option(\"display.max_rows\", 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc51d56a-70ce-484d-8ad3-e6234a5d8b9b",
   "metadata": {},
   "source": [
    "#### PART 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c3fb82f-132c-4760-b597-5635ccd1ff33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T08:52:48.762262Z",
     "iopub.status.busy": "2024-10-22T08:52:48.761733Z",
     "iopub.status.idle": "2024-10-22T08:52:48.768961Z",
     "shell.execute_reply": "2024-10-22T08:52:48.768961Z",
     "shell.execute_reply.started": "2024-10-22T08:52:48.762262Z"
    }
   },
   "outputs": [],
   "source": [
    "def differ_to_ref(series, convert_to=None):\n",
    "    \"\"\"\n",
    "    Calculate differential values relative to the first measurement in the series.\n",
    "\n",
    "    Parameters:\n",
    "    - series (pd.Series): A pandas Series containing the measurements.\n",
    "    - convert_to (str or None): Unit to convert the differential values to.\n",
    "                                Accepts 'milimeter', 'centimeter', or None for 'meters'.\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray: The differential values converted to the specified unit.\n",
    "\n",
    "    Raises:\n",
    "    - ValueError: If 'convert_to' is not 'milimeter', 'centimeter', or None.\n",
    "\n",
    "    \"\"\"\n",
    "    # Determine the conversion multiplier based on the desired unit.\n",
    "    if convert_to == \"milimeter\":\n",
    "        multiplier = 1000\n",
    "    elif convert_to == \"centimeter\":\n",
    "        multiplier = 100\n",
    "    elif convert_to is None:\n",
    "        multiplier = 1  # Keep the original unit (meters).\n",
    "    else:\n",
    "        raise ValueError(\"Invalid 'convert_to' value. Must be 'milimeter', 'centimeter', or None for meters.\")\n",
    "\n",
    "    # Calculate differential values relative to the first measurement and apply conversion.\n",
    "    return np.array((series - series.iloc[0]) * multiplier, dtype=np.float16)\n",
    "\n",
    "\n",
    "# -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n",
    "def cdisp_from_base(input_array):\n",
    "    cdisp_ref_to_base = np.nancumsum(input_array[::-1], dtype=np.float64)\n",
    "    return cdisp_ref_to_base[::-1]\n",
    "\n",
    "\n",
    "# -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n",
    "def numeric_depth(input_array):\n",
    "    string_to_num = [eval(ele.split(\"_\")[-1].split(\"m\")[0]) for ele in input_array]\n",
    "    round_num = np.round(string_to_num, 3)\n",
    "    return round_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf5a9a3-36aa-49ed-aea5-4214a653963c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_dir = r\"E:\\SUBSIDENCE_PROJECT_DATA\\地陷資料整理\\地陷井\\監測井_資料清理結果\"\n",
    "\n",
    "# Retrieve all well data file paths\n",
    "data_fpath = glob(os.path.join(data_dir, \"*.xz\"))\n",
    "\n",
    "all_mlcw_station = []\n",
    "\n",
    "# select_fpath = data_fpath[5]\n",
    "# select_fpath = r\"E:\\SUBSIDENCE_PROJECT_DATA\\地陷資料整理\\地陷井\\監測井_資料清理結果\\僑義.xz\"\n",
    "\n",
    "# Loop through each well data file for processing.\n",
    "for select_fpath in tqdm(data_fpath):\n",
    "\n",
    "    # Extract the basename of the file without the extension (e.g., \"僑義\").\n",
    "    basename = os.path.basename(select_fpath).split(\".\")[0]\n",
    "\n",
    "    # Convert the Chinese basename to its pinyin equivalent and convert it to uppercase.\n",
    "    # This is useful for creating standard, readable identifiers.\n",
    "    ename = pinyin.get(basename, format=\"strip\").upper()\n",
    "\n",
    "    # Read the well data from the .xz file using pandas, resulting in a DataFrame.\n",
    "    well_df = pd.read_pickle(select_fpath)\n",
    "    # Ensure the index (date) of the DataFrame is in datetime format for time-based operations.\n",
    "    well_df.index = pd.to_datetime(well_df.index)\n",
    "\n",
    "    # Calculate differences between adjacent columns (dates) to assess daily changes in measurements.\n",
    "    # This step is essential to determine the deformation or compaction over time.\n",
    "    column_diffs = well_df.diff(axis=1)\n",
    "    # Preserve the first column of original values as there is no prior measurement for comparison.\n",
    "    column_diffs.iloc[:, 0] = well_df.iloc[:, 0]\n",
    "\n",
    "    # Fill any missing values (NaN) in the DataFrame by carrying the last valid observation forward.\n",
    "    # This ensures that gaps in data do not disrupt subsequent analysis.\n",
    "    filled_diffs = column_diffs.fillna(axis=0, method=\"ffill\")\n",
    "\n",
    "    # Differential values relative to the first measurement.\n",
    "    # This uses a custom function `differ_to_ref` to convert measurements relative to the initial date.\n",
    "    # It adjusts values to show changes from the initial state of each time series.\n",
    "    diffs_ref2first_transposed = filled_diffs.apply(lambda x: differ_to_ref(x), axis=0).transpose()\n",
    "\n",
    "    ## Cumulative Compaction Calculation ##\n",
    "    # Calculate cumulative compaction from the bottom of the well upwards.\n",
    "    # Uses a custom function `cdisp_from_base` to sum deformations from the base to the top.\n",
    "    cdisp_ref2base = diffs_ref2first_transposed.apply(cdisp_from_base, axis=\"index\")\n",
    "\n",
    "    # Convert the column names (which are datetime objects) into string format (e.g., \"Nyyyymmdd\").\n",
    "    # This is useful for later stages where the date format needs to be uniform and readable.\n",
    "    cdisp_ref2base.columns = [datetime_handle.datetime_to_string(x) for x in cdisp_ref2base.columns]\n",
    "\n",
    "    # Reset the index to include depth as a column in the DataFrame.\n",
    "    # Rename the index column to \"Depth\" for clarity.\n",
    "    cdisp_ref2base_final = cdisp_ref2base.reset_index(drop=False).rename({\"index\": \"Depth\"}, axis=1)\n",
    "\n",
    "    # Convert the \"Depth\" column values to numeric format (e.g., floats) for further calculations.\n",
    "    mlcw_depth_arr = numeric_depth(cdisp_ref2base_final[\"Depth\"].tolist())\n",
    "\n",
    "    # Extract the date values (strings) for each measurement.\n",
    "    # Assumes dates in columns start with \"N\", indicating a specific date format.\n",
    "    mlcw_datetime_arr = [col[1:] for col in cdisp_ref2base.columns if col.startswith(\"N\")]\n",
    "\n",
    "    # Prepare a dictionary structure to store processed well data for easy access.\n",
    "    station_data = {\n",
    "        ename: {\n",
    "            \"values\": {\"col_diff\": column_diffs.transpose().to_numpy(), \"ref2base\": cdisp_ref2base.to_numpy()},\n",
    "            \"date\": mlcw_datetime_arr,\n",
    "            \"depth\": mlcw_depth_arr,\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Append the processed data for the current well to the main list.\n",
    "    all_mlcw_station.append(station_data)\n",
    "# -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n",
    "all_mlcw_station_ddict = gwatertools.merge_dicts(*all_mlcw_station)\n",
    "# -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n",
    "today_string = datetime.now().strftime(\"%Y%m%d\")\n",
    "\n",
    "# Write updated data and metadata back to the HDF5 file\n",
    "with h5py.File(f\"{today_string}_MLCW_CRFP.h5\", \"w\") as hdf5_file:\n",
    "    # gwatertools.h5pytools.metadata_to_hdf5(hdf5_file, updated_metadata_dict)\n",
    "    gwatertools.h5pytools.data_to_hdf5(hdf5_file, all_mlcw_station_ddict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0fc965-13f4-417f-b78d-2a39f1aadce3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T03:08:43.372270Z",
     "iopub.status.busy": "2024-10-22T03:08:43.371738Z",
     "iopub.status.idle": "2024-10-22T03:08:43.375969Z",
     "shell.execute_reply": "2024-10-22T03:08:43.375452Z",
     "shell.execute_reply.started": "2024-10-22T03:08:43.372270Z"
    }
   },
   "source": [
    "#### PART 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5fb587-5d78-40fb-b3f5-3a4380e63030",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metadata_fpath = r\"E:\\SUBSIDENCE_PROJECT_DATA\\地陷資料整理\\地陷井\\well_meta.xlsx\"\n",
    "\n",
    "df = pd.read_excel(metadata_fpath)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b478d8fd-5062-4c85-96fd-9592a0e4e52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_columns = [\n",
    "    \"CountyName\",\n",
    "    \"GroundWaterZoneCode\",\n",
    "    \"GroundWaterZoneName\",\n",
    "    \"LandSubsidenceMonitoringWellIdentifier\",\n",
    "    \"LandSubsidenceMonitoringWellName\",\n",
    "    \"LocationByWGS84_Latitude\",\n",
    "    \"LocationByWGS84_Longitude\",\n",
    "    \"SetTime\",\n",
    "    \"TownName\",\n",
    "    \"檔案名稱\",\n",
    "    \"表格對照\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3b7c75-9de5-42ab-9dcf-772ae12d446d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n",
    "all_mlcw_station = []\n",
    "# -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n",
    "all_mlcw_station.append(\n",
    "    {\n",
    "        \"Description\": \"\"\"2024/10/22: Convert MLCW data into HDF5 format along with well's metadata. `col_diff`: differential values between rings to isolate the measurements of each single ring. `ref2base`: cumulative compaction reference to the base of the well\"\"\"\n",
    "    }\n",
    ")\n",
    "# -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n",
    "\n",
    "data_dir = r\"E:\\SUBSIDENCE_PROJECT_DATA\\地陷資料整理\\地陷井\\監測井_資料清理結果\"\n",
    "\n",
    "# Retrieve all well data file paths\n",
    "data_fpath = glob(os.path.join(data_dir, \"*.xz\"))\n",
    "\n",
    "# select_fpath = data_fpath[5]\n",
    "\n",
    "for select_fpath in tqdm(data_fpath):\n",
    "    basename = os.path.basename(select_fpath).split(\".\")[0]\n",
    "    ename = pinyin.get(basename, format=\"strip\").upper()\n",
    "\n",
    "    df_byBaseName = df.query(\"檔案名稱==@basename\").loc[:, select_columns].reset_index()\n",
    "\n",
    "    if len(df_byBaseName) > 0:\n",
    "\n",
    "        extract_data_byBaseName = df_byBaseName.to_dict()\n",
    "        # Extracting the data for index 20\n",
    "        ddict_byBaseName = {key: value[0] for key, value in extract_data_byBaseName.items()}\n",
    "\n",
    "        del ddict_byBaseName[\"index\"]\n",
    "\n",
    "        all_mlcw_station.append({ename: ddict_byBaseName})\n",
    "    else:\n",
    "        print(select_fpath)\n",
    "\n",
    "# -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n",
    "all_mlcw_station_metadata = gwatertools.merge_dicts(*all_mlcw_station)\n",
    "# -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n",
    "gwl_hdf5_file = r\"20241022_MLCW_CRFP.h5\"\n",
    "# Extract existing data and metadata\n",
    "with h5py.File(gwl_hdf5_file, \"r\") as hdf5_file:\n",
    "    existing_data_dict = gwatertools.h5pytools.hdf5_to_data_dict(hdf5_file)\n",
    "    existing_metadata_dict = gwatertools.h5pytools.hdf5_to_metadata_dict(hdf5_file)\n",
    "# -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n",
    "updated_metadata_dict = gwatertools.h5pytools.update_metadata_dict(existing_metadata_dict, all_mlcw_station_metadata)\n",
    "# -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n",
    "today_string = datetime.now().strftime(\"%Y%m%d\")\n",
    "\n",
    "# Write updated data and metadata back to the HDF5 file\n",
    "with h5py.File(f\"{today_string}_MLCW_CRFP_v2.h5\", \"w\") as hdf5_file:\n",
    "    gwatertools.h5pytools.metadata_to_hdf5(hdf5_file, updated_metadata_dict)\n",
    "    gwatertools.h5pytools.data_to_hdf5(hdf5_file, existing_data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157ec768-701f-415c-a97e-eae6a4f60d36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
