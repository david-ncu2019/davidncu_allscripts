{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aefa2301-b375-4fd2-8261-0879fbd70c79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T09:38:24.503966Z",
     "iopub.status.busy": "2024-08-31T09:38:24.503966Z",
     "iopub.status.idle": "2024-08-31T09:38:26.956953Z",
     "shell.execute_reply": "2024-08-31T09:38:26.956953Z",
     "shell.execute_reply.started": "2024-08-31T09:38:24.503966Z"
    }
   },
   "outputs": [],
   "source": [
    "from appgeopy import *\n",
    "from my_packages import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "453c77a3-67ad-42b2-8d99-1805ab5dc5fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T09:38:26.958955Z",
     "iopub.status.busy": "2024-08-31T09:38:26.957953Z",
     "iopub.status.idle": "2024-08-31T09:38:26.962140Z",
     "shell.execute_reply": "2024-08-31T09:38:26.962017Z",
     "shell.execute_reply.started": "2024-08-31T09:38:26.958955Z"
    }
   },
   "outputs": [],
   "source": [
    "def dataset_to_series(hdf5_file, dataset, time_idx):\n",
    "    with h5py.File(hdf5_file, \"r\") as f:\n",
    "        array = f[dataset][...]\n",
    "        series = pd.Series(data=array, index=time_idx)\n",
    "    start = series.first_valid_index()\n",
    "    end = series.last_valid_index()\n",
    "    return series[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e74b293-821c-43ce-819a-d350f1fa8863",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T09:38:26.963997Z",
     "iopub.status.busy": "2024-08-31T09:38:26.963997Z",
     "iopub.status.idle": "2024-08-31T09:38:27.087882Z",
     "shell.execute_reply": "2024-08-31T09:38:27.087882Z",
     "shell.execute_reply.started": "2024-08-31T09:38:26.963997Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ANHE', 'ANNAN', 'BEIGANG', 'BOZI', 'CAICUO']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gwl_hdf5_file = \"20240828_GWL_CRFP_model.h5\"\n",
    "\n",
    "# List available datasets in the HDF5 file for reference\n",
    "with h5py.File(gwl_hdf5_file, \"r\") as hdf5_file:\n",
    "    # _____________________________________________\n",
    "    # Filter datasets that contain \"model\" in their name\n",
    "    available_datasets = [\n",
    "        elem\n",
    "        for elem in gwatertools.h5pytools.list_datasets(hdf5_file)\n",
    "        if \"model\" in elem\n",
    "    ]\n",
    "    # _____________________________________________\n",
    "    # Find active datasets based on the 'Status' attribute\n",
    "    active_datasets = []\n",
    "    for dataset in available_datasets:\n",
    "        datagroup = \"/\".join(dataset.split(\"/\")[:2])\n",
    "        if hdf5_file[datagroup].attrs.get(\"Status\") == \"Active\":\n",
    "            active_datasets.append(dataset)\n",
    "    # _____________________________________________\n",
    "    # Get the datetime index from the 'date' dataset\n",
    "    datetime_idx = pd.to_datetime(hdf5_file[\"date\"][...], format=\"%Y%m%d\")\n",
    "\n",
    "# Extract the station names from available datasets, ensuring unique and sorted values\n",
    "available_stations = sorted(\n",
    "    {dataset.split(\"/\")[0] for dataset in active_datasets}\n",
    ")\n",
    "\n",
    "# Display the first five available stations\n",
    "available_stations[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "929f2c1a-735f-47ae-b315-1fae0918417a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T09:38:27.089881Z",
     "iopub.status.busy": "2024-08-31T09:38:27.088880Z",
     "iopub.status.idle": "2024-08-31T09:38:45.593667Z",
     "shell.execute_reply": "2024-08-31T09:38:45.593667Z",
     "shell.execute_reply.started": "2024-08-31T09:38:27.089881Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 238/238 [00:18<00:00, 12.87it/s]\n"
     ]
    }
   ],
   "source": [
    "all_measurement_data = {station: {} for station in available_stations}\n",
    "\n",
    "for select_dataset in tqdm(active_datasets):\n",
    "    # Extract station and wellcode from dataset path\n",
    "    station, wellcode, *_ = select_dataset.split(\"/\")\n",
    "\n",
    "    # Convert dataset to a pandas Series\n",
    "    model_gwl_series = dataset_to_series(\n",
    "        hdf5_file=gwl_hdf5_file, dataset=select_dataset, time_idx=datetime_idx\n",
    "    )\n",
    "\n",
    "    # Initialize peak and trough caches within a single structure\n",
    "    cache = {\n",
    "        \"peaks\": {\"date\": [], \"value\": []},\n",
    "        \"troughs\": {\"date\": [], \"value\": []},\n",
    "    }\n",
    "\n",
    "    # Process each unique year in the model_gwl_series\n",
    "    for year in model_gwl_series.index.year.unique():\n",
    "        select_by_year = model_gwl_series.loc[str(year)]\n",
    "        peaks, troughs = analysis.find_peaks_troughs(select_by_year)\n",
    "\n",
    "        # Use len() to check if peaks and troughs are non-empty\n",
    "        if len(peaks) > 0 and len(troughs) > 0:\n",
    "            temp = analysis.find_peak_to_peak(\n",
    "                data=select_by_year, peak_idx=peaks, trough_idx=troughs\n",
    "            )\n",
    "\n",
    "            # Store peak data\n",
    "            cache[\"peaks\"][\"date\"].append(\n",
    "                temp.idxmax().iloc[0].strftime(\"%Y%m%d\")\n",
    "            )\n",
    "            cache[\"peaks\"][\"value\"].append(temp.max().iloc[0])\n",
    "\n",
    "            # Store trough data\n",
    "            cache[\"troughs\"][\"date\"].append(\n",
    "                temp.idxmin().iloc[0].strftime(\"%Y%m%d\")\n",
    "            )\n",
    "            cache[\"troughs\"][\"value\"].append(temp.min().iloc[0])\n",
    "\n",
    "    # Store results in the all_measurement_data structure\n",
    "    all_measurement_data[station][wellcode] = cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4fa20b4-d4b8-4510-aba0-e51b256a28bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T09:38:45.595668Z",
     "iopub.status.busy": "2024-08-31T09:38:45.594665Z",
     "iopub.status.idle": "2024-08-31T09:38:46.725204Z",
     "shell.execute_reply": "2024-08-31T09:38:46.724203Z",
     "shell.execute_reply.started": "2024-08-31T09:38:45.595668Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'appgeopy.gwatertools.h5pytools' has no attribute 'h5py_to_data_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Extract existing data and metadata\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m h5py\u001b[38;5;241m.\u001b[39mFile(gwl_hdf5_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m hdf5_file:\n\u001b[1;32m----> 6\u001b[0m     existing_data_dict \u001b[38;5;241m=\u001b[39m \u001b[43mgwatertools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mh5pytools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mh5py_to_data_dict\u001b[49m(hdf5_file)\n\u001b[0;32m      7\u001b[0m     existing_metadata_dict \u001b[38;5;241m=\u001b[39m gwatertools\u001b[38;5;241m.\u001b[39mh5pytools\u001b[38;5;241m.\u001b[39mh5py_to_metadata_dict(\n\u001b[0;32m      8\u001b[0m         hdf5_file\n\u001b[0;32m      9\u001b[0m     )\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Update dictionaries with new measurement data\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'appgeopy.gwatertools.h5pytools' has no attribute 'h5py_to_data_dict'"
     ]
    }
   ],
   "source": [
    "# Copy the original HDF5 file to a secure version\n",
    "shutil.copy2(src=gwl_hdf5_file, dst=gwl_hdf5_file.replace(\".h5\", \"_secure.h5\"))\n",
    "\n",
    "# Extract existing data and metadata\n",
    "with h5py.File(gwl_hdf5_file, \"r\") as hdf5_file:\n",
    "    existing_data_dict = gwatertools.h5pytools.hdf5_to_data_dict(hdf5_file)\n",
    "    existing_metadata_dict = gwatertools.h5pytools.hdf5_to_metadata_dict(\n",
    "        hdf5_file\n",
    "    )\n",
    "\n",
    "# Update dictionaries with new measurement data\n",
    "updated_data_dict = gwatertools.h5pytools.update_data_dict(\n",
    "    existing_data_dict, all_measurement_data\n",
    ")\n",
    "\n",
    "# Write updated data and metadata back to a new HDF5 file\n",
    "output_file_name = f\"{datetime.now().strftime('%Y%m%d')}_GWL_CRFP.h5\"\n",
    "with h5py.File(output_file_name, \"w\") as hdf5_file:\n",
    "    gwatertools.h5pytools.metadata_to_hdf5(hdf5_file, existing_metadata_dict)\n",
    "    gwatertools.h5pytools.data_to_hdf5(hdf5_file, updated_data_dict)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cd09d1d9-26bb-4da3-8ca2-554f4b0bb230",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T16:05:41.752847Z",
     "iopub.status.busy": "2024-08-30T16:05:41.752847Z",
     "iopub.status.idle": "2024-08-30T16:05:41.958805Z",
     "shell.execute_reply": "2024-08-30T16:05:41.958805Z",
     "shell.execute_reply.started": "2024-08-30T16:05:41.752847Z"
    }
   },
   "source": [
    "a = pd.DataFrame(all_measurement_data[\"ANHE\"][\"10070131\"][\"peaks\"])\n",
    "b = pd.DataFrame(all_measurement_data[\"ANHE\"][\"10070131\"][\"troughs\"])\n",
    "a['date'] = pd.to_datetime(a['date'])\n",
    "b['date'] = pd.to_datetime(b['date'])\n",
    "a = a.set_index('date')\n",
    "b = b.set_index('date')\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "model_gwl_series.plot(ax=ax)\n",
    "a.plot(marker='o', linestyle=' ', ax=ax)\n",
    "b.plot(marker='o', linestyle=' ', ax=ax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
