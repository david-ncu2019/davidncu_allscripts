{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e46d1a99-f7d5-45c8-a921-44cb1ac3382a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "from appgeopy import *\n",
    "from my_packages import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8b05b8f-51b6-46cd-92e3-038896835117",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_nscore(df, idx_column=\"STATION\", transformation_columns=None):\n",
    "    \"\"\"\n",
    "    Applies normal score transformation to specified columns in the input DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "      df (pd.DataFrame): Input data frame.\n",
    "      idx_column (str): Name of the unique identifier column (default: \"STATION\").\n",
    "      transformation_columns (list of str): List of column names to transform.\n",
    "          If None, all columns except the idx_column are used.\n",
    "\n",
    "    Returns:\n",
    "      pd.DataFrame: A new DataFrame containing the original identifier and the new\n",
    "          transformed columns, each prefixed with 'Trans_'.\n",
    "\n",
    "    Structural Rules for the Input DataFrame:\n",
    "      1. Must include a unique identifier column (default name: \"STATION\") that uniquely\n",
    "         identifies each record.\n",
    "      2. Must contain one or more numeric columns that are to be transformed.\n",
    "      3. Any additional columns (meta-data) are preserved as is.\n",
    "      4. If transformation_columns is not provided, all columns except the idx_column will\n",
    "         be considered for transformation.\n",
    "    \"\"\"\n",
    "    # Validate that the required identifier column exists\n",
    "    if idx_column not in df.columns:\n",
    "        raise ValueError(\n",
    "            f\"Input DataFrame must contain the '{idx_column}' column as a unique identifier.\"\n",
    "        )\n",
    "\n",
    "    # Determine columns to transform if not explicitly provided\n",
    "    if transformation_columns is None:\n",
    "        transformation_columns = [\n",
    "            col for col in df.columns if col != idx_column\n",
    "        ]\n",
    "\n",
    "    # Create a copy to work on; use idx_column as index for mapping transformation results\n",
    "    output_df = df.loc[:, ~df.columns.isin(transformation_columns)].copy()\n",
    "    output_df.set_index(idx_column, inplace=True)\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    # Significant change: Refactored loop to process each transformation column generically\n",
    "    # --------------------------------------------------------------------------\n",
    "    for col in tqdm(transformation_columns):\n",
    "        try:\n",
    "            # Create a temporary DataFrame for the current column\n",
    "            temp = df[[idx_column, col]].dropna(subset=[col]).copy()\n",
    "\n",
    "            # Apply normal score transformation\n",
    "            # The new transformed column is prefixed with 'Trans_'\n",
    "            transformed_col = \"Trans_\" + col\n",
    "            temp[transformed_col], tvDisp, tnsDisp = geostats.nscore(temp, col)\n",
    "\n",
    "            # Filter out outliers outside the acceptable range [-3, 3]\n",
    "            filter_cond = (temp[transformed_col] >= -3) & (\n",
    "                temp[transformed_col] <= 3\n",
    "            )\n",
    "            temp = temp[filter_cond]\n",
    "            temp.set_index(idx_column, inplace=True)\n",
    "\n",
    "            # Map the transformed values back to the output DataFrame using the identifier\n",
    "            output_df[transformed_col] = output_df.index.map(\n",
    "                temp[transformed_col]\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing column '{col}': {e}\")\n",
    "            continue\n",
    "\n",
    "    # Reset index so that the identifier becomes a column again\n",
    "    output_df.reset_index(inplace=True)\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ac7001-c46f-4c3a-981c-260455b5fa91",
   "metadata": {},
   "source": [
    "#### Monthly dU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f5822d0-c8cd-46df-a563-0e3f9f7073eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88652df1b5ba44e9891588ff464713b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpath = \"CORRECTED_Monthly_DISPLACEMENT_CRFP_saveqgis_Oct2025.xz\"\n",
    "basename = os.path.basename(fpath).split(\".\")[0]\n",
    "df = pd.read_pickle(fpath)\n",
    "df = df.reset_index(drop=False)\n",
    "trans_cols = [col for col in df.columns if col.startswith(\"N\")]\n",
    "transformed_df = apply_nscore(\n",
    "    df=df, idx_column=\"PointKey\", transformation_columns=trans_cols\n",
    ")\n",
    "# transformed_df.to_csv(f\"2_Transformed/NSCORE_{basename.replace(\".xz\", \".csv\")}\", index=False)\n",
    "\n",
    "# with open(f\"2_Transformed/NSCORE_{basename}\", \"wb\") as f:\n",
    "#     pickle.dump(transformed_df.to_dict(), f, protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b3ed0e7-2bbb-49a7-aa23-12d2b42fc465",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_chunks = 30\n",
    "\n",
    "# Split the output DataFrame into 10 equally sized chunks.\n",
    "chunks = np.array_split(transformed_df, number_of_chunks)\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    out_path = f\"2_Transformed/NSCORE_{basename}_{str(i+1).zfill(3)}.xz\"\n",
    "    with open(out_path, \"wb\") as f:\n",
    "        pickle.dump(chunk.to_dict(), f, protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630ee50c-2b67-4d1e-8311-d86023f51dce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "34e6845c40864164b6a5909fe7c866d0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "69ca8dd0f8034e7c80c0f99b77bd8c35": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "832b2f7c7f0140c6851facccba245497": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_69ca8dd0f8034e7c80c0f99b77bd8c35",
       "max": 112,
       "style": "IPY_MODEL_fe52e06f4ca64554a769e485bde19109",
       "value": 112
      }
     },
     "88652df1b5ba44e9891588ff464713b1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_f0a6b5bd659c4978b7c0de84cb323ad8",
        "IPY_MODEL_832b2f7c7f0140c6851facccba245497",
        "IPY_MODEL_98afba309b4140a4917f64e1db5097f0"
       ],
       "layout": "IPY_MODEL_fe36d5aa4a944add8dc4dd7364bfe5ea"
      }
     },
     "92fc7a8e242e4cbc97333063ebb2cc8f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "98afba309b4140a4917f64e1db5097f0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_34e6845c40864164b6a5909fe7c866d0",
       "style": "IPY_MODEL_ae62d3cbb6254150b6c4503a4d8e1bb8",
       "value": " 112/112 [11:53&lt;00:00,  6.50s/it]"
      }
     },
     "ae62d3cbb6254150b6c4503a4d8e1bb8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "cb9abc48c4214d468425cc00e21fdd0f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f0a6b5bd659c4978b7c0de84cb323ad8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_92fc7a8e242e4cbc97333063ebb2cc8f",
       "style": "IPY_MODEL_cb9abc48c4214d468425cc00e21fdd0f",
       "value": "100%"
      }
     },
     "fe36d5aa4a944add8dc4dd7364bfe5ea": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "fe52e06f4ca64554a769e485bde19109": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
