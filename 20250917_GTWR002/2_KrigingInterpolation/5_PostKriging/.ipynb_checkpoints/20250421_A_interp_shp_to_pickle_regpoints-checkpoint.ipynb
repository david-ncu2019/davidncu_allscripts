{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35a85ed8-046e-4bbe-9725-2bc0ab2b1391",
   "metadata": {},
   "source": [
    "| Component | Description | Shape | Type | Example | Notes |\n",
    "|-----------|-------------|-------|------|---------|-------|\n",
    "| `coords` | Spatial coordinates | n × 2 | numpy array or pandas DataFrame | `[[x₁,y₁], [x₂,y₂], ..., [xₙ,yₙ]]` | First column usually longitude, second latitude |\n",
    "| `t` | Time coordinates | n × 1 | numpy array | `[[t₁], [t₂], ..., [tₙ]]` | Could be year, day, or any time unit |\n",
    "| `X` | Independent variables | n × k | numpy array or pandas DataFrame | `[[x₁₁, x₁₂, ..., x₁ₖ], ..., [xₙ₁, xₙ₂, ..., xₙₖ]]` | Each column represents one variable |\n",
    "| `y` | Dependent variable | n × 1 | numpy array, pandas DataFrame, or Series | `[[y₁], [y₂], ..., [yₙ]]` | Target variable being modeled |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d500003-6570-408c-81de-ccea26056c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from appgeopy import *\n",
    "from my_packages import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0b1b3a-a82d-4182-852a-ee227a828a57",
   "metadata": {},
   "source": [
    "#### Extract predicted values from output shapefiles and save to pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1784c903-c658-4613-8cf4-c5233e48205b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\1000_SCRIPTS\\\\003_Project002\\\\20250917_GTWR002\\\\2_KrigingInterpolation\\\\4_Interpolation\\\\001\\\\NSCORE_CORRECTED_Monthly_DISPLACEMENT_CRFP_saveqgis_Oct2025',\n",
       " 'D:\\\\1000_SCRIPTS\\\\003_Project002\\\\20250917_GTWR002\\\\2_KrigingInterpolation\\\\4_Interpolation\\\\002\\\\NSCORE_Monthly_DISPLACEMENT_dU_CRFP_2025_Full']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kriging_interp_fld = r\"D:\\1000_SCRIPTS\\003_Project002\\20250917_GTWR002\\2_KrigingInterpolation\\4_Interpolation\"\n",
    "target_flds = [f.path for f in os.scandir(kriging_interp_fld) if f.is_dir()]\n",
    "subflds = [f.path for fld in target_flds for f in os.scandir(fld) if f.is_dir()]\n",
    "subflds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "394f4d86-fcad-4b96-bd03-d3139a063355",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shapefiles(select_fld, fld_type=\"Validation\", point_type=\"grid\"):\n",
    "    points_fld = [\n",
    "        f\n",
    "        for f in glob(os.path.join(select_fld, f\"*{fld_type}*{point_type}*\"))\n",
    "        if os.path.isdir(f)\n",
    "    ][0]\n",
    "    points_shp = glob(os.path.join(points_fld, \"*.shp\"))\n",
    "    return points_shp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7986de-569b-435a-b5ce-9fefae7a41fb",
   "metadata": {},
   "source": [
    "**2025/4/21**\n",
    "\n",
    "This code is used to extract the interpolated transformed values at grid points"
   ]
  },
  {
   "cell_type": "raw",
   "id": "02a675bd-4669-46f4-9237-b1d433995dbb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# select_fld = subflds[0]\n",
    "for select_fld in tqdm(subflds[-1:]):\n",
    "    try:\n",
    "        fld_basename = os.path.basename(select_fld)\n",
    "        points_shp = get_shapefiles(\n",
    "            select_fld, fld_type=\"Points\", point_type=\"grid\"\n",
    "        )\n",
    "        # combined_df = pd.DataFrame(data=None)\n",
    "        print(\"\\n\\n\", fld_basename)\n",
    "\n",
    "        for i in range(len(points_shp)):\n",
    "            # for i in range(5):\n",
    "            select_shp = points_shp[i]\n",
    "\n",
    "            shp_basename = os.path.basename(select_shp).split(\".\")[0]\n",
    "            extract_datetime = shp_basename.split(\"_\")[-1]\n",
    "\n",
    "            select_shp_gdf = gpd.read_file(select_shp, read_geometry=True)\n",
    "            output_shp_gdf = select_shp_gdf.loc[\n",
    "                :,\n",
    "                [  # \"STATION\",\n",
    "                    # \"LandSubsid\",\n",
    "                    \"POINT_X\",\n",
    "                    \"POINT_Y\",\n",
    "                    \"Predicted\",\n",
    "                ],\n",
    "            ].copy()\n",
    "            output_shp_gdf = output_shp_gdf.rename(\n",
    "                {\n",
    "                    # \"LandSubsid\": \"WellCode\",\n",
    "                    \"POINT_X\": \"X_TWD97\",\n",
    "                    \"POINT_Y\": \"Y_TWD97\",\n",
    "                    \"Predicted\": extract_datetime,\n",
    "                },\n",
    "                axis=1,\n",
    "            )\n",
    "            # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "            # 2025/4/21: add PointKey column, converted from meters to milimeters\n",
    "            # to make sure the PointKey is unique\n",
    "            # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "            pointkey = [\n",
    "                f\"X{int(x_twd97*1000)}Y{int(y_twd97*1000)}\"\n",
    "                for x_twd97, y_twd97 in zip(\n",
    "                    output_shp_gdf[\"X_TWD97\"], output_shp_gdf[\"Y_TWD97\"]\n",
    "                )\n",
    "            ]\n",
    "            output_shp_gdf.insert(loc=0, column=\"PointKey\", value=pointkey)\n",
    "\n",
    "            if i == 0:\n",
    "                combined_df = output_shp_gdf.copy()\n",
    "                combined_df = combined_df.set_index(\"PointKey\")\n",
    "            else:\n",
    "                output_shp_gdf = output_shp_gdf.set_index(\"PointKey\")\n",
    "                combined_df[extract_datetime] = combined_df.index.map(\n",
    "                    output_shp_gdf[extract_datetime]\n",
    "                )\n",
    "\n",
    "        combined_df.to_pickle(f\"{fld_basename}.xz\")\n",
    "    except Exception as e:\n",
    "        print(extract_datetime)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae339b4-31ec-472d-a6fe-f719542172f7",
   "metadata": {},
   "source": [
    "**Single-run Process**\n",
    "\n",
    "Run this one because I have only one folder to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ea63f83-9a11-4e6e-a3cb-5243363b16cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc76e826a8354d588f3812f58eb3d8cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2025/09/20\n",
    "# Run this one because I have only one folder to process\n",
    "\n",
    "# select_fld = r\"D:\\1000_SCRIPTS\\003_Project002\\20250222_GTWR001\\2_KrigingInterpolation\\4_Interpolation\\003\\NSCORE_Monthly_DISPLACEMENT_dU_CRFP_Full\"\n",
    "\n",
    "select_fld = r\"D:\\1000_SCRIPTS\\003_Project002\\20250917_GTWR002\\2_KrigingInterpolation\\4_Interpolation\\001\\NSCORE_CORRECTED_Monthly_DISPLACEMENT_CRFP_saveqgis_Oct2025\"\n",
    "\n",
    "point_type = \"mlcw\"  # point_type=\"grid\" or \"mlcw\"\n",
    "fld_basename = os.path.basename(select_fld)\n",
    "points_shp = get_shapefiles(\n",
    "    select_fld, fld_type=\"Points\", point_type=point_type\n",
    ")\n",
    "# combined_df = pd.DataFrame(data=None)\n",
    "\n",
    "for i in trange(len(points_shp)):\n",
    "    try:\n",
    "        # for i in range(5):\n",
    "        select_shp = points_shp[i]\n",
    "\n",
    "        shp_basename = os.path.basename(select_shp).split(\".\")[0]\n",
    "        extract_datetime = shp_basename.split(\"_\")[-1]\n",
    "\n",
    "        select_shp_gdf = gpd.read_file(select_shp, read_geometry=True)\n",
    "        output_shp_gdf = select_shp_gdf.loc[\n",
    "            :,\n",
    "            [  # \"STATION\",\n",
    "                # \"LandSubsid\",\n",
    "                \"POINT_X\",\n",
    "                \"POINT_Y\",\n",
    "                \"Predicted\",\n",
    "            ],\n",
    "        ].copy()\n",
    "\n",
    "        output_shp_gdf = output_shp_gdf.rename(\n",
    "            {\n",
    "                # \"LandSubsid\": \"WellCode\",\n",
    "                \"POINT_X\": \"X_TWD97\",\n",
    "                \"POINT_Y\": \"Y_TWD97\",\n",
    "                \"Predicted\": extract_datetime,\n",
    "            },\n",
    "            axis=1,\n",
    "        )\n",
    "        # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "        # 2025/4/21: add PointKey column, converted from meters to milimeters\n",
    "        # to make sure the PointKey is unique\n",
    "        # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "        pointkey = [\n",
    "            f\"X{int(x_twd97*1000)}Y{int(y_twd97*1000)}\"\n",
    "            for x_twd97, y_twd97 in zip(\n",
    "                output_shp_gdf[\"X_TWD97\"], output_shp_gdf[\"Y_TWD97\"]\n",
    "            )\n",
    "        ]\n",
    "        output_shp_gdf.insert(loc=0, column=\"PointKey\", value=pointkey)\n",
    "\n",
    "        if i == 0:\n",
    "            combined_df = output_shp_gdf.copy()\n",
    "            combined_df = combined_df.set_index(\"PointKey\")\n",
    "        else:\n",
    "            output_shp_gdf = output_shp_gdf.set_index(\"PointKey\")\n",
    "            combined_df[extract_datetime] = combined_df.index.map(\n",
    "                output_shp_gdf[extract_datetime]\n",
    "            )\n",
    "    except Exception as e:\n",
    "        print(os.path.basename(select_shp))\n",
    "        pass\n",
    "\n",
    "# combined_df.to_pickle(f\"{fld_basename}_{point_type}.xz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed6e3d0d-0488-49db-b0ca-60cac6ca0cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in combined_df.columns:\n",
    "    temp = combined_df[col].isnull().unique()\n",
    "    temp2 = (combined_df[col] == 0).unique()\n",
    "    if len(temp) > 1 or len(temp2) > 1:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "896f5735-fa7d-4fbe-8ffc-64d3c2f91a0d",
   "metadata": {},
   "source": [
    "# check empty column\n",
    "df = pd.read_pickle(r\"NSCORE_Monthly_DISPLACEMENT_dU_mlcw.xz\")\n",
    "for col in df.columns:\n",
    "    if not np.isfinite(df[col].mean()):\n",
    "        print(col)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
