{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "601e6f0a-6b56-4341-98f0-f043aec57be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from appgeopy import *\n",
    "from my_packages import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db293cd-e913-4ba4-96d4-a98fb2ba8213",
   "metadata": {},
   "source": [
    "# 2025/10/24\n",
    "\n",
    "After successfully model the `diff. disp.` relationship between MLCW and InSAR using GWR,\n",
    "we try to test if we can predict the future `diff. disp.` based on the timeseries of $\\beta_{1}$ and $\\beta_{0}$\n",
    "\n",
    "Work flow:\n",
    "\n",
    "1. Values of `diff. disp.` from MLCW in 2023 - 2024 to validate (get it from `GTWR` input files)\n",
    "2. Values of `diff. disp.` from InSAR in 2023 - 2024 to calculate the predicted values (get it from `GTWR` input files as well)\n",
    "3. Filter the stations with available MLCW values in 2023 - 2024\n",
    "4. `Approach 1`: Get the average and stdev of coefficient & intercept --> perform prediction\n",
    "5. `Approach 2`: Model the signal of coefficient & intercept with SARIMAX --> perform prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786095b7-ec2c-478c-82cf-ae2811d8e4de",
   "metadata": {},
   "source": [
    "#### Preparation\n",
    "\n",
    "Prepare the diff. disp. value for 2023 - 2024 period"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9b3f2d9a-7667-41c9-b676-f0ad014e8b8f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# Prepare the diff. disp. value for 2023 - 2024 period\n",
    "# We will borrow the prepared regpoints from GTWR input\n",
    "\n",
    "folder = r\"D:\\1000_SCRIPTS\\003_Project002\\20250917_GTWR002\\4_MainRun\\reg_input\"\n",
    "files = glob(os.path.join(folder, \"*GTWR*Layer*csv\"))\n",
    "\n",
    "# select_file = files[0]\n",
    "for select_file in tqdm(files):\n",
    "    current_layer = (\n",
    "        \"Layer_\" + os.path.basename(select_file).split(\".\")[0].split(\"_\")[-1]\n",
    "    )\n",
    "    df = pd.read_csv(select_file)\n",
    "    reg_df = df.query(\"monthly>=67\").reset_index(drop=True)\n",
    "\n",
    "    unique_stations = reg_df[\"STATION\"].unique()\n",
    "\n",
    "    combine_output = pd.DataFrame(data=None, index=None)\n",
    "\n",
    "    for station in unique_stations:\n",
    "        temp = reg_df.query(\"STATION==@station\")\n",
    "        if len(temp) > 2:\n",
    "            temp2 = temp.iloc[1:, :].copy()\n",
    "            mlcw_diffdisp = temp[current_layer].diff().dropna()\n",
    "            insar_diffdisp = temp[\"CUMDISP\"].diff().dropna()\n",
    "            temp2[current_layer] = mlcw_diffdisp\n",
    "            temp2[\"CUMDISP\"] = insar_diffdisp\n",
    "            temp2 = temp2.rename({\"CUMDISP\": \"DIFFDISP\"}, axis=1)\n",
    "            combine_output = pd.concat(\n",
    "                [combine_output, temp2], ignore_index=True\n",
    "            )\n",
    "\n",
    "        combine_output.to_csv(\n",
    "            os.path.join(\n",
    "                \"reg_diffdisp\",\n",
    "                f\"{datetime.now().strftime('%Y%m%d')}_GWR_RegPoints_DIFFDISP_{current_layer}.csv\",\n",
    "            ),\n",
    "            index=False,\n",
    "        )\n",
    "\n",
    "    # temp = reg_df.query(\"STATION=='TUKU'\")\n",
    "    # temp2 = temp.iloc[1:, :].copy()\n",
    "    # mlcw_diffdisp = temp[current_layer].diff().dropna()\n",
    "    # insar_diffdisp = temp[\"CUMDISP\"].diff().dropna()\n",
    "    # temp2[current_layer] = mlcw_diffdisp\n",
    "    # temp2[\"CUMDISP\"] = insar_diffdisp\n",
    "    # temp2 = temp2.rename({\"CUMDISP\":\"DIFFDISP\"}, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb3c65e-ccae-4d1c-9e9a-f77705f0ddc3",
   "metadata": {},
   "source": [
    "#### Approach 1\n",
    "\n",
    "Get the average and stdev of coefficient & intercept --> perform prediction"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9d8fdd53-0a6f-4b30-a201-2c5b119dd60f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "files = glob(os.path.join(\"reg_diffdisp/\", \"*csv\"))\n",
    "\n",
    "select_file = files[0]\n",
    "\n",
    "current_layer = \"_\".join(\n",
    "    os.path.basename(select_file).split(\".\")[0].split(\"_\")[-2:]\n",
    ")\n",
    "\n",
    "select_station = \"BEICHEN\"\n",
    "\n",
    "df = pd.read_csv(select_file)\n",
    "df_byStation = df.query(\"STATION==@select_station\")\n",
    "show(df_byStation)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "df08e2e0-e43d-48f0-b85d-6263254b6723",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "results_csv = glob(os.path.join(\"GWR*Output*\", \"*combined_results.csv\"))\n",
    "\n",
    "select_result = results_csv[0]\n",
    "\n",
    "result_df = pd.read_csv(select_result)\n",
    "result_df = result_df.rename({\"input_STATION\": \"STATION\"}, axis=1)\n",
    "\n",
    "result_df_byStation = result_df.query(\"STATION==@select_station\")\n",
    "show(result_df_byStation)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0ec13ab0-0a33-40c1-8b40-4ffb2c6f31b3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "from utils import *\n",
    "\n",
    "# Single station analysis\n",
    "future_timearr = pd.to_datetime(df_byStation[\"time\"])\n",
    "future_insar = df_byStation[\"DIFFDISP\"].values\n",
    "future_mlcw_obs = df_byStation[\n",
    "    current_layer\n",
    "].values  # Replace with actual column\n",
    "\n",
    "coeff_arr = result_df_byStation[\"CUMDISP\"].values\n",
    "interp_arr = result_df_byStation[\"Intercept\"].values\n",
    "\n",
    "# Predict\n",
    "pred_result = predict_disp(future_insar, coeff_arr, interp_arr)\n",
    "metrics = calc_metrics(future_mlcw_obs, pred_result[\"pred\"])\n",
    "\n",
    "# Visualize\n",
    "fig = plot_pred_vs_obs(\n",
    "    time=future_timearr,\n",
    "    x=future_insar,\n",
    "    obs=future_mlcw_obs,\n",
    "    result=pred_result,\n",
    "    station=select_station,\n",
    "    layer=current_layer,\n",
    "    metrics=metrics,\n",
    ")\n",
    "\n",
    "# Save figure\n",
    "# fig.savefig('mlcw_prediction_with_uncertainty.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "53199399-d9b4-43b0-bdd4-92c00e0f60b7",
   "metadata": {},
   "source": [
    "from utils import *\n",
    "\n",
    "files = glob(os.path.join(\"reg_diffdisp/\", \"*csv\"))\n",
    "results_csv = glob(os.path.join(\"GWR*Output*\", \"*combined_results.csv\"))\n",
    "\n",
    "\n",
    "for select_file, select_result in zip(tqdm(files[:]), results_csv):\n",
    "\n",
    "    full_df = pd.read_csv(select_file)\n",
    "\n",
    "    full_results = pd.read_csv(select_result)\n",
    "    full_results = full_results.rename({\"input_STATION\": \"STATION\"}, axis=1)\n",
    "\n",
    "    current_layer = \"_\".join(\n",
    "        os.path.basename(select_file).split(\".\")[0].split(\"_\")[-2:]\n",
    "    )\n",
    "\n",
    "    fld2savefig = os.path.join(\n",
    "        os.getcwd(), \"figs2\", f\"GWR_TemporalPrediction_{current_layer}\"\n",
    "    )\n",
    "    if not os.path.exists(fld2savefig):\n",
    "        os.makedirs(fld2savefig)\n",
    "\n",
    "    # Multi-station batch processing\n",
    "    summary_df, figs = process_stations(\n",
    "        df=full_df,\n",
    "        result_df=full_results,\n",
    "        station_col=\"STATION\",\n",
    "        time_col=\"time\",\n",
    "        insar_col=\"DIFFDISP\",\n",
    "        obs_col=current_layer,\n",
    "        coeff_col=\"CUMDISP\",\n",
    "        interp_col=\"Intercept\",\n",
    "        layer_name=current_layer.replace(\"_\", \" \"),\n",
    "    )\n",
    "\n",
    "    summary_df.to_excel(\n",
    "        os.path.join(\n",
    "            fld2savefig, f\"multi_station_summary_{current_layer}.xlsx\"\n",
    "        ),\n",
    "        index=False,\n",
    "    )\n",
    "\n",
    "    for station in figs.keys():\n",
    "        fig_byStation = figs[station]\n",
    "        savepath = os.path.join(fld2savefig, f\"{station}_{current_layer}.png\")\n",
    "        visualize.save_figure_with_exact_dimensions(\n",
    "            fig=fig_byStation,\n",
    "            savepath=savepath,\n",
    "            width_px=4950,\n",
    "            height_px=3510,\n",
    "            dpi=300,\n",
    "        )"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bff72af2-976a-4562-bf87-29d3fe841fad",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "#### EXAMPLE ERROR PROPAGATION IN LINEAR PREDICTIONS\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Example data\n",
    "x = np.array([1, 2, 3, 4, 5])\n",
    "a_values = np.array([2.1, 1.9, 2.0, 2.2, 1.8])  # Multiple slope estimates\n",
    "b_values = np.array([0.5, 0.3, 0.4, 0.6, 0.2])  # Multiple intercept estimates\n",
    "\n",
    "# Calculate means\n",
    "a_mean = np.mean(a_values)\n",
    "b_mean = np.mean(b_values)\n",
    "\n",
    "# Calculate standard deviations\n",
    "a_std = np.std(a_values, ddof=1)  # Sample std (ddof=1)\n",
    "b_std = np.std(b_values, ddof=1)\n",
    "\n",
    "# Predict y using mean parameters\n",
    "y_pred = a_mean * x + b_mean\n",
    "\n",
    "# Propagate uncertainty to y (error propagation formula)\n",
    "# For y = a*x + b, the variance is: Var(y) = x²·Var(a) + Var(b) + 2x·Cov(a,b)\n",
    "cov_ab = np.cov(a_values, b_values)[0, 1]  # Covariance between a and b\n",
    "\n",
    "# Calculate uncertainty for each x value\n",
    "y_std = np.sqrt(x**2 * a_std**2 + b_std**2 + 2 * x * cov_ab)\n",
    "\n",
    "# Display results\n",
    "print(f\"a = {a_mean:.3f} ± {a_std:.3f}\")\n",
    "print(f\"b = {b_mean:.3f} ± {b_std:.3f}\")\n",
    "print(f\"Covariance(a,b) = {cov_ab:.3f}\")\n",
    "print(\"\\nPredictions with uncertainty:\")\n",
    "for xi, yi, yi_std in zip(x, y_pred, y_std):\n",
    "    print(f\"x={xi}: y = {yi:.3f} ± {yi_std:.3f}\")\n",
    "\n",
    "# Confidence bounds (±2σ ≈ 95% confidence)\n",
    "y_lower = y_pred - 2 * y_std\n",
    "y_upper = y_pred + 2 * y_std\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.plot(x, y_pred, \"b-\", linewidth=2, label=f\"y = {a_mean:.2f}x + {b_mean:.2f}\")\n",
    "ax.fill_between(x, y_lower, y_upper, alpha=0.3, label=\"95% Confidence\")\n",
    "ax.scatter(x, y_pred, color=\"blue\", s=50, zorder=5)\n",
    "ax.errorbar(x, y_pred, yerr=2 * y_std, fmt=\"none\", ecolor=\"gray\", capsize=5)\n",
    "ax.set_xlabel(\"x\", fontsize=12)\n",
    "ax.set_ylabel(\"y\", fontsize=12)\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696a634b-358c-4a3a-99bb-81f84efb9c30",
   "metadata": {},
   "source": [
    "#### Approach 2\n",
    "\n",
    "Apply SARIMAX to forecast the values of coefficient & intercept in period 2023 - 2024 --> perform prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05e60f4b-845a-436e-92ab-1f7d4071f38c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc4a233ebb00432c9fe9922a1261cea4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ BEICHEN\n",
      "✓ GUANGFU\n",
      "✓ HONGLUN\n",
      "✓ HUNAN\n",
      "✓ HUWEI\n",
      "✓ JIAXING\n",
      "✓ KECUO\n",
      "✓ NEILIAO\n",
      "✓ QIAOYI\n",
      "✓ TUKU\n",
      "✓ XINSHENG\n",
      "✓ XIUTAN\n",
      "✓ XIZHOU\n",
      "✓ YUANCHANG\n",
      "\n",
      "Processing complete. Results saved to arima_output_seasonal1/Layer_1/\n",
      "✓ BEICHEN\n",
      "✓ GUANGFU\n",
      "✓ HONGLUN\n",
      "✓ HUNAN\n",
      "✓ HUWEI\n",
      "✓ JIAXING\n",
      "✓ KECUO\n",
      "✓ NEILIAO\n",
      "✓ QIAOYI\n",
      "✓ TUKU\n",
      "✓ XINSHENG\n",
      "✓ XIUTAN\n",
      "✓ XIZHOU\n",
      "✓ YUANCHANG\n",
      "\n",
      "Processing complete. Results saved to arima_output_seasonal1/Layer_2/\n",
      "✓ BEICHEN\n",
      "✓ GUANGFU\n",
      "✓ HONGLUN\n",
      "✓ HUNAN\n",
      "✓ HUWEI\n",
      "✓ JIAXING\n",
      "✓ KECUO\n",
      "✓ NEILIAO\n",
      "✓ QIAOYI\n",
      "✓ TUKU\n",
      "✓ XINSHENG\n",
      "✓ XIUTAN\n",
      "✓ XIZHOU\n",
      "✓ YUANCHANG\n",
      "\n",
      "Processing complete. Results saved to arima_output_seasonal1/Layer_3/\n",
      "✓ BEICHEN\n",
      "✓ GUANGFU\n",
      "✓ HONGLUN\n",
      "✓ HUNAN\n",
      "✓ HUWEI\n",
      "✓ KECUO\n",
      "✓ NEILIAO\n",
      "✓ QIAOYI\n",
      "✓ TUKU\n",
      "✓ XINSHENG\n",
      "✓ XIUTAN\n",
      "✓ XIZHOU\n",
      "✓ YUANCHANG\n",
      "\n",
      "Processing complete. Results saved to arima_output_seasonal1/Layer_4/\n",
      "✓ BEICHEN\n",
      "✓ GUANGFU\n",
      "✓ HONGLUN\n",
      "✓ HUNAN\n",
      "✓ HUWEI\n",
      "✓ JIAXING\n",
      "✓ KECUO\n",
      "✓ NEILIAO\n",
      "✓ QIAOYI\n",
      "✓ TUKU\n",
      "✓ XINSHENG\n",
      "✓ XIUTAN\n",
      "✓ XIZHOU\n",
      "✓ YUANCHANG\n",
      "\n",
      "Processing complete. Results saved to arima_output_seasonal1/Layer_All/\n"
     ]
    }
   ],
   "source": [
    "from utils2 import *\n",
    "\n",
    "files = glob(os.path.join(\"reg_diffdisp/\", \"*csv\"))\n",
    "results_csv = glob(os.path.join(\"GWR*Output*\", \"*combined_results.csv\"))\n",
    "# idx = 0\n",
    "\n",
    "n_seasonal = 1\n",
    "\n",
    "for idx in trange(len(files)):\n",
    "\n",
    "    select_file = files[idx]\n",
    "    select_result = results_csv[idx]\n",
    "\n",
    "    df = pd.read_csv(select_file)\n",
    "    result_df = pd.read_csv(select_result).rename(\n",
    "        {\"input_STATION\": \"STATION\"}, axis=1\n",
    "    )\n",
    "\n",
    "    current_layer = \"_\".join(\n",
    "        os.path.basename(select_file).split(\".\")[0].split(\"_\")[-2:]\n",
    "    )\n",
    "    output_dir = f\"arima_output_seasonal{n_seasonal}/{current_layer}\"\n",
    "\n",
    "    # Process all stations\n",
    "    all_metrics = []\n",
    "    all_mlcw_metrics = []\n",
    "\n",
    "    for station in df[\"STATION\"].unique():\n",
    "        try:\n",
    "            df_station = df.query(\"STATION==@station\")\n",
    "            result_station = result_df.query(\"STATION==@station\")\n",
    "            future_dates = pd.to_datetime(df_station[\"time\"])\n",
    "\n",
    "            # Fit ARIMA and save predictions\n",
    "            metrics = process_single_station_with_predictions(\n",
    "                df_station,\n",
    "                result_station,\n",
    "                station,\n",
    "                current_layer,\n",
    "                future_dates,\n",
    "                output_dir,\n",
    "                n_seasonal=n_seasonal,\n",
    "            )\n",
    "            all_metrics.append(metrics)\n",
    "\n",
    "            # Generate MLCW predictions\n",
    "            insar_data = df_station[[\"time\", \"DIFFDISP\"]].copy()\n",
    "            insar_data[\"time\"] = pd.to_datetime(insar_data[\"time\"])\n",
    "\n",
    "            mlcw_predictions = predict_mlcw_from_arima(\n",
    "                station_name=station,\n",
    "                insar_data=insar_data,\n",
    "                predictions_dir=output_dir,\n",
    "                layer_name=current_layer,\n",
    "            )\n",
    "\n",
    "            # Save MLCW predictions\n",
    "            mlcw_predictions.to_csv(\n",
    "                f\"{output_dir}/{station}_MLCW_predictions.csv\", index=False\n",
    "            )\n",
    "\n",
    "            # Visualize and evaluate MLCW predictions\n",
    "            mlcw_metrics = plot_mlcw_prediction_vs_observed(\n",
    "                mlcw_predictions=mlcw_predictions,\n",
    "                observed_data=df_station[[\"time\", current_layer]],\n",
    "                station_name=station,\n",
    "                layer_name=current_layer,\n",
    "                output_dir=output_dir,\n",
    "            )\n",
    "            all_mlcw_metrics.append(mlcw_metrics)\n",
    "\n",
    "            print(f\"✓ {station}\")\n",
    "        except Exception as e:\n",
    "            print(f\"✗ {station}: {e}\")\n",
    "\n",
    "    # Save all metrics\n",
    "    pd.DataFrame(all_metrics).to_excel(\n",
    "        f\"{output_dir}/arima_fitting_metrics.xlsx\", index=False\n",
    "    )\n",
    "    pd.DataFrame(all_mlcw_metrics).to_excel(\n",
    "        f\"{output_dir}/mlcw_prediction_metrics.xlsx\", index=False\n",
    "    )\n",
    "\n",
    "    print(f\"\\nProcessing complete. Results saved to {output_dir}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2545353a-efa5-41a0-8872-cf640bfd78b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
