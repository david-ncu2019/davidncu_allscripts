{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a01a6e8-9344-4e62-a6ca-f339dbe274bf",
   "metadata": {},
   "source": [
    "1. Open file containing timeseries of cumulative displacement\n",
    "2. Open file containing leveling measurement of county ABC\n",
    "3. Open file containing `PointKey` of points surrounding the leveling benchmark in county ABC\n",
    "4. Loop through each benchmark, select `PointKey` of points surrounding that benchmark.\n",
    "5. Take average of the `CUMDISP` timeseries of those points\n",
    "6. Calculate linear trend (force zero intercept) of leveling measurement and `CUMDISP`\n",
    "7. Calculate the difference $\\Delta slope = slope_{Leveling} - slope_{InSAR}$\n",
    "8. Export the final table with `coordinates` and $\\Delta slope$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739bf1fb-bb45-48bb-8070-56f962673c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from appgeopy import *\n",
    "from my_packages import *"
   ]
  },
  {
   "cell_type": "raw",
   "id": "626c9ecd-9c5e-4f5e-a33c-07f491335820",
   "metadata": {},
   "source": [
    "def get_slope(input_series, force=True):\n",
    "    fulltime_arr = datetime_handle.get_fulltime(input_series.index)\n",
    "    fulltime_timeseries = datetime_handle.fulltime_table(\n",
    "        df=input_series, fulltime_series=fulltime_arr\n",
    "    )\n",
    "    linear_trend, slope = analysis.get_linear_trend(\n",
    "        series=fulltime_timeseries, force_zero_intercept=force\n",
    "    )\n",
    "    return linear_trend, slope"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6dccfa91-92d4-4410-9779-41ca535443a7",
   "metadata": {},
   "source": [
    "# load timeseries of cumulative displacement of all points\n",
    "cumdisp_df = pd.read_pickle(\n",
    "    r\"D:\\1000_SCRIPTS\\003_Project002\\20250917_GTWR002\\2_KrigingInterpolation\\5_PostKriging\\Monthly_CUMDISP_saveqgis_Oct2025.xz\"\n",
    ")\n",
    "cumdisp_df = cumdisp_df.set_index(\"PointKey\")\n",
    "show(cumdisp_df)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "17b3b7c8-ddcf-41f5-976f-4d9639365ba8",
   "metadata": {},
   "source": [
    "leveling_fpath = r\"Yunlin_Leveling_2024_modified2016_2024.xz\"\n",
    "leveling_df = pd.read_pickle(leveling_fpath)\n",
    "show(leveling_df)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ba8209fb-1a37-4007-9ed0-32f912a6137e",
   "metadata": {},
   "source": [
    "points_byLeveling = pd.read_pickle(r\"CUMDISP_in_YunlinLeveling_200m.xz\")\n",
    "show(points_byLeveling)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c66a606a-b9ab-4b9f-8b3a-aa7df5517d89",
   "metadata": {},
   "source": [
    "cache = {\"ALTCODE\": [], \"Lev_slope\": [], \"InSAR_slope\": [], \"Delta_slope\": []}\n",
    "\n",
    "all_leveling_code = points_byLeveling[\"ALTCODE\"].unique().tolist()\n",
    "\n",
    "# loop through each leveling benchmark code\n",
    "# select_leveling_code = all_leveling_code[0]\n",
    "\n",
    "for select_leveling_code in tqdm(all_leveling_code):\n",
    "\n",
    "    cache[\"ALTCODE\"].append(select_leveling_code)\n",
    "\n",
    "    # using the select benchmark code, we get the pointkey located within the leveling's buffer\n",
    "    pointkey_byCode = points_byLeveling.query(\"ALTCODE==@select_leveling_code\")[\n",
    "        \"PointKey\"\n",
    "    ].tolist()\n",
    "\n",
    "    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "    # deal with Leveling survey timeseries\n",
    "    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "    leveling_measure_cols = [\n",
    "        col for col in leveling_df.columns if col.startswith(\"N\")\n",
    "    ]\n",
    "    leveling_timeseries = leveling_df.loc[\n",
    "        select_leveling_code, leveling_measure_cols\n",
    "    ]\n",
    "\n",
    "    leveling_timeseries = leveling_timeseries.astype(np.float64)\n",
    "    # reference the measurement to the first acquisition\n",
    "    # and convert to milimeter\n",
    "    leveling_timeseries = (\n",
    "        leveling_timeseries - leveling_timeseries.iloc[0]\n",
    "    ) * 1000\n",
    "\n",
    "    leveling_timeseries.index = pd.to_datetime(\n",
    "        [idx[1:] for idx in leveling_timeseries.index]\n",
    "    )\n",
    "\n",
    "    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "    # deal with CUMDISP timeseries\n",
    "    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "    cumdisp_byLevelingCode = cumdisp_df.loc[pointkey_byCode, :]\n",
    "\n",
    "    cumdisp_measure_cols = [\n",
    "        col for col in cumdisp_byLevelingCode.columns if col.startswith(\"D\")\n",
    "    ]\n",
    "\n",
    "    cumdisp_byLevelingCode = cumdisp_byLevelingCode.loc[:, cumdisp_measure_cols]\n",
    "\n",
    "    average_cumdisp_byLevelingCode = cumdisp_byLevelingCode.mean(axis=0)\n",
    "\n",
    "    # we add one day to convert datetime to the beginning of the month\n",
    "    average_cumdisp_byLevelingCode.index = [\n",
    "        pd.to_datetime(idx[1:]) + relativedelta(days=1)\n",
    "        for idx in average_cumdisp_byLevelingCode.index\n",
    "    ]\n",
    "\n",
    "    #### do not need to reference to the first date\n",
    "\n",
    "    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "    # calculate slope value for each\n",
    "    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "    # leveling timeseries\n",
    "    leveling_trend, leveling_slope = get_slope(leveling_timeseries)\n",
    "\n",
    "    # average cumdisp timeseries\n",
    "    cumdisp_trend, cumdisp_slope = get_slope(\n",
    "        average_cumdisp_byLevelingCode, force=False\n",
    "    )\n",
    "\n",
    "    # get slope difference\n",
    "    delta_slope = leveling_slope - cumdisp_slope\n",
    "\n",
    "    # Add information to dictionary for later saving\n",
    "    cache[\"Lev_slope\"].append(leveling_slope)\n",
    "    cache[\"InSAR_slope\"].append(cumdisp_slope)\n",
    "    cache[\"Delta_slope\"].append(delta_slope)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "edbd7e87-cfdd-471a-a204-a67f596e67d8",
   "metadata": {},
   "source": [
    "output_df = pd.DataFrame(cache)\n",
    "output_df = output_df.set_index(\"ALTCODE\")\n",
    "for col in [\"X_TWD97\", \"Y_TWD97\"]:\n",
    "    output_df[col] = output_df.index.map(leveling_df[col])\n",
    "\n",
    "output_df.to_pickle(leveling_fpath.replace(\".xz\", \"_deltaSlope.xz\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd216c66-edad-4f97-9d0a-42cda431622e",
   "metadata": {},
   "source": [
    "\n",
    "#### 2025/10/14: Merge two output table into one, and convert them to geospatial dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad9420b-feb7-4e61-9539-9a85e93ae26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "changhua_df = pd.read_pickle(r\"Changhua_Leveling_2024_modified2016_2024_deltaSlope.xz\")\n",
    "changhua_df = changhua_df.reset_index(drop=False)\n",
    "\n",
    "yunlin_df = pd.read_pickle(r\"Yunlin_Leveling_2024_modified2016_2024_deltaSlope.xz\")\n",
    "yunlin_df = yunlin_df.reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5fb389-0fc8-4b85-9eef-aa02558a1714",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.concat([changhua_df, yunlin_df], ignore_index=True)\n",
    "merged_gdf = geospatial.convert_to_geodata(df=merged, xcoord_col=\"X_TWD97\", ycoord_col=\"Y_TWD97\", crs_epsg=\"EPSG:3826\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae361255-08d8-4292-9606-af2206e2540e",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_gdf.to_file(r\"Leveling_2024_modified2016_2024_deltaSlope.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0db024-d3f1-4c6c-9166-32dcbc3a95c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
