{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc510d12-5e6e-4031-ad2d-33de69a6bfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from appgeopy import *\n",
    "from my_packages import *\n",
    "\n",
    "# ==============================================================================\n",
    "# CONFIGURATION\n",
    "# ==============================================================================\n",
    "\n",
    "initial_timepoint = datetime(2016, 5, 1)\n",
    "TIME_FILTER_THRESHOLD = 68\n",
    "DISPLAY_START_DATE = datetime(2016, 1, 1)\n",
    "DISPLAY_END_DATE = datetime(2022, 1, 1)\n",
    "VLINE_START_DATE = datetime(2016, 1, 1)\n",
    "VLINE_END_DATE = datetime(2022, 4, 1)\n",
    "VLINE_INTERVAL_MONTHS = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83f957a4-48bd-4572-a0c2-0958b01ece01",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# HELPER FUNCTIONS\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "def create_pointkey(x, y):\n",
    "    \"\"\"Generate unique point identifier from coordinates.\"\"\"\n",
    "    return f\"X{int(x*1000)}Y{int(y*1000)}\"\n",
    "\n",
    "\n",
    "def prepare_dataframe(filepath):\n",
    "    \"\"\"Load and prepare dataframe with PointKey indexing.\"\"\"\n",
    "    df = pd.read_csv(filepath)\n",
    "    pointkey_arr = [\n",
    "        create_pointkey(x, y) for x, y in zip(df[\"X_TWD97\"], df[\"Y_TWD97\"])\n",
    "    ]\n",
    "    df.insert(loc=0, column=\"PointKey\", value=pointkey_arr)\n",
    "    df = df.set_index(\"PointKey\")\n",
    "    return df.query(f\"Time_value<={TIME_FILTER_THRESHOLD}\")\n",
    "\n",
    "\n",
    "def convert_time_values(time_values, initial_timepoint):\n",
    "    \"\"\"Convert time step values to datetime objects.\"\"\"\n",
    "    return pd.to_datetime(\n",
    "        [\n",
    "            initial_timepoint + relativedelta(months=int(step))\n",
    "            for step in time_values\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def calculate_metrics(obs_val, predict_val):\n",
    "    \"\"\"Calculate model performance metrics.\"\"\"\n",
    "    r2 = r2_score(obs_val, predict_val)\n",
    "    rmse = root_mean_squared_error(obs_val, predict_val)\n",
    "    mae = mean_absolute_error(obs_val, predict_val)\n",
    "    pbias = 100.0 * np.sum(predict_val - obs_val) / np.sum(obs_val)\n",
    "    return r2, rmse, mae, pbias\n",
    "\n",
    "\n",
    "def calculate_ylim(obs_val, predict_val, padding=0.2):\n",
    "    \"\"\"Calculate y-axis limits with padding.\"\"\"\n",
    "    _top_temp = max(obs_val.max(), predict_val.max())\n",
    "    _bot_temp = min(obs_val.min(), predict_val.min())\n",
    "    top_bot_range = abs(_top_temp - _bot_temp)\n",
    "    return (\n",
    "        _bot_temp - top_bot_range * padding,\n",
    "        _top_temp + top_bot_range * padding,\n",
    "    )\n",
    "\n",
    "\n",
    "def generate_vline_dates(start, end, interval_months):\n",
    "    \"\"\"Generate list of dates for vertical grid lines.\"\"\"\n",
    "    vline_dates = []\n",
    "    current = start\n",
    "    while current <= end:\n",
    "        vline_dates.append(current)\n",
    "        current += relativedelta(months=interval_months)\n",
    "    return vline_dates\n",
    "\n",
    "\n",
    "def style_axes(axes, vline_dates):\n",
    "    \"\"\"Apply consistent styling to all axes.\"\"\"\n",
    "    for ax in axes:\n",
    "        visualize.configure_axis(\n",
    "            ax=ax,\n",
    "            tick_direction=\"out\",\n",
    "            hide_spines=[\"top\", \"right\"],\n",
    "            major_tick_length=10,\n",
    "            minor_tick_length=7,\n",
    "        )\n",
    "\n",
    "        visualize.configure_datetime_ticks(\n",
    "            ax=ax,\n",
    "            major_interval=12,\n",
    "            minor_interval=3,\n",
    "            fontsize=14,\n",
    "            grid=False,\n",
    "            start_date=DISPLAY_START_DATE,\n",
    "            end_date=DISPLAY_END_DATE,\n",
    "        )\n",
    "\n",
    "        # Force first tick at display start\n",
    "        current_ticks = list(ax.get_xticks())\n",
    "        first_tick = mdates.date2num(DISPLAY_START_DATE)\n",
    "        ax.set_xticks([first_tick] + current_ticks)\n",
    "\n",
    "        # Add vertical grid lines\n",
    "        for vline_date in vline_dates:\n",
    "            ax.axvline(\n",
    "                x=vline_date,\n",
    "                color=\"gray\",\n",
    "                linestyle=\"--\",\n",
    "                linewidth=1,\n",
    "                alpha=0.5,\n",
    "                zorder=0,\n",
    "            )\n",
    "\n",
    "\n",
    "def create_visualization(\n",
    "    df_byPointKey, layer_number, mlcw_station, r2, rmse, mae, pbias\n",
    "):\n",
    "    \"\"\"Create three-panel visualization figure.\"\"\"\n",
    "    # Extract data\n",
    "    time_arr = df_byPointKey[\"Time_value\"]\n",
    "    obs_val = df_byPointKey[f\"input_Layer_{layer_number}\"]\n",
    "    predict_val = df_byPointKey[\"predicted_value\"]\n",
    "\n",
    "    # Calculate limits and statistics\n",
    "    obs_botlim, obs_toplim = calculate_ylim(obs_val, predict_val)\n",
    "    coeff_mean = np.mean(df_byPointKey[\"CUMDISP\"])\n",
    "    coeff_stdev = np.std(df_byPointKey[\"CUMDISP\"])\n",
    "    intercept_mean = np.mean(df_byPointKey[\"Intercept\"])\n",
    "    intercept_stdev = np.std(df_byPointKey[\"Intercept\"])\n",
    "\n",
    "    # Create figure\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(11.69, 8.27), sharex=True)\n",
    "    fig.suptitle(\n",
    "        f\"{mlcw_station} - Layer {layer_number}\",\n",
    "        y=0.975,\n",
    "        fontweight=\"bold\",\n",
    "        fontsize=20,\n",
    "    )\n",
    "\n",
    "    # Panel 1: Observations vs Predictions\n",
    "    ax1 = axes[0]\n",
    "    ax1.plot(\n",
    "        time_arr,\n",
    "        obs_val,\n",
    "        color=\"darkgrey\",\n",
    "        ls=\"--\",\n",
    "        linewidth=2,\n",
    "        marker=\"o\",\n",
    "        ms=8,\n",
    "        label=\"Obs\",\n",
    "        markevery=3,\n",
    "    )\n",
    "    ax1.plot(\n",
    "        time_arr,\n",
    "        predict_val,\n",
    "        color=\"dodgerblue\",\n",
    "        linestyle=(0, (1, 1)),\n",
    "        marker=\"s\",\n",
    "        ms=8,\n",
    "        linewidth=2,\n",
    "        label=\"Pred\",\n",
    "        markevery=3,\n",
    "    )\n",
    "    ax1.set_ylim(bottom=obs_botlim, top=obs_toplim)\n",
    "    ax1.set_ylabel(\n",
    "        \"Cumulative\\nCompaction (mm)\", fontsize=14, fontweight=\"bold\"\n",
    "    )\n",
    "\n",
    "    stats_text = f\"R²   : {r2:.3f}\\nRMSE : {rmse:.3f}\\nMAE  : {mae:.3f}\\nPBIAS: {pbias:.2f}%\"\n",
    "    ax1.text(\n",
    "        0.98,\n",
    "        0.97,\n",
    "        stats_text,\n",
    "        transform=ax1.transAxes,\n",
    "        ha=\"right\",\n",
    "        va=\"top\",\n",
    "        fontsize=10,\n",
    "        fontfamily=\"monospace\",\n",
    "        bbox=dict(boxstyle=\"round,pad=0.5\", fc=\"#EAEAF2\", ec=\"black\", lw=1),\n",
    "    )\n",
    "\n",
    "    visualize.configure_ticks(ax=ax1, y_minor_interval=5)\n",
    "    visualize.configure_legend(\n",
    "        ax=ax1,\n",
    "        columnspacing=0.5,\n",
    "        labelspacing=0.1,\n",
    "        handletextpad=0.2,\n",
    "        ncol=2,\n",
    "        fontsize_base=14,\n",
    "        loc=\"lower left\",\n",
    "    )\n",
    "\n",
    "    # Panel 2: GTWR Coefficients\n",
    "    ax2 = axes[1]\n",
    "    ax2.plot(\n",
    "        time_arr,\n",
    "        df_byPointKey[\"CUMDISP\"],\n",
    "        color=\"darkviolet\",\n",
    "        marker=\"s\",\n",
    "        markerfacecolor=\"none\",\n",
    "        ms=8,\n",
    "        linewidth=2,\n",
    "        markevery=3,\n",
    "    )\n",
    "    ax2.axhline(coeff_mean, lw=1, color=\"darkmagenta\", ls=\"--\")\n",
    "    ax2.set_ylabel(\"GTWR\\nCoefficient\", fontsize=14, fontweight=\"bold\")\n",
    "    ax2.text(\n",
    "        0.025,\n",
    "        0.1,\n",
    "        rf\"$\\overline{{\\beta_1}}$={coeff_mean:.2f}±{coeff_stdev:.2f}\",\n",
    "        transform=ax2.transAxes,\n",
    "        fontsize=14,\n",
    "    )\n",
    "\n",
    "    # Panel 3: Model Intercept\n",
    "    ax3 = axes[2]\n",
    "    ax3.plot(\n",
    "        time_arr,\n",
    "        df_byPointKey[\"Intercept\"],\n",
    "        color=\"darkgreen\",\n",
    "        marker=\"D\",\n",
    "        markerfacecolor=\"none\",\n",
    "        ms=8,\n",
    "        linewidth=2,\n",
    "        markevery=3,\n",
    "    )\n",
    "    ax3.axhline(intercept_mean, lw=1, color=\"green\", ls=\"--\")\n",
    "    ax3.set_ylabel(\"GTWR\\nIntercept\", fontsize=14, fontweight=\"bold\")\n",
    "    ax3.text(\n",
    "        0.025,\n",
    "        0.1,\n",
    "        rf\"$\\overline{{\\beta_0}}$={intercept_mean:.2f}±{intercept_stdev:.2f}\",\n",
    "        transform=ax3.transAxes,\n",
    "        fontsize=14,\n",
    "    )\n",
    "\n",
    "    # Apply styling\n",
    "    vline_dates = generate_vline_dates(\n",
    "        VLINE_START_DATE, VLINE_END_DATE, VLINE_INTERVAL_MONTHS\n",
    "    )\n",
    "    style_axes(axes, vline_dates)\n",
    "\n",
    "    # Finalize layout\n",
    "    fig.tight_layout(rect=[0, 0.05, 1, 0.96])\n",
    "    fig.autofmt_xdate(ha=\"center\", rotation=90)\n",
    "\n",
    "    return fig, coeff_mean, coeff_stdev, intercept_mean, intercept_stdev\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# MAIN PROCESSING LOOP\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "def process_model_outputs(output_files, model_folder, mlcw_gdf):\n",
    "    \"\"\"Process all model output files and generate visualizations.\"\"\"\n",
    "    cache = {\n",
    "        \"STATION\": [],\n",
    "        \"Layer\": [],\n",
    "        \"r_sq\": [],\n",
    "        \"RMSE\": [],\n",
    "        \"MAE\": [],\n",
    "        \"PBIAS\": [],\n",
    "        \"Coeff_Mean\": [],\n",
    "        \"Coeff_Stdev\": [],\n",
    "        \"Intercept_Mean\": [],\n",
    "        \"Intercept_Stdev\": [],\n",
    "    }\n",
    "\n",
    "    for select_file in tqdm(output_files, desc=\"Layer\"):\n",
    "        # Setup output directory\n",
    "        savefig_folder = os.path.join(\n",
    "            model_folder,\n",
    "            \"y_yhat_figs_2\",\n",
    "            os.path.dirname(select_file).split(\"\\\\\")[-1],\n",
    "        )\n",
    "        os.makedirs(savefig_folder, exist_ok=True)\n",
    "\n",
    "        layer_number = os.path.basename(select_file).split(\"_\")[2]\n",
    "\n",
    "        # Load and prepare data\n",
    "        df = prepare_dataframe(select_file)\n",
    "        unique_pointkey = df.index.unique()\n",
    "\n",
    "        # Process each location\n",
    "        for select_pointkey in tqdm(\n",
    "            unique_pointkey, desc=\"Pointkey\", leave=False\n",
    "        ):\n",
    "            try:\n",
    "                mlcw_station = mlcw_gdf.query(\n",
    "                    \"PointKey==@select_pointkey\"\n",
    "                ).STATION.values[0]\n",
    "\n",
    "                # Prepare time series data\n",
    "                df_byPointKey = df.loc[select_pointkey].copy()\n",
    "                df_byPointKey[\"Time_value\"] = convert_time_values(\n",
    "                    df_byPointKey[\"Time_value\"], initial_timepoint\n",
    "                )\n",
    "\n",
    "                # Calculate metrics\n",
    "                obs_val = df_byPointKey[f\"input_Layer_{layer_number}\"]\n",
    "                predict_val = df_byPointKey[\"predicted_value\"]\n",
    "                r2, rmse, mae, pbias = calculate_metrics(obs_val, predict_val)\n",
    "\n",
    "                # Create visualization\n",
    "                (\n",
    "                    fig,\n",
    "                    coeff_mean,\n",
    "                    coeff_stdev,\n",
    "                    intercept_mean,\n",
    "                    intercept_stdev,\n",
    "                ) = create_visualization(\n",
    "                    df_byPointKey,\n",
    "                    layer_number,\n",
    "                    mlcw_station,\n",
    "                    r2,\n",
    "                    rmse,\n",
    "                    mae,\n",
    "                    pbias,\n",
    "                )\n",
    "\n",
    "                # Update cache\n",
    "                for key, value in zip(\n",
    "                    cache.keys(),\n",
    "                    [\n",
    "                        mlcw_station,\n",
    "                        layer_number,\n",
    "                        r2,\n",
    "                        rmse,\n",
    "                        mae,\n",
    "                        pbias,\n",
    "                        coeff_mean,\n",
    "                        coeff_stdev,\n",
    "                        intercept_mean,\n",
    "                        intercept_stdev,\n",
    "                    ],\n",
    "                ):\n",
    "                    cache[key].append(value)\n",
    "\n",
    "                # Save figure\n",
    "                save_filename = f\"{mlcw_station}_layer_{layer_number}.png\"\n",
    "                visualize.save_figure(\n",
    "                    fig, os.path.join(savefig_folder, save_filename)\n",
    "                )\n",
    "                plt.close(fig)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {select_pointkey}: {e}\")\n",
    "\n",
    "        # Save summary table for this layer\n",
    "        summary_table = pd.DataFrame(cache)\n",
    "        summary_table.to_excel(\n",
    "            os.path.join(\n",
    "                savefig_folder, f\"summary_table_Layer_{layer_number}.xlsx\"\n",
    "            ),\n",
    "            index=False,\n",
    "        )\n",
    "\n",
    "    return cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dcaee98-47fd-4934-bb0d-2240d1318a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\1000_SCRIPTS\\\\003_Project002\\\\20250917_GTWR002\\\\3D_TestRun_4\\\\gtwr_run_output_Layer_1\\\\gtwr_Layer_1_regression_kernel-tricube_lambda-0d03_bw-25_results.csv',\n",
       " 'D:\\\\1000_SCRIPTS\\\\003_Project002\\\\20250917_GTWR002\\\\3D_TestRun_4\\\\gtwr_run_output_Layer_2\\\\gtwr_Layer_2_regression_kernel-tricube_lambda-0d002_bw-18_results.csv',\n",
       " 'D:\\\\1000_SCRIPTS\\\\003_Project002\\\\20250917_GTWR002\\\\3D_TestRun_4\\\\gtwr_run_output_Layer_3\\\\gtwr_Layer_3_regression_kernel-tricube_lambda-0d07_bw-17_results.csv',\n",
       " 'D:\\\\1000_SCRIPTS\\\\003_Project002\\\\20250917_GTWR002\\\\3D_TestRun_4\\\\gtwr_run_output_Layer_4\\\\gtwr_Layer_4_regression_kernel-tricube_lambda-0d1_bw-18_results.csv',\n",
       " 'D:\\\\1000_SCRIPTS\\\\003_Project002\\\\20250917_GTWR002\\\\3D_TestRun_4\\\\gtwr_run_output_Layer_All\\\\gtwr_Layer_All_regression_kernel-tricube_lambda-0d002_bw-17_results.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# USAGE EXAMPLE\n",
    "# ==============================================================================\n",
    "model_folder = os.getcwd()\n",
    "mlcw_gdf = gpd.read_file(\n",
    "    r\"D:\\1000_SCRIPTS\\003_Project002\\20250222_GTWR001\\2_KrigingInterpolation\\points_fld\\mlcw_twd97.shp\"\n",
    ")\n",
    "\n",
    "# Define the specific kernel name used in the model to find relevant result files.\n",
    "kernel_name = \"tricube\"\n",
    "# Use `glob` to find all files within `model_folder` that contain the kernel name in their filename.\n",
    "output_files = glob(os.path.join(model_folder, \"*\", f\"*{kernel_name}*.csv\"))\n",
    "cache = process_model_outputs(output_files, model_folder, mlcw_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a18bb3-8676-4465-a9ac-a41b5f41676b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
