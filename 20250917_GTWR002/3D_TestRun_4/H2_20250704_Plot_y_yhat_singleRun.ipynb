{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f1d7a30-d91e-4931-bf94-2d3e3bcf3bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. SETUP AND IMPORTS ---\n",
    "# Import custom modules and necessary third-party libraries.\n",
    "# `appgeopy` and `my_packages` appear to be user-defined modules.\n",
    "# It's assumed they contain helper functions and libraries like geopandas, pandas, os, glob, and matplotlib.\n",
    "from appgeopy import *\n",
    "from my_packages import *\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error,\n",
    "    r2_score,\n",
    "    root_mean_squared_error,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec4bafdf-2dd3-480c-920f-3ad4934376cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. DATA LOADING AND PREPARATION ---\n",
    "\n",
    "# Load a shapefile containing geospatial point data (monitoring stations) into a GeoDataFrame.\n",
    "# The 'r' prefix indicates a raw string, which prevents backslashes from being treated as escape characters.\n",
    "mlcw_gdf = gpd.read_file(\n",
    "    r\"D:\\1000_SCRIPTS\\003_Project002\\20250222_GTWR001\\2_KrigingInterpolation\\points_fld\\mlcw_twd97.shp\"\n",
    ")\n",
    "# Display the first 5 rows of the GeoDataFrame to verify it loaded correctly.\n",
    "mlcw_gdf.head(5)\n",
    "mlcw_gdf[\"PointKey\"] = [\n",
    "    f\"X{int(x)}Y{int(y)}\"\n",
    "    for x, y in zip(mlcw_gdf[\"POINT_X\"], mlcw_gdf[\"POINT_Y\"])\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a3a26a-f798-4644-8f8a-97928fe7c503",
   "metadata": {},
   "source": [
    "#### $Layer_{n} = \\text{CUMDISP} + \\text{CUMDISP}^{2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afb4fb26-bed8-41c6-b9c2-b9436c973870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "629cd8a7c42b4486b2e6c413c3c57057",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pointkey:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to process point X178859Y2608228. Error: name 'r2_score' is not defined\n",
      "Failed to process point X173088Y2608157. Error: name 'r2_score' is not defined\n",
      "Failed to process point X175783Y2616755. Error: name 'r2_score' is not defined\n",
      "Failed to process point X190429Y2629865. Error: name 'r2_score' is not defined\n",
      "Failed to process point X171859Y2631894. Error: name 'r2_score' is not defined\n",
      "Failed to process point X179785Y2632016. Error: name 'r2_score' is not defined\n",
      "Failed to process point X189084Y2626508. Error: name 'r2_score' is not defined\n",
      "Failed to process point X171150Y2629140. Error: name 'r2_score' is not defined\n",
      "Failed to process point X183487Y2620454. Error: name 'r2_score' is not defined\n",
      "Failed to process point X197073Y2649583. Error: name 'r2_score' is not defined\n",
      "Failed to process point X192041Y2623606. Error: name 'r2_score' is not defined\n",
      "Failed to process point X163506Y2614756. Error: name 'r2_score' is not defined\n",
      "Failed to process point X194875Y2616146. Error: name 'r2_score' is not defined\n",
      "Failed to process point X182075Y2613831. Error: name 'r2_score' is not defined\n",
      "Failed to process point X179646Y2624184. Error: name 'r2_score' is not defined\n",
      "Failed to process point X184142Y2611723. Error: name 'r2_score' is not defined\n",
      "Failed to process point X196150Y2637964. Error: name 'r2_score' is not defined\n",
      "Failed to process point X187772Y2620611. Error: name 'r2_score' is not defined\n",
      "Failed to process point X177634Y2639733. Error: name 'r2_score' is not defined\n",
      "Failed to process point X188364Y2643201. Error: name 'r2_score' is not defined\n",
      "Failed to process point X179743Y2644119. Error: name 'r2_score' is not defined\n",
      "Failed to process point X188342Y2648279. Error: name 'r2_score' is not defined\n",
      "Failed to process point X170721Y2626356. Error: name 'r2_score' is not defined\n",
      "Failed to process point X183652Y2617397. Error: name 'r2_score' is not defined\n",
      "Failed to process point X199069Y2638501. Error: name 'r2_score' is not defined\n",
      "Failed to process point X167842Y2604974. Error: name 'r2_score' is not defined\n",
      "Failed to process point X179485Y2616803. Error: name 'r2_score' is not defined\n",
      "Failed to process point X202939Y2621720. Error: name 'r2_score' is not defined\n",
      "Failed to process point X191944Y2639635. Error: name 'r2_score' is not defined\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# --- 1. SCRIPT SETUP AND CONFIGURATION ---\n",
    "# This section defines the file paths and initial parameters needed for the script.\n",
    "# Modifying these variables is the primary way to change the script's behavior.\n",
    "# ==============================================================================\n",
    "\n",
    "# Define the full path to the input CSV file containing the model's coefficient data.\n",
    "select_file = r\"D:\\1000_SCRIPTS\\003_Project002\\20250917_GTWR002\\4_MainRun\\gtwr_Layer_1_kernel-bisquare_lambda-0d2_bw-14_coefficients.csv\"\n",
    "\n",
    "# --- Prepare Output Directory ---\n",
    "# Extract the folder and filename from the full path.\n",
    "model_folder = os.path.dirname(select_file)\n",
    "file_basename = os.path.basename(select_file).split(\".\")[0]\n",
    "\n",
    "# Define the subfolder where all output plot images will be saved.\n",
    "savefig_folder = os.path.join(model_folder, r\"y_yhat_figs\")\n",
    "\n",
    "# Create the output folder if it doesn't already exist to prevent errors during saving.\n",
    "if not os.path.exists(savefig_folder):\n",
    "    os.makedirs(savefig_folder)\n",
    "\n",
    "# Define the starting date for the time series. The 'time_stamp' column in the\n",
    "# CSV is assumed to be an integer offset (in months) from this date.\n",
    "initial_timepoint = datetime(2016, 5, 1)\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# --- 2. DATA LOADING AND PRE-PROCESSING ---\n",
    "# This section loads the data from the CSV file and prepares it for analysis\n",
    "# by creating a unique key for each geographical point.\n",
    "# ==============================================================================\n",
    "\n",
    "# Extract a \"layer number\" from the filename to use in plot titles and saved filenames.\n",
    "# This assumes a consistent filename format like 'gtwr_Layer_1_...'.\n",
    "layer_number = os.path.basename(select_file).split(\"_\")[2]\n",
    "\n",
    "# Load the selected CSV file into a pandas DataFrame.\n",
    "df = pd.read_csv(select_file)\n",
    "\n",
    "# --- Create a Unique Identifier for Each Point ---\n",
    "# A 'PointKey' is created by combining the X and Y coordinates. This provides a\n",
    "# simple, readable key to group all time-series entries for a single location.\n",
    "pointkey_arr = [\n",
    "    f\"X{int(x)}Y{int(y)}\" for x, y in zip(df[\"X_TWD97\"], df[\"Y_TWD97\"])\n",
    "]\n",
    "# Insert this new 'PointKey' column at the beginning of the DataFrame.\n",
    "df.insert(loc=0, column=\"PointKey\", value=pointkey_arr)\n",
    "# Set 'PointKey' as the DataFrame's index for efficient data lookup using df.loc[].\n",
    "df = df.set_index(\"PointKey\")\n",
    "\n",
    "# Get a list of all unique point keys (i.e., all unique locations) in the dataset.\n",
    "unique_pointkey = df.index.unique()\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# --- 3. MAIN PROCESSING LOOP ---\n",
    "# This loop iterates through each unique point (location) in the dataset,\n",
    "# generating and saving a separate plot for each one.\n",
    "# A try-except block is used to ensure that an error with one point\n",
    "# does not stop the entire script.\n",
    "# ==============================================================================\n",
    "\n",
    "# Loop through each unique point. `tqdm` provides a progress bar.\n",
    "# Note: `unique_pointkey[:1]` is currently set to only process the FIRST point for testing.\n",
    "# To process all points, change it to `unique_pointkey`.\n",
    "for select_pointkey in tqdm(unique_pointkey[:], desc=\"Pointkey\", leave=False):\n",
    "    try:\n",
    "        # --- 3.1. Filter and Prepare Data for the Current Point ---\n",
    "\n",
    "        # Find the station name corresponding to the current PointKey.\n",
    "        # This assumes 'mlcw_gdf' is a GeoDataFrame loaded previously in the environment.\n",
    "        mlcw_station = mlcw_gdf.query(\n",
    "            \"PointKey==@select_pointkey\"\n",
    "        ).STATION.values[0]\n",
    "\n",
    "        # Filter the main DataFrame to get a new DataFrame containing only the\n",
    "        # time-series data for the currently selected point.\n",
    "        df_byPointKey = df.loc[select_pointkey]\n",
    "\n",
    "        # Convert the integer 'time_stamp' column into actual datetime objects.\n",
    "        # This is crucial for plotting the x-axis correctly.\n",
    "        df_byPointKey[\"time_stamp\"] = pd.to_datetime(\n",
    "            [\n",
    "                initial_timepoint + relativedelta(months=time_step)\n",
    "                for time_step in df_byPointKey[\"time_stamp\"]\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # --- 3.2. Extract Data Series for Plotting ---\n",
    "        # Assign columns to separate variables for cleaner plotting code.\n",
    "        time_arr = df_byPointKey[\"time_stamp\"]  # Time stamps for the x-axis\n",
    "        obs_val = df_byPointKey[\"y\"]  # Observed (actual) values\n",
    "        predict_val = df_byPointKey[\"yhat\"]  # Predicted values from the model\n",
    "        relative_err = df_byPointKey[\n",
    "            \"residual\"\n",
    "        ]  # Residuals (observed - predicted)\n",
    "\n",
    "        # Calculate the y-axis limits for the first plot, adding 20% padding for visual clarity.\n",
    "        obs_toplim = obs_val.max() + abs(obs_val.max() * 0.2)\n",
    "        obs_botlim = obs_val.min() - abs(obs_val.min() * 0.2)\n",
    "\n",
    "        # --- 3.3. Calculate Model Performance Metrics ---\n",
    "        # These metrics quantify how well the predictions match the observations.\n",
    "        r2 = r2_score(obs_val, predict_val)\n",
    "        rmse = root_mean_squared_error(obs_val, predict_val)\n",
    "        mae = mean_absolute_error(obs_val, predict_val)\n",
    "        pbias = 100.0 * np.sum(predict_val - obs_val) / np.sum(obs_val)\n",
    "\n",
    "        # ==========================================================================\n",
    "        # --- 3.4. VISUALIZATION ---\n",
    "        # This section creates the multi-panel plot.\n",
    "        # ==========================================================================\n",
    "\n",
    "        # Create a figure and a set of 4 subplots stacked vertically.\n",
    "        # `sharex=True` links the x-axes, so zooming one zooms them all.\n",
    "        fig, axes = plt.subplots(4, 1, figsize=(11.69, 8.27), sharex=True)\n",
    "\n",
    "        # Add a centered main title for the entire figure.\n",
    "        fig.suptitle(\n",
    "            f\"{mlcw_station} - Layer {layer_number}\",\n",
    "            y=0.975,\n",
    "            fontweight=\"bold\",\n",
    "            fontsize=20,\n",
    "        )\n",
    "\n",
    "        # --- Plot 1: Observations vs. Predictions ---\n",
    "        ax1 = axes[0]\n",
    "        # Plot observed values as a solid gray line.\n",
    "        ax1.plot(\n",
    "            time_arr,\n",
    "            obs_val,\n",
    "            color=\"darkgrey\",\n",
    "            linewidth=2,\n",
    "            marker=\"o\",\n",
    "            ms=8,\n",
    "            label=\"Observations\",\n",
    "            markevery=3,  # Reduces clutter by showing a marker only every 3 points.\n",
    "        )\n",
    "        # Plot predicted values as a blue dotted line.\n",
    "        ax1.plot(\n",
    "            time_arr,\n",
    "            predict_val,\n",
    "            color=\"blue\",\n",
    "            linestyle=(0, (1, 1)),  # Creates a dotted line style.\n",
    "            marker=\"o\",\n",
    "            ms=8,\n",
    "            linewidth=2,\n",
    "            label=\"Predictions\",\n",
    "            markevery=3,\n",
    "        )\n",
    "        ax1.set_ylim(bottom=obs_botlim, top=obs_toplim)\n",
    "\n",
    "        # Add a text box with the calculated performance metrics to the plot.\n",
    "        stats_text = (\n",
    "            f\"R²   : {r2:.3f}\\n\"\n",
    "            f\"RMSE : {rmse:.3f}\\n\"\n",
    "            f\"MAE  : {mae:.3f}\\n\"\n",
    "            f\"PBIAS: {pbias:.2f}%\"\n",
    "        )\n",
    "        ax1.text(\n",
    "            0.99,\n",
    "            0.99,\n",
    "            stats_text,\n",
    "            transform=ax1.transAxes,  # Positions text relative to the subplot axes.\n",
    "            ha=\"right\",  # Horizontal alignment.\n",
    "            va=\"top\",  # Vertical alignment.\n",
    "            fontsize=8,\n",
    "            fontfamily=\"monospace\",  # Ensures text aligns nicely.\n",
    "            bbox=dict(boxstyle=\"round,pad=0.5\", fc=\"#EAEAF2\", ec=\"black\", lw=1),\n",
    "        )\n",
    "\n",
    "        # --- Plot 2 & 3: Model Coefficients ---\n",
    "        # This loop efficiently plots the two CUMDISP coefficients on separate axes.\n",
    "        ax2 = axes[1]\n",
    "        ax3 = axes[2]\n",
    "        for ax, colname, color in zip(\n",
    "            [ax2, ax3],\n",
    "            [\"CUMDISP\", \"sq_CUMDISP\"],\n",
    "            [\"blueviolet\", \"mediumorchid\"],\n",
    "        ):\n",
    "            ax.plot(\n",
    "                time_arr,\n",
    "                df_byPointKey[colname],\n",
    "                color=color,\n",
    "                marker=\"s\",\n",
    "                markerfacecolor=\"none\",  # Creates hollow markers.\n",
    "                ms=8,\n",
    "                linewidth=2,\n",
    "                markevery=3,\n",
    "                label=colname,  # Label for the legend.\n",
    "            )\n",
    "\n",
    "        # --- Plot 4: Model Intercept ---\n",
    "        ax4 = axes[3]\n",
    "        ax4.plot(\n",
    "            time_arr,\n",
    "            df_byPointKey[\"Intercept\"],\n",
    "            color=\"black\",\n",
    "            marker=\"D\",\n",
    "            markerfacecolor=\"none\",\n",
    "            ms=8,\n",
    "            linewidth=2,\n",
    "            markevery=3,\n",
    "            label=\"Intercept\",  # Label for the legend.\n",
    "        )\n",
    "\n",
    "        # ==========================================================================\n",
    "        # --- 3.5. FINAL STYLING AND OUTPUT ---\n",
    "        # ==========================================================================\n",
    "\n",
    "        # Loop through all axes to apply consistent styling.\n",
    "        for ax in axes:\n",
    "            # `visualize.configure_axis` is a custom helper function for styling.\n",
    "            visualize.configure_axis(\n",
    "                ax=ax, tick_direction=\"out\", hide_spines=[\"top\", \"right\"]\n",
    "            )\n",
    "            # `visualize.configure_legend` is a custom helper for legend styling.\n",
    "            # This creates a separate legend for each subplot that has a label.\n",
    "            visualize.configure_legend(\n",
    "                ax=ax,\n",
    "                columnspacing=0.5,\n",
    "                labelspacing=0.1,\n",
    "                handletextpad=0.2,\n",
    "                ncols=4,\n",
    "                fontsize_base=14,\n",
    "            )\n",
    "            # `visualize.configure_datetime_ticks` is a custom helper for date formatting.\n",
    "            visualize.configure_datetime_ticks(\n",
    "                ax=ax,\n",
    "                major_interval=12,\n",
    "                minor_interval=3,\n",
    "                fontsize=14,\n",
    "                grid=False,\n",
    "                start_date=datetime(2016, 1, 1),\n",
    "                end_date=datetime(2022, 1, 1),\n",
    "            )\n",
    "\n",
    "        # --- Set Y-Axis Labels for Each Subplot ---\n",
    "        ax1.set_ylabel(\n",
    "            \"Cumulative\\nCompaction (mm)\",\n",
    "            loc=\"center\",\n",
    "            fontweight=\"bold\",\n",
    "            fontsize=14,\n",
    "        )\n",
    "        ax2.set_ylabel(\n",
    "            r\"$\\text{CUMDISP}$\" + \"\\nCoefficients\",\n",
    "            loc=\"center\",\n",
    "            fontweight=\"bold\",\n",
    "            fontsize=14,\n",
    "        )\n",
    "        ax3.set_ylabel(\n",
    "            r\"$\\text{CUMDISP}^{2}$\" + \"\\nCoefficients\",\n",
    "            loc=\"center\",\n",
    "            fontweight=\"bold\",\n",
    "            fontsize=14,\n",
    "        )\n",
    "        ax4.set_ylabel(\n",
    "            \"Intercept\", loc=\"center\", fontweight=\"bold\", fontsize=14\n",
    "        )\n",
    "\n",
    "        # --- Final Adjustments and Saving ---\n",
    "        # Adjust layout to prevent titles and labels from overlapping.\n",
    "        fig.tight_layout(rect=[0, 0.05, 1, 0.96])\n",
    "        # Automatically format x-axis date labels to prevent them from crowding.\n",
    "        fig.autofmt_xdate(ha=\"center\", rotation=90)\n",
    "\n",
    "        # Save the figure to the designated folder with a descriptive name.\n",
    "        visualize.save_figure(\n",
    "            fig=fig,\n",
    "            savepath=os.path.join(\n",
    "                savefig_folder,\n",
    "                \"_\".join([mlcw_station, \"layer\", layer_number]) + \".png\",\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        # Close the figure to free up memory before the next loop iteration.\n",
    "        plt.close(fig)\n",
    "\n",
    "    # This 'except' block will catch any error during the processing of a single\n",
    "    # point, print the error, and allow the loop to continue to the next point.\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process point {select_pointkey}. Error: {e}\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086856b1-2fa4-43bc-b6ae-60ec6bafb738",
   "metadata": {},
   "source": [
    "#### CUMDISP ~ Layer_1 + Layer_2 + Layer_3 + Layer_4"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5c0beae0-ce9c-48e9-8b0a-fde42d23868f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T03:12:05.266049Z",
     "iopub.status.busy": "2025-07-07T03:12:05.265554Z",
     "iopub.status.idle": "2025-07-07T03:12:20.384969Z",
     "shell.execute_reply": "2025-07-07T03:12:20.384969Z",
     "shell.execute_reply.started": "2025-07-07T03:12:05.266049Z"
    },
    "scrolled": true
   },
   "source": [
    "from sklearn.metrics import (\n",
    "    mean_absolute_error,\n",
    "    r2_score,\n",
    "    root_mean_squared_error,\n",
    ")\n",
    "\n",
    "select_file = r\"D:\\1000_SCRIPTS\\003_Project002\\20250222_GTWR001\\4_GTWR\\12_TestRun_112\\gtwr_run_output\\gtwr_CUMDISP_kernel-tricube_lambda-0d01_bw-36_coefficients.csv\"\n",
    "\n",
    "model_folder = os.path.dirname(select_file)\n",
    "file_basename = os.path.basename(select_file).split(\".\")[0]\n",
    "\n",
    "savefig_folder = os.path.join(model_folder, r\"y_yhat_figs\", \"_\".join(file_basename.split(\"_\")[3:]))\n",
    "\n",
    "if not os.path.exists(savefig_folder):\n",
    "    os.makedirs(savefig_folder)\n",
    "\n",
    "# Select the first file from the list for analysis.\n",
    "# select_file = output_files[0]\n",
    "\n",
    "# Extract a \"layer number\" from the filename by splitting the name and taking the third element ([2]).\n",
    "# layer_number = os.path.basename(select_file).split(\"_\")[2]\n",
    "\n",
    "# --- 3. DATA PROCESSING FOR A SELECTED POINT ---\n",
    "\n",
    "# Load the selected CSV file into a pandas DataFrame.\n",
    "df = pd.read_csv(select_file)\n",
    "# Create a unique identifier (\"PointKey\") for each row by combining the X and Y coordinates.\n",
    "# This is a common technique to create a simple, readable key for spatial points.\n",
    "pointkey_arr = [\n",
    "    f\"X{int(x*1000)}Y{int(y*1000)}\"\n",
    "    for x, y in zip(df[\"X_TWD97\"], df[\"Y_TWD97\"])\n",
    "]\n",
    "# Insert this new 'PointKey' column at the beginning of the DataFrame.\n",
    "df.insert(loc=0, column=\"PointKey\", value=pointkey_arr)\n",
    "# Set the 'PointKey' column as the DataFrame's index for efficient data lookup.\n",
    "df = df.set_index(\"PointKey\")\n",
    "\n",
    "# Get a list of all unique point keys (i.e., all unique locations) in the dataset.\n",
    "unique_pointkey = df.index.unique()\n",
    "\n",
    "# Select a specific point to analyze from the list of unique points. Here, the fifth point is chosen.\n",
    "# select_pointkey = unique_pointkey[4]\n",
    "for select_pointkey in tqdm(unique_pointkey[:], desc=\"Pointkey\", leave=False):\n",
    "\n",
    "    # Using the selected point key, find the corresponding station name from the initial GeoDataFrame.\n",
    "    mlcw_station = mlcw_gdf.query(\"PointKey==@select_pointkey\").STATION.values[\n",
    "        0\n",
    "    ]\n",
    "\n",
    "    # Filter the main DataFrame to get all time-series data for the selected point.\n",
    "    df_byPointKey = df.loc[select_pointkey]\n",
    "\n",
    "    # --- 4. PREPARE DATA FOR PLOTTING ---\n",
    "\n",
    "    # Extract the relevant data columns for plotting into separate variables for clarity.\n",
    "    time_arr = df_byPointKey[\"time_stamp\"]  # Time stamps for the x-axis\n",
    "    obs_val = df_byPointKey[\"y\"]  # Observed (actual) values\n",
    "    predict_val = df_byPointKey[\"yhat\"]  # Predicted values from the model\n",
    "    relative_err = df_byPointKey[\"residual\"]  # Residuals (observed - predicted)\n",
    "\n",
    "    # Calculate the upper and lower y-axis limits for the first plot to provide some padding.\n",
    "    obs_toplim = obs_val.max() + abs(obs_val.max() * 0.2)\n",
    "    obs_botlim = obs_val.min() - abs(obs_val.min() * 0.2)\n",
    "\n",
    "    # --- Step 1: Calculate Evaluation Metrics ---\n",
    "    # R-squared (Coefficient of Determination): Measures how well the predictions\n",
    "    # replicate the observed outcomes. A value of 1.0 is a perfect fit.\n",
    "    r2 = r2_score(obs_val, predict_val)\n",
    "\n",
    "    # Root Mean Squared Error (RMSE): The square root of average of the squared differences between\n",
    "    # observed and predicted values. It penalizes larger errors more heavily.\n",
    "    rmse = root_mean_squared_error(obs_val, predict_val)\n",
    "\n",
    "    # Mean Absolute Error (MAE): The average of the absolute differences.\n",
    "    # It gives a direct sense of the average magnitude of the error.\n",
    "    mae = mean_absolute_error(obs_val, predict_val)\n",
    "\n",
    "    # Percent Bias (PBIAS): Measures the average tendency of the predicted values\n",
    "    # to be larger or smaller than their observed counterparts.\n",
    "    # 0 is optimal. Positive values indicate overestimation bias, negative values\n",
    "    # indicate underestimation bias.\n",
    "    pbias = 100.0 * np.sum(predict_val - obs_val) / np.sum(obs_val)\n",
    "\n",
    "    # --- 5. VISUALIZATION ---\n",
    "\n",
    "    # Create a figure and a set of subplots (3 rows, 1 column) on an A4 landscape canvas.\n",
    "    # `sharex=True` links the x-axes of all subplots, so zooming one zooms them all.\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(11.69, 8.27), sharex=True)\n",
    "\n",
    "    # Add a centered main title to the figure, positioned slightly down from the top (`y=0.975`).\n",
    "    # fig.suptitle(f\"{mlcw_station} - Layer {layer_number}\", y=0.975, fontweight=\"bold\", fontsize=20)\n",
    "    fig.suptitle(f\"{mlcw_station}\", y=0.975, fontweight=\"bold\", fontsize=20)\n",
    "\n",
    "    # --- Plot 1: Observations vs. Predictions ---\n",
    "    ax1 = axes[0]\n",
    "    ax1.plot(\n",
    "        time_arr,\n",
    "        obs_val,\n",
    "        color=\"darkgrey\",\n",
    "        linewidth=2,\n",
    "        marker=\"o\",\n",
    "        markerfacecolor=\"none\",\n",
    "        ms=4,\n",
    "        label=\"Observations\",\n",
    "    )\n",
    "    ax1.plot(\n",
    "        time_arr,\n",
    "        predict_val,\n",
    "        color=\"blue\",\n",
    "        marker=\"o\",  # Use circle markers\n",
    "        markerfacecolor=\"none\",  # Make markers hollow\n",
    "        ms=4,  # Marker size\n",
    "        linewidth=2,\n",
    "        label=\"Predictions\",\n",
    "    )\n",
    "    ax1.set_ylim(\n",
    "        bottom=obs_botlim, top=obs_toplim\n",
    "    )  # Apply the calculated y-limits\n",
    "\n",
    "    # --- Step 2: Display Metrics on the Subplot ---\n",
    "    # Create a formatted string containing all the calculated metrics.\n",
    "    # Using an f-string makes it easy to embed the values.\n",
    "    # The '\\n' character creates a new line.\n",
    "    stats_text = (\n",
    "        f\"R-squared (R²): {r2:.3f}\\n\"\n",
    "        f\"RMSE: {rmse:.3f}\\n\"\n",
    "        f\"MAE: {mae:.3f}\\n\"\n",
    "        f\"PBIAS: {pbias:.2f}%\"\n",
    "    )\n",
    "\n",
    "    ax1.text(\n",
    "        0.025,\n",
    "        0.2,\n",
    "        stats_text,\n",
    "        ha=\"left\",\n",
    "        va=\"center\",\n",
    "        fontsize=10,\n",
    "        fontfamily=\"monospace\",\n",
    "        transform=ax1.transAxes,  # Use axes-relative coordinates\n",
    "        bbox=dict(boxstyle=\"round,pad=0.5\", fc=\"#EAEAF2\", ec=\"black\", lw=1),\n",
    "    )\n",
    "\n",
    "    # --- Plot 2: Cumulative Displacement Coefficient ---\n",
    "    ax2 = axes[1]\n",
    "    for lay in range(1, 5):\n",
    "        ax2.plot(\n",
    "            time_arr,\n",
    "            df_byPointKey[f\"Layer_{lay}\"],  # Assumed to be a model coefficient\n",
    "            # color=\"blueviolet\",\n",
    "            # linestyle=\"--\",  # Use a dashed line\n",
    "            marker=\"o\",  # Use square markers\n",
    "            # markerfacecolor=\"none\",\n",
    "            ms=4,\n",
    "            linewidth=2,\n",
    "            label=f\"Layer {lay}\",\n",
    "        )\n",
    "        # ax2.set_title(\"Coefficients\")\n",
    "\n",
    "    # --- Plot 3: Model Intercept ---\n",
    "    ax3 = axes[2]\n",
    "    ax3.plot(\n",
    "        time_arr,\n",
    "        df_byPointKey[\"Intercept\"],  # The model's intercept term over time\n",
    "        color=\"black\",\n",
    "        # linestyle=\"--\",\n",
    "        marker=\"D\",  # Use diamond markers\n",
    "        # markerfacecolor=\"none\",\n",
    "        ms=4,\n",
    "        linewidth=2,\n",
    "        label=\"Intercept\",\n",
    "    )\n",
    "    # ax3.set_title(\"Intercept\")\n",
    "\n",
    "    # --- 6. FINAL STYLING AND OUTPUT ---\n",
    "\n",
    "    # Loop through all axes to apply consistent styling using a custom helper function.\n",
    "    for ax in axes:\n",
    "        # `visualize.configure_axis` is a custom function to style the axis ticks and borders.\n",
    "        visualize.configure_axis(\n",
    "            ax=ax, tick_direction=\"out\", hide_spines=[\"top\", \"right\"]\n",
    "        )\n",
    "        # `visualize.configure_legend` is another custom function for legend styling.\n",
    "        visualize.configure_legend(\n",
    "            ax=ax,\n",
    "            columnspacing=0.5,\n",
    "            labelspacing=0.1,\n",
    "            handletextpad=0.2,\n",
    "            ncols=4,\n",
    "            fontsize_base=14,\n",
    "        )\n",
    "\n",
    "    ax1.set_ylabel(\n",
    "        \"Cumulative\\nCompaction (mm)\", loc=\"center\", fontweight=\"bold\"\n",
    "    )\n",
    "    ax2.set_ylabel(\"GTWR\\nCoefficients\", loc=\"center\", fontweight=\"bold\")\n",
    "    ax3.set_ylabel(\"GTWR\\nIntercept\", loc=\"center\", fontweight=\"bold\")\n",
    "\n",
    "    # Adjust subplot params for a tight layout to prevent titles/labels from overlapping.\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # The code to save the figure is commented out. If uncommented, it would save the plot as a PNG.\n",
    "    visualize.save_figure(\n",
    "        fig=fig,\n",
    "        savepath=os.path.join(\n",
    "            savefig_folder,\n",
    "            # \"_\".join([mlcw_station, \"layer\", layer_number]) + \".png\",\n",
    "            f\"{mlcw_station}.png\",\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # Display the final plot on the screen.\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f6094f-3dce-494b-be3f-aa99cfa9518f",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_pointkey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce3917e-5ba0-4371-b57a-873bf431f9fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
