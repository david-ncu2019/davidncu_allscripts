{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d680374a-01b8-4eec-b0dc-ef4e61911c54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T07:48:14.488342Z",
     "iopub.status.busy": "2024-09-17T07:48:14.488342Z",
     "iopub.status.idle": "2024-09-17T07:48:17.623849Z",
     "shell.execute_reply": "2024-09-17T07:48:17.623849Z",
     "shell.execute_reply.started": "2024-09-17T07:48:14.488342Z"
    }
   },
   "outputs": [],
   "source": [
    "from my_packages import *\n",
    "\n",
    "from appgeopy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9caeefd6-1f7c-4ead-84bb-e5e610093d81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T07:48:17.625720Z",
     "iopub.status.busy": "2024-09-17T07:48:17.625720Z",
     "iopub.status.idle": "2024-09-17T07:48:17.656753Z",
     "shell.execute_reply": "2024-09-17T07:48:17.655759Z",
     "shell.execute_reply.started": "2024-09-17T07:48:17.625720Z"
    }
   },
   "outputs": [],
   "source": [
    "# _______________________________________________________________________\n",
    "def detect_peaks_troughs(signal, time_index, prominence=True, dist=True):\n",
    "    \"\"\"\n",
    "    Detect peaks and troughs in a given signal.\n",
    "\n",
    "    Parameters:\n",
    "    - signal (array-like): The signal data where peaks and troughs are to be detected.\n",
    "    - time_index (array-like): Corresponding time index for the signal.\n",
    "    - prominence (bool): Whether to consider prominence in peak detection (default=True).\n",
    "    - dist (bool): Whether to consider distance in peak detection (default=True).\n",
    "\n",
    "    Returns:\n",
    "    - peaks, properties_peaks, peak_times: Detected peaks and their properties.\n",
    "    - troughs, properties_troughs, trough_times: Detected troughs and their properties.\n",
    "    \"\"\"\n",
    "    # Detect peaks in the signal\n",
    "    peaks, properties_peaks = scipy.signal.find_peaks(signal, prominence=prominence, distance=dist)\n",
    "    peak_times = time_index[peaks]\n",
    "\n",
    "    # Detect troughs by inverting the signal\n",
    "    troughs, properties_troughs = scipy.signal.find_peaks(-signal, prominence=prominence, distance=dist)\n",
    "    trough_times = time_index[troughs]\n",
    "\n",
    "    return peaks, properties_peaks, peak_times, troughs, properties_troughs, trough_times\n",
    "\n",
    "\n",
    "# ______________________________________________________________________\n",
    "def get_seasonal_and_trend_data(series, detrend_degree=2):\n",
    "    \"\"\"\n",
    "    Extracts the trend and seasonal components from a given time series using polynomial regression.\n",
    "\n",
    "    Parameters:\n",
    "        series (pd.Series): Time-series data.\n",
    "        detrend_degree (int): Degree of polynomial to use for detrending.\n",
    "\n",
    "    Returns:\n",
    "        tuple: The trend component and the detrended series.\n",
    "    \"\"\"\n",
    "    numeric_time_idx = datetime_handle.numeric_time_index(series)\n",
    "    finite_values = series[~series.isnull()].values\n",
    "\n",
    "    # Polynomial trend estimation\n",
    "    trend, _ = analysis.get_polynomial_trend(\n",
    "        x=numeric_time_idx,\n",
    "        y=finite_values,\n",
    "        order=detrend_degree,\n",
    "        x_estimate=np.arange(len(series)),\n",
    "    )\n",
    "    trend.index = series.index\n",
    "\n",
    "    # Detrending the series\n",
    "    detrended_series = series - trend\n",
    "\n",
    "    return trend, detrended_series\n",
    "\n",
    "\n",
    "# _______________________________________________________________________\n",
    "def get_threshold(dict_prop, prom_proportion=1, dist_proportion=1):\n",
    "    \"\"\"\n",
    "    Calculate thresholds for prominence and distance based on a proportion of the minimum values.\n",
    "\n",
    "    Parameters:\n",
    "    - dict_prop (dict): Dictionary of properties containing 'prominences' and 'left_bases'.\n",
    "    - proportion (float): Proportion of the minimum value to use for threshold calculation (default=0.8).\n",
    "\n",
    "    Returns:\n",
    "    - list: Threshold values for prominence and distance.\n",
    "    \"\"\"\n",
    "    prominence_array = dict_prop[\"prominences\"][np.where(dict_prop[\"prominences\"] > 0)]\n",
    "    prominence_thresh = np.min(prominence_array) * prom_proportion\n",
    "\n",
    "    distance_array = dict_prop[\"left_bases\"][np.where(dict_prop[\"left_bases\"] > 10)]\n",
    "    dist_thresh = np.min(distance_array) * dist_proportion\n",
    "    return [prominence_thresh, dist_thresh]\n",
    "\n",
    "\n",
    "# _______________________________________________________________________\n",
    "def filter_extremes_per_year(input_df, date_col, value_col, extreme_type=\"peak\"):\n",
    "    \"\"\"\n",
    "    Filters the extremes (peaks or troughs) by year, retaining only the highest peak or lowest trough per year.\n",
    "\n",
    "    Parameters:\n",
    "    - input_df (pd.DataFrame): DataFrame containing the time-series data (peaks or troughs).\n",
    "    - date_col (str): Column name for the date (datetime format).\n",
    "    - value_col (str): Column name for the values (peaks or troughs).\n",
    "    - extreme_type (str): Type of extreme ('peak' or 'trough'). Determines whether to retain highest or lowest value.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: A DataFrame with the highest peak or lowest trough retained for each year.\n",
    "    \"\"\"\n",
    "    df = input_df.copy()\n",
    "    df[\"Year\"] = pd.DatetimeIndex(df[date_col]).year\n",
    "\n",
    "    # Select either the highest peak or the lowest trough by grouping by year\n",
    "    if extreme_type == \"peak\":\n",
    "        filtered_df = df.loc[df.groupby(\"Year\")[value_col].idxmax()]\n",
    "    elif extreme_type == \"trough\":\n",
    "        filtered_df = df.loc[df.groupby(\"Year\")[value_col].idxmin()]\n",
    "\n",
    "    return filtered_df.drop(columns=[\"Year\"])\n",
    "\n",
    "\n",
    "# _______________________________________________________________________\n",
    "def filter_extremes_by_range(input_df, date_col, value_col, extreme_type=\"peak\", months_range=2):\n",
    "    \"\"\"\n",
    "    Filters the extremes (peaks or troughs) within a given range of months around each year.\n",
    "    Retains the two highest peaks or two lowest troughs within the search window, and ensures that no duplicate\n",
    "    peaks or troughs are selected in overlapping windows.\n",
    "\n",
    "    Parameters:\n",
    "    - input_df (pd.DataFrame): DataFrame containing the time-series data (peaks or troughs).\n",
    "    - date_col (str): Column name for the date (datetime format).\n",
    "    - value_col (str): Column name for the values (peaks or troughs).\n",
    "    - extreme_type (str): Type of extreme ('peak' or 'trough'). Determines whether to retain the highest or lowest values.\n",
    "    - months_range (int): Number of months before and after the current year to include in the search window.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: A DataFrame with the selected peaks or troughs for each window.\n",
    "    \"\"\"\n",
    "    df = input_df.copy()\n",
    "    df[date_col] = pd.to_datetime(df[date_col])\n",
    "\n",
    "    # Create a column for Year and Month for easier manipulation\n",
    "    df[\"Year\"] = pd.DatetimeIndex(df[date_col]).year\n",
    "    df[\"Month\"] = pd.DatetimeIndex(df[date_col]).month\n",
    "\n",
    "    # Initialize list to hold selected extremes\n",
    "    selected_extremes = []\n",
    "\n",
    "    # Iterate over each year in the dataset\n",
    "    for year in sorted(df[\"Year\"].unique()):\n",
    "        # Define the search window: year +/- x months\n",
    "        start_date = pd.Timestamp(year=year, month=1, day=1) - pd.DateOffset(months=months_range)\n",
    "        end_date = pd.Timestamp(year=year, month=12, day=31) + pd.DateOffset(months=months_range)\n",
    "\n",
    "        # Subset the data within the search window\n",
    "        window_df = df[(df[date_col] >= start_date) & (df[date_col] <= end_date)]\n",
    "\n",
    "        # If there is no data in the current window, skip this year\n",
    "        if window_df.empty:\n",
    "            continue\n",
    "\n",
    "        # Select either the top two peaks or the lowest two troughs\n",
    "        if extreme_type == \"peak\":\n",
    "            top_two_extremes = window_df.nlargest(2, value_col)\n",
    "        elif extreme_type == \"trough\":\n",
    "            top_two_extremes = window_df.nsmallest(2, value_col)\n",
    "\n",
    "        # Append the selected extremes (top two) to the result list\n",
    "        selected_extremes.append(top_two_extremes)\n",
    "\n",
    "        # Remove the selected extremes from the original dataframe to avoid selecting them again in the next window\n",
    "        df = df.drop(top_two_extremes.index)\n",
    "\n",
    "    # Combine the selected extremes from all windows\n",
    "    selected_extremes_df = pd.concat(selected_extremes).drop(columns=[\"Year\", \"Month\"])\n",
    "\n",
    "    return selected_extremes_df\n",
    "\n",
    "\n",
    "# _______________________________________________________________________\n",
    "def filter_consecutive(input_peaks, input_troughs, time_peak, value_peak, time_trough, value_trough):\n",
    "    \"\"\"\n",
    "    Filters out consecutive peaks or troughs, ensuring alternating patterns of peaks and troughs.\n",
    "\n",
    "    Parameters:\n",
    "    - input_peaks (pd.DataFrame): DataFrame containing peak data.\n",
    "    - input_troughs (pd.DataFrame): DataFrame containing trough data.\n",
    "    - time_peak (str): Column name for peak timestamps.\n",
    "    - value_peak (str): Column name for peak values.\n",
    "    - time_trough (str): Column name for trough timestamps.\n",
    "    - value_trough (str): Column name for trough values.\n",
    "\n",
    "    Returns:\n",
    "    - filtered_peaks, filtered_troughs (pd.DataFrame): Filtered DataFrames of peaks and troughs.\n",
    "    \"\"\"\n",
    "    peaks = input_peaks.copy()\n",
    "    troughs = input_troughs.copy()\n",
    "\n",
    "    # Combine peaks and troughs into one DataFrame, assign 'Type' column for identification\n",
    "    combined = pd.concat(\n",
    "        [\n",
    "            peaks[[time_peak, value_peak]].rename(columns={time_peak: \"Time\", value_peak: \"Value\"}).assign(Type=\"Peak\"),\n",
    "            troughs[[time_trough, value_trough]]\n",
    "            .rename(columns={time_trough: \"Time\", value_trough: \"Value\"})\n",
    "            .assign(Type=\"Trough\"),\n",
    "        ],\n",
    "        ignore_index=True,\n",
    "    )\n",
    "\n",
    "    combined = combined.sort_values(by=\"Time\").reset_index(drop=True)\n",
    "\n",
    "    # Filter alternating peaks and troughs\n",
    "    filtered = []\n",
    "    last_type = None\n",
    "\n",
    "    for _, row in combined.iterrows():\n",
    "        curr_type = row[\"Type\"]\n",
    "        curr_value = row[\"Value\"]\n",
    "\n",
    "        if last_type is None or curr_type != last_type:\n",
    "            filtered.append(row)\n",
    "            last_type = curr_type\n",
    "        else:\n",
    "            if curr_type == \"Peak\" and curr_value > filtered[-1][\"Value\"]:\n",
    "                filtered[-1] = row\n",
    "            elif curr_type == \"Trough\" and curr_value < filtered[-1][\"Value\"]:\n",
    "                filtered[-1] = row\n",
    "\n",
    "    # Convert filtered list back to DataFrame, separate back into peaks and troughs\n",
    "    filtered_df = pd.DataFrame(filtered)\n",
    "\n",
    "    filtered_peaks = filtered_df[filtered_df[\"Type\"] == \"Peak\"].rename(columns={\"Time\": time_peak, \"Value\": value_peak})\n",
    "\n",
    "    filtered_troughs = filtered_df[filtered_df[\"Type\"] == \"Trough\"].rename(\n",
    "        columns={\"Time\": time_trough, \"Value\": value_trough}\n",
    "    )\n",
    "\n",
    "    return [\n",
    "        filtered_peaks.drop(\"Type\", axis=1).reset_index(drop=True),\n",
    "        filtered_troughs.drop(\"Type\", axis=1).reset_index(drop=True),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c8de7b5-cfb5-4d71-ab21-b7ec5dc8bd54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T07:48:17.657752Z",
     "iopub.status.busy": "2024-09-17T07:48:17.656753Z",
     "iopub.status.idle": "2024-09-17T07:48:18.325887Z",
     "shell.execute_reply": "2024-09-17T07:48:18.325887Z",
     "shell.execute_reply.started": "2024-09-17T07:48:17.657752Z"
    }
   },
   "outputs": [],
   "source": [
    "# _______________________________________________________________________\n",
    "# Load HDF5 File and Extract Dataset Information\n",
    "hdf5_fpath = r\"20240903_GWL_CRFP.h5\"\n",
    "\n",
    "with h5py.File(hdf5_fpath, \"r\") as hdf5_file:\n",
    "    # Extract existing data and available datasets\n",
    "    existing_data_dict = h5pytools.hdf5_to_data_dict(hdf5_file)\n",
    "    available_datasets = h5pytools.list_datasets(hdf5_file)\n",
    "\n",
    "    # Extract the 'date' array and convert to a datetime index\n",
    "    date_strings = [date.decode(\"utf-8\") for date in existing_data_dict[\"date\"]]\n",
    "    datetime_array = pd.to_datetime(date_strings, format=\"%Y%m%d\")\n",
    "\n",
    "# _______________________________________________________________________\n",
    "# Extract the list of stations and wellcodes for processing\n",
    "stations = sorted(set([elem.split(\"/\")[0] for elem in available_datasets if \"date\" not in elem]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bb8757-5a99-4357-9b93-91516f779fae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T07:48:18.327752Z",
     "iopub.status.busy": "2024-09-17T07:48:18.327752Z",
     "iopub.status.idle": "2024-09-17T07:49:59.731318Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|████████████████████████████                                                     | 36/104 [01:40<03:09,  2.79s/it]\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 3417, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-4-fb7b04a6c3d4>\", line 231, in <module>\n",
      "    visualize.save_figure(fig, output_fig_path)\n",
      "  File \"C:\\Users\\FAFALAB\\miniconda3\\envs\\davidncu\\lib\\site-packages\\appgeopy\\visualize.py\", line 421, in save_figure\n",
      "    fig.savefig(\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\figure.py\", line 3046, in savefig\n",
      "    self.canvas.print_figure(fname, **kwargs)\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\backend_bases.py\", line 2299, in print_figure\n",
      "    bbox_inches = self.figure.get_tightbbox(\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\figure.py\", line 1684, in get_tightbbox\n",
      "    bbox = a.get_tightbbox(renderer)\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\axis.py\", line 1103, in get_tightbbox\n",
      "    ticks_to_draw = self._update_ticks()\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\axis.py\", line 1053, in _update_ticks\n",
      "    minor_locs = self.get_minorticklocs()\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\axis.py\", line 1282, in get_minorticklocs\n",
      "    major_locs = self.major.locator()\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\ticker.py\", line 2115, in __call__\n",
      "    return self.tick_values(vmin, vmax)\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\ticker.py\", line 2123, in tick_values\n",
      "    locs = self._raw_ticks(vmin, vmax)\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\ticker.py\", line 2062, in _raw_ticks\n",
      "    nbins = np.clip(self.axis.get_tick_space(),\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\axis.py\", line 2524, in get_tick_space\n",
      "    ends = ends.transformed(self.axes.transAxes -\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\transforms.py\", line 492, in transformed\n",
      "    ll, ul, lr = transform.transform(np.array(\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\transforms.py\", line 1503, in transform\n",
      "    res = self.transform_affine(self.transform_non_affine(values))\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\transforms.py\", line 2419, in transform_affine\n",
      "    return self.get_affine().transform(points)\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\transforms.py\", line 2446, in get_affine\n",
      "    return Affine2D(np.dot(self._b.get_affine().get_matrix(),\n",
      "  File \"<__array_function__ internals>\", line 200, in dot\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\FAFALAB\\miniconda3\\envs\\davidncu\\lib\\inspect.py\", line 1515, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\FAFALAB\\miniconda3\\envs\\davidncu\\lib\\inspect.py\", line 1473, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\FAFALAB\\miniconda3\\envs\\davidncu\\lib\\inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\FAFALAB\\miniconda3\\envs\\davidncu\\lib\\inspect.py\", line 754, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"C:\\Users\\FAFALAB\\miniconda3\\envs\\davidncu\\lib\\ntpath.py\", line 647, in realpath\n",
      "    path = _getfinalpathname(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 3417, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-4-fb7b04a6c3d4>\", line 231, in <module>\n",
      "    visualize.save_figure(fig, output_fig_path)\n",
      "  File \"C:\\Users\\FAFALAB\\miniconda3\\envs\\davidncu\\lib\\site-packages\\appgeopy\\visualize.py\", line 421, in save_figure\n",
      "    fig.savefig(\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\figure.py\", line 3046, in savefig\n",
      "    self.canvas.print_figure(fname, **kwargs)\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\backend_bases.py\", line 2299, in print_figure\n",
      "    bbox_inches = self.figure.get_tightbbox(\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\figure.py\", line 1684, in get_tightbbox\n",
      "    bbox = a.get_tightbbox(renderer)\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\axis.py\", line 1103, in get_tightbbox\n",
      "    ticks_to_draw = self._update_ticks()\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\axis.py\", line 1053, in _update_ticks\n",
      "    minor_locs = self.get_minorticklocs()\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\axis.py\", line 1282, in get_minorticklocs\n",
      "    major_locs = self.major.locator()\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\ticker.py\", line 2115, in __call__\n",
      "    return self.tick_values(vmin, vmax)\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\ticker.py\", line 2123, in tick_values\n",
      "    locs = self._raw_ticks(vmin, vmax)\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\ticker.py\", line 2062, in _raw_ticks\n",
      "    nbins = np.clip(self.axis.get_tick_space(),\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\axis.py\", line 2524, in get_tick_space\n",
      "    ends = ends.transformed(self.axes.transAxes -\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\transforms.py\", line 492, in transformed\n",
      "    ll, ul, lr = transform.transform(np.array(\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\transforms.py\", line 1503, in transform\n",
      "    res = self.transform_affine(self.transform_non_affine(values))\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\transforms.py\", line 2419, in transform_affine\n",
      "    return self.get_affine().transform(points)\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\transforms.py\", line 2446, in get_affine\n",
      "    return Affine2D(np.dot(self._b.get_affine().get_matrix(),\n",
      "  File \"<__array_function__ internals>\", line 200, in dot\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 3337, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 3434, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 2046, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(etype,\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\", line 1335, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\", line 1192, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\", line 1150, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\FAFALAB\\miniconda3\\envs\\davidncu\\lib\\inspect.py\", line 1515, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\FAFALAB\\miniconda3\\envs\\davidncu\\lib\\inspect.py\", line 1473, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\FAFALAB\\miniconda3\\envs\\davidncu\\lib\\inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\FAFALAB\\miniconda3\\envs\\davidncu\\lib\\inspect.py\", line 754, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"C:\\Users\\FAFALAB\\miniconda3\\envs\\davidncu\\lib\\ntpath.py\", line 664, in realpath\n",
      "    if _getfinalpathname(spath) == path:\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 3417, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-4-fb7b04a6c3d4>\", line 231, in <module>\n",
      "    visualize.save_figure(fig, output_fig_path)\n",
      "  File \"C:\\Users\\FAFALAB\\miniconda3\\envs\\davidncu\\lib\\site-packages\\appgeopy\\visualize.py\", line 421, in save_figure\n",
      "    fig.savefig(\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\figure.py\", line 3046, in savefig\n",
      "    self.canvas.print_figure(fname, **kwargs)\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\backend_bases.py\", line 2299, in print_figure\n",
      "    bbox_inches = self.figure.get_tightbbox(\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\figure.py\", line 1684, in get_tightbbox\n",
      "    bbox = a.get_tightbbox(renderer)\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\axis.py\", line 1103, in get_tightbbox\n",
      "    ticks_to_draw = self._update_ticks()\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\axis.py\", line 1053, in _update_ticks\n",
      "    minor_locs = self.get_minorticklocs()\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\axis.py\", line 1282, in get_minorticklocs\n",
      "    major_locs = self.major.locator()\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\ticker.py\", line 2115, in __call__\n",
      "    return self.tick_values(vmin, vmax)\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\ticker.py\", line 2123, in tick_values\n",
      "    locs = self._raw_ticks(vmin, vmax)\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\ticker.py\", line 2062, in _raw_ticks\n",
      "    nbins = np.clip(self.axis.get_tick_space(),\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\axis.py\", line 2524, in get_tick_space\n",
      "    ends = ends.transformed(self.axes.transAxes -\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\transforms.py\", line 492, in transformed\n",
      "    ll, ul, lr = transform.transform(np.array(\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\transforms.py\", line 1503, in transform\n",
      "    res = self.transform_affine(self.transform_non_affine(values))\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\transforms.py\", line 2419, in transform_affine\n",
      "    return self.get_affine().transform(points)\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\transforms.py\", line 2446, in get_affine\n",
      "    return Affine2D(np.dot(self._b.get_affine().get_matrix(),\n",
      "  File \"<__array_function__ internals>\", line 200, in dot\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 3337, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 3434, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 2046, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(etype,\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\", line 1335, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\", line 1192, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\", line 1150, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 2922, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 3145, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 3356, in run_ast_nodes\n",
      "    self.showtraceback()\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 2046, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(etype,\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\", line 1335, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\", line 1210, in structured_traceback\n",
      "    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\", line 1150, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\FAFALAB\\miniconda3\\envs\\davidncu\\lib\\inspect.py\", line 1515, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\FAFALAB\\miniconda3\\envs\\davidncu\\lib\\inspect.py\", line 1473, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\FAFALAB\\miniconda3\\envs\\davidncu\\lib\\inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\FAFALAB\\miniconda3\\envs\\davidncu\\lib\\inspect.py\", line 754, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"C:\\Users\\FAFALAB\\miniconda3\\envs\\davidncu\\lib\\ntpath.py\", line 664, in realpath\n",
      "    if _getfinalpathname(spath) == path:\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function flush_figures at 0x0000014E92C1D940> (for post_execute):\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 3417, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-4-fb7b04a6c3d4>\", line 231, in <module>\n",
      "    visualize.save_figure(fig, output_fig_path)\n",
      "  File \"C:\\Users\\FAFALAB\\miniconda3\\envs\\davidncu\\lib\\site-packages\\appgeopy\\visualize.py\", line 421, in save_figure\n",
      "    fig.savefig(\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\figure.py\", line 3046, in savefig\n",
      "    self.canvas.print_figure(fname, **kwargs)\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\backend_bases.py\", line 2299, in print_figure\n",
      "    bbox_inches = self.figure.get_tightbbox(\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\figure.py\", line 1684, in get_tightbbox\n",
      "    bbox = a.get_tightbbox(renderer)\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\axis.py\", line 1103, in get_tightbbox\n",
      "    ticks_to_draw = self._update_ticks()\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\axis.py\", line 1053, in _update_ticks\n",
      "    minor_locs = self.get_minorticklocs()\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\axis.py\", line 1282, in get_minorticklocs\n",
      "    major_locs = self.major.locator()\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\ticker.py\", line 2115, in __call__\n",
      "    return self.tick_values(vmin, vmax)\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\ticker.py\", line 2123, in tick_values\n",
      "    locs = self._raw_ticks(vmin, vmax)\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\ticker.py\", line 2062, in _raw_ticks\n",
      "    nbins = np.clip(self.axis.get_tick_space(),\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\axis.py\", line 2524, in get_tick_space\n",
      "    ends = ends.transformed(self.axes.transAxes -\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\transforms.py\", line 492, in transformed\n",
      "    ll, ul, lr = transform.transform(np.array(\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\transforms.py\", line 1503, in transform\n",
      "    res = self.transform_affine(self.transform_non_affine(values))\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\transforms.py\", line 2419, in transform_affine\n",
      "    return self.get_affine().transform(points)\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\transforms.py\", line 2446, in get_affine\n",
      "    return Affine2D(np.dot(self._b.get_affine().get_matrix(),\n",
      "  File \"<__array_function__ internals>\", line 200, in dot\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 3337, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 3434, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 2046, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(etype,\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\", line 1335, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\", line 1192, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\", line 1150, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 2922, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 3145, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 3356, in run_ast_nodes\n",
      "    self.showtraceback()\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 2046, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(etype,\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\", line 1335, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\", line 1210, in structured_traceback\n",
      "    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\", line 1150, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 2876, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 2927, in _run_cell\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 2046, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(etype,\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\", line 1335, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\", line 1210, in structured_traceback\n",
      "    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\", line 1150, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\events.py\", line 88, in trigger\n",
      "    func(*args, **kwargs)\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\pylab\\backend_inline.py\", line 121, in flush_figures\n",
      "    return show(True)\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\pylab\\backend_inline.py\", line 41, in show\n",
      "    display(\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\display.py\", line 313, in display\n",
      "    format_dict, md_dict = format(obj, include=include, exclude=exclude)\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\formatters.py\", line 180, in format\n",
      "    data = formatter(obj)\n",
      "  File \"C:\\Users\\FAFALAB\\miniconda3\\envs\\davidncu\\lib\\site-packages\\decorator.py\", line 232, in fun\n",
      "    return caller(func, *(extras + args), **kw)\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\formatters.py\", line 224, in catch_format_error\n",
      "    r = method(self, *args, **kwargs)\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\formatters.py\", line 341, in __call__\n",
      "    return printer(obj)\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\pylabtools.py\", line 248, in <lambda>\n",
      "    png_formatter.for_type(Figure, lambda fig: print_figure(fig, 'png', **kwargs))\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\pylabtools.py\", line 132, in print_figure\n",
      "    fig.canvas.print_figure(bytes_io, **kw)\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\backend_bases.py\", line 2299, in print_figure\n",
      "    bbox_inches = self.figure.get_tightbbox(\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\figure.py\", line 1684, in get_tightbbox\n",
      "    bbox = a.get_tightbbox(renderer)\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\axis.py\", line 1105, in get_tightbbox\n",
      "    self._update_label_position(renderer)\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\axis.py\", line 2083, in _update_label_position\n",
      "    bboxes, bboxes2 = self._get_tick_boxes_siblings(renderer=renderer)\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\axis.py\", line 1880, in _get_tick_boxes_siblings\n",
      "    ticks_to_draw = axis._update_ticks()\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\axis.py\", line 1053, in _update_ticks\n",
      "    minor_locs = self.get_minorticklocs()\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\axis.py\", line 1282, in get_minorticklocs\n",
      "    major_locs = self.major.locator()\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\dates.py\", line 1174, in __call__\n",
      "    return self.tick_values(dmin, dmax)\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\dates.py\", line 1181, in tick_values\n",
      "    return self.raise_if_exceeds(date2num(dates))\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\dates.py\", line 448, in date2num\n",
      "    d = _dt64_to_ordinalf(d)\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\dates.py\", line 317, in _dt64_to_ordinalf\n",
      "    extra = (d - dseconds).astype('timedelta64[ns]')\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\FAFALAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\FAFALAB\\miniconda3\\envs\\davidncu\\lib\\inspect.py\", line 1515, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\FAFALAB\\miniconda3\\envs\\davidncu\\lib\\inspect.py\", line 1473, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\FAFALAB\\miniconda3\\envs\\davidncu\\lib\\inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\FAFALAB\\miniconda3\\envs\\davidncu\\lib\\inspect.py\", line 751, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"C:\\Users\\FAFALAB\\miniconda3\\envs\\davidncu\\lib\\inspect.py\", line 720, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"C:\\Users\\FAFALAB\\miniconda3\\envs\\davidncu\\lib\\inspect.py\", line 705, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"C:\\Users\\FAFALAB\\miniconda3\\envs\\davidncu\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "error_station = []\n",
    "\n",
    "save_Excel = True\n",
    "save_Figure = True\n",
    "\n",
    "for i in range(1, 10000):\n",
    "    savefolder = f\"Attemp{i:03}\"\n",
    "    if not os.path.exists(savefolder):\n",
    "        # Your code to create or use the savefolder goes here\n",
    "        break\n",
    "\n",
    "\n",
    "# station = \"DONGFANG\"\n",
    "for station in tqdm(stations[::]):\n",
    "    try:\n",
    "\n",
    "        # _______________________________________________________________________\n",
    "        # Extract and process station data\n",
    "        station_data = existing_data_dict[station]\n",
    "        wellcodes = [elem for elem, val in station_data.items() if isinstance(val, dict) and len(val) == 3]\n",
    "        # wellcode = wellcodes[1]\n",
    "        for wellcode in wellcodes:\n",
    "\n",
    "            # _______________________________________________________________________\n",
    "            # Extract time-series data and process the valid data range\n",
    "            model_gwl_arr = station_data[wellcode][\"measure\"][\"model\"]\n",
    "            model_gwl_series = pd.Series(data=model_gwl_arr, index=datetime_array)\n",
    "            valid_gwl_series = model_gwl_series.loc[\n",
    "                model_gwl_series.first_valid_index() : model_gwl_series.last_valid_index()\n",
    "            ]\n",
    "            # valid_gwl_series = model_gwl_series.loc[pd.to_datetime(\"2016-01-01\") : pd.to_datetime(\"2023-01-01\")]\n",
    "\n",
    "            if valid_gwl_series.index.year.unique().size > 2:\n",
    "\n",
    "                trend, detrended_series = get_seasonal_and_trend_data(series=valid_gwl_series, detrend_degree=3)\n",
    "\n",
    "                # _______________________________________________________________________\n",
    "                # Apply smoothing on the time series\n",
    "                smoothed_series = smoothing.simple_moving_average(num_arr=detrended_series, window_size=11)\n",
    "\n",
    "                # _______________________________________________________________________\n",
    "                # Detect peaks and troughs\n",
    "                peaks, properties_peaks, peak_times, troughs, properties_troughs, trough_times = detect_peaks_troughs(\n",
    "                    signal=smoothed_series.values, time_index=smoothed_series.index\n",
    "                )\n",
    "\n",
    "                # _______________________________________________________________________\n",
    "                # Calculate thresholds for peaks and troughs\n",
    "                peak_prom, peak_dist = get_threshold(properties_peaks, prom_proportion=0.8, dist_proportion=0.8)\n",
    "                trough_prom, trough_dist = get_threshold(properties_troughs, prom_proportion=0.5, dist_proportion=0.5)\n",
    "\n",
    "                peak_dist = 2 if peak_dist < 1 else peak_dist\n",
    "                trough_dist = 2 if trough_dist < 1 else trough_dist\n",
    "                # _______________________________________________________________________\n",
    "                # Redetect peaks and troughs based on thresholds\n",
    "                peaks, _ = scipy.signal.find_peaks(smoothed_series.values, prominence=peak_prom, distance=peak_dist)\n",
    "                peak_times = smoothed_series.index[peaks]\n",
    "                troughs, _ = scipy.signal.find_peaks(\n",
    "                    -smoothed_series.values, prominence=trough_prom, distance=trough_dist\n",
    "                )\n",
    "                trough_times = smoothed_series.index[troughs]\n",
    "                # _______________________________________________________________________\n",
    "                # Convert to DataFrames\n",
    "                signal_peaks = pd.DataFrame(data={\"time\": peak_times, \"value\": valid_gwl_series[peak_times].values})\n",
    "                signal_troughs = pd.DataFrame(\n",
    "                    data={\"time\": trough_times, \"value\": valid_gwl_series[trough_times].values}\n",
    "                )\n",
    "\n",
    "                # _______________________________________________________________________\n",
    "                # Filter extremes per year for peaks and troughs\n",
    "                # filtered_peaks = filter_extremes_per_year(\n",
    "                #     signal_peaks, date_col=\"time\", value_col=\"value\", extreme_type=\"peak\"\n",
    "                # )\n",
    "                filtered_peaks = filter_extremes_by_range(\n",
    "                    signal_peaks, date_col=\"time\", value_col=\"value\", extreme_type=\"peak\", months_range=3\n",
    "                )\n",
    "                # filtered_troughs = filter_extremes_per_year(\n",
    "                #     signal_troughs, date_col=\"time\", value_col=\"value\", extreme_type=\"trough\"\n",
    "                # )\n",
    "                filtered_troughs = filter_extremes_by_range(\n",
    "                    signal_troughs, date_col=\"time\", value_col=\"value\", extreme_type=\"trough\", months_range=3\n",
    "                )\n",
    "\n",
    "                # _______________________________________________________________________\n",
    "                # Apply filtering for consecutive peaks and troughs\n",
    "                final_peaks, final_troughs = filter_consecutive(\n",
    "                    input_peaks=filtered_peaks,\n",
    "                    # input_peaks=signal_peaks,\n",
    "                    input_troughs=filtered_troughs,\n",
    "                    # input_troughs=signal_troughs,\n",
    "                    time_peak=\"time\",\n",
    "                    value_peak=\"value\",\n",
    "                    time_trough=\"time\",\n",
    "                    value_trough=\"value\",\n",
    "                )\n",
    "\n",
    "                if save_Excel:\n",
    "                    fld2saveExcel = os.path.join(savefolder, \"Peaks_Troughs\")\n",
    "                    os.makedirs(fld2saveExcel, exist_ok=True)\n",
    "\n",
    "                    savepath = os.path.join(fld2saveExcel, f\"{station}_{wellcode}.xlsx\")\n",
    "\n",
    "                    if not os.path.isfile(savepath):\n",
    "                        final_peaks.to_excel(savepath, index=False, sheet_name=\"peaks\")\n",
    "                        data_io.save_df_to_excel(\n",
    "                            df_to_save=final_troughs, filepath=savepath, sheet_name=\"troughs\", verbose=False\n",
    "                        )\n",
    "                    else:\n",
    "                        print(\"Target file has already existed!\")\n",
    "                        continue\n",
    "\n",
    "                # _______________________________________________________________________\n",
    "\n",
    "                fig_width, fig_height = (11.7 * 3 / 2, 8.3 * 2 / 3)\n",
    "                fig = plt.figure(figsize=(fig_width, fig_height))\n",
    "\n",
    "                ax = fig.add_subplot(111)\n",
    "                # _______________________________________________________________________\n",
    "                # Plot the valid groundwater level series\n",
    "                ax.plot(valid_gwl_series, color=\"black\", zorder=1)\n",
    "\n",
    "                # _______________________________________________________________________\n",
    "\n",
    "                # Plot all detected peaks (in grey with transparency)\n",
    "                ax.plot(\n",
    "                    signal_peaks.set_index(\"time\"),\n",
    "                    marker=\"o\",\n",
    "                    linestyle=\" \",\n",
    "                    markersize=14,\n",
    "                    zorder=1,\n",
    "                    color=\"none\",\n",
    "                    markeredgecolor=\"black\",\n",
    "                    alpha=0.5,\n",
    "                )\n",
    "\n",
    "                # Plot filtered peaks (by year, in blue)\n",
    "                ax.plot(\n",
    "                    filtered_peaks.set_index(\"time\"),\n",
    "                    marker=\"s\",\n",
    "                    linestyle=\" \",\n",
    "                    markersize=12,\n",
    "                    zorder=2,\n",
    "                    color=\"blue\",\n",
    "                    alpha=0.2,\n",
    "                )\n",
    "\n",
    "                # Plot final filtered peaks (after consecutive filtering, in lime green)\n",
    "                ax.plot(\n",
    "                    final_peaks.set_index(\"time\"),\n",
    "                    marker=\"^\",\n",
    "                    linestyle=(0, (1, 2)),\n",
    "                    markersize=10,\n",
    "                    zorder=3,\n",
    "                    color=\"lime\",\n",
    "                    markeredgecolor=\"black\",\n",
    "                    alpha=1,\n",
    "                    label=\"Peaks\",\n",
    "                )\n",
    "\n",
    "                # _______________________________________________________________________\n",
    "\n",
    "                # Plot all detected troughs (in grey with transparency)\n",
    "                ax.plot(\n",
    "                    signal_troughs.set_index(\"time\"),\n",
    "                    marker=\"o\",\n",
    "                    linestyle=\" \",\n",
    "                    markersize=14,\n",
    "                    color=\"none\",\n",
    "                    markeredgecolor=\"black\",\n",
    "                    zorder=1,\n",
    "                    alpha=0.5,\n",
    "                )\n",
    "\n",
    "                # Plot filtered troughs (by year, in red)\n",
    "                ax.plot(\n",
    "                    filtered_troughs.set_index(\"time\"),\n",
    "                    marker=\"s\",\n",
    "                    linestyle=\" \",\n",
    "                    markersize=12,\n",
    "                    color=\"darkorange\",\n",
    "                    zorder=2,\n",
    "                    alpha=0.2,\n",
    "                )\n",
    "\n",
    "                # Plot final filtered troughs (after consecutive filtering, in magenta)\n",
    "                ax.plot(\n",
    "                    final_troughs.set_index(\"time\"),\n",
    "                    marker=\"^\",\n",
    "                    linestyle=(0, (1, 2)),\n",
    "                    markersize=10,\n",
    "                    color=\"magenta\",\n",
    "                    markeredgecolor=\"black\",\n",
    "                    zorder=3,\n",
    "                    alpha=1,\n",
    "                    label=\"Troughs\",\n",
    "                )\n",
    "\n",
    "                # _______________________________________________________________________\n",
    "\n",
    "                # Configure datetime ticks for the x-axis\n",
    "                visualize.configure_axis(\n",
    "                    ax=ax,\n",
    "                    xlabel=\"\",\n",
    "                    ylabel=\"Groundwater Levels (m)\",\n",
    "                    scaling_factor=1.2,\n",
    "                    title=f\"{station} - {wellcode}\",\n",
    "                )\n",
    "                visualize.configure_datetime_ticks(ax=ax, axis=\"x\")\n",
    "                visualize.configure_legend(ax=ax, scaling_factor=1, frameon=False, fontsize_base=12)\n",
    "\n",
    "                # _______________________________________________________________________\n",
    "\n",
    "                # Add grid and set layout for better readability\n",
    "                ax.grid(axis=\"x\", which=\"major\", linestyle=\"-\", linewidth=1, color=\"grey\")\n",
    "                ax.grid(axis=\"x\", which=\"minor\", linestyle=\"--\", linewidth=1, color=\"lightgrey\")\n",
    "                ax.set_axisbelow(True)\n",
    "                ax.set_xlim(datetime(2000, 1, 1), datetime(2025, 1, 1))\n",
    "\n",
    "                # _______________________________________________________________________\n",
    "\n",
    "                # Optimize layout and show the plot\n",
    "                fig.tight_layout()\n",
    "                # Apply rotation to the x-tick labels on the shared axis (ax3)\n",
    "                plt.setp(ax.get_xticklabels(), rotation=90, ha=\"center\")\n",
    "\n",
    "                # _______________________________________________________________________\n",
    "                if save_Figure:\n",
    "                    fld2savefig = os.path.join(savefolder, \"Figures\")\n",
    "                    os.makedirs(fld2savefig, exist_ok=True)\n",
    "                    output_fig_path = os.path.join(fld2savefig, f\"{station}_{wellcode}.png\")\n",
    "                    visualize.save_figure(fig, output_fig_path)\n",
    "\n",
    "                plt.close()\n",
    "                # _______________________________________________________________________\n",
    "    except Exception as e:\n",
    "        print(f\"{station}_{wellcode}\", e)\n",
    "        error_station.append(f\"{station}_{wellcode}\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55295b66-4af6-4b25-a1d5-7f057958fcc9",
   "metadata": {},
   "source": [
    "#### SINGLE STATION MODIFICATION"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ec5ee2d4-c672-4a73-abab-c03c9934fce4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T07:23:30.384346Z",
     "iopub.status.busy": "2024-09-17T07:23:30.384346Z",
     "iopub.status.idle": "2024-09-17T07:23:31.058349Z",
     "shell.execute_reply": "2024-09-17T07:23:31.057347Z",
     "shell.execute_reply.started": "2024-09-17T07:23:30.384346Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "savefolder = \"Attemp002\"\n",
    "\n",
    "save_Excel = False\n",
    "save_Figure = False\n",
    "\n",
    "station = \"QUANXING\"\n",
    "# _______________________________________________________________________\n",
    "# Extract and process station data\n",
    "station_data = existing_data_dict[station]\n",
    "wellcodes = [elem for elem, val in station_data.items() if isinstance(val, dict) and len(val) == 3]\n",
    "\n",
    "wellcode = \"07050132\"\n",
    "\n",
    "# _______________________________________________________________________\n",
    "# Extract time-series data and process the valid data range\n",
    "model_gwl_arr = station_data[wellcode][\"measure\"][\"model\"]\n",
    "model_gwl_series = pd.Series(data=model_gwl_arr, index=datetime_array)\n",
    "valid_gwl_series = model_gwl_series.loc[\n",
    "    model_gwl_series.first_valid_index() : model_gwl_series.last_valid_index()\n",
    "]\n",
    "\n",
    "if valid_gwl_series.index.year.unique().size > 2:\n",
    "\n",
    "    trend, detrended_series = get_seasonal_and_trend_data(series=valid_gwl_series, detrend_degree=3)\n",
    "\n",
    "    # _______________________________________________________________________\n",
    "    # Apply smoothing on the time series\n",
    "    smoothed_series = smoothing.simple_moving_average(num_arr=detrended_series, window_size=15)\n",
    "\n",
    "    # _______________________________________________________________________\n",
    "    # Detect peaks and troughs\n",
    "    peaks, properties_peaks, peak_times, troughs, properties_troughs, trough_times = detect_peaks_troughs(\n",
    "        signal=smoothed_series.values, time_index=smoothed_series.index\n",
    "    )\n",
    "\n",
    "    # _______________________________________________________________________\n",
    "    # Calculate thresholds for peaks and troughs\n",
    "    peak_prom, peak_dist = get_threshold(properties_peaks, prom_proportion=0.9, dist_proportion=0.3)\n",
    "    trough_prom, trough_dist = get_threshold(properties_troughs, prom_proportion=0.9, dist_proportion=0.3)\n",
    "\n",
    "    peak_dist = 1 if peak_dist < 1 else peak_dist\n",
    "    # _______________________________________________________________________\n",
    "    # Redetect peaks and troughs based on thresholds\n",
    "    peaks, _ = scipy.signal.find_peaks(smoothed_series.values, prominence=peak_prom, distance=peak_dist)\n",
    "    peak_times = smoothed_series.index[peaks]\n",
    "    troughs, _ = scipy.signal.find_peaks(\n",
    "        -smoothed_series.values, prominence=trough_prom, distance=trough_dist\n",
    "    )\n",
    "    trough_times = smoothed_series.index[troughs]\n",
    "    # _______________________________________________________________________\n",
    "    # Convert to DataFrames\n",
    "    signal_peaks = pd.DataFrame(data={\"time\": peak_times, \"value\": valid_gwl_series[peak_times].values})\n",
    "    signal_troughs = pd.DataFrame(\n",
    "        data={\"time\": trough_times, \"value\": valid_gwl_series[trough_times].values}\n",
    "    )\n",
    "\n",
    "    # _______________________________________________________________________\n",
    "    # Filter extremes per year for peaks and troughs\n",
    "    # filtered_peaks = filter_extremes_per_year(\n",
    "    #     signal_peaks, date_col=\"time\", value_col=\"value\", extreme_type=\"peak\"\n",
    "    # )\n",
    "    filtered_peaks = filter_extremes_by_range(\n",
    "        signal_peaks, date_col=\"time\", value_col=\"value\", extreme_type=\"peak\", months_range=2\n",
    "    )\n",
    "    # filtered_troughs = filter_extremes_per_year(\n",
    "    #     signal_troughs, date_col=\"time\", value_col=\"value\", extreme_type=\"trough\"\n",
    "    # )\n",
    "    filtered_troughs = filter_extremes_by_range(\n",
    "        signal_troughs, date_col=\"time\", value_col=\"value\", extreme_type=\"trough\", months_range=2\n",
    "    )\n",
    "\n",
    "    # _______________________________________________________________________\n",
    "    # Apply filtering for consecutive peaks and troughs\n",
    "    final_peaks, final_troughs = filter_consecutive(\n",
    "        input_peaks=filtered_peaks,\n",
    "        input_troughs=filtered_troughs,\n",
    "        time_peak=\"time\",\n",
    "        value_peak=\"value\",\n",
    "        time_trough=\"time\",\n",
    "        value_trough=\"value\",\n",
    "    )\n",
    "\n",
    "    if save_Excel:\n",
    "        fld2saveExcel = os.path.join(savefolder, \"Peaks_Troughs\")\n",
    "        os.makedirs(fld2saveExcel, exist_ok=True)\n",
    "    \n",
    "        savepath = os.path.join(fld2saveExcel, f\"{station}_{wellcode}.xlsx\")\n",
    "    \n",
    "        if not os.path.isfile(savepath):\n",
    "            final_peaks.to_excel(savepath, index=False, sheet_name=\"peaks\")\n",
    "            data_io.save_df_to_excel(\n",
    "                df_to_save=final_troughs, filepath=savepath, sheet_name=\"troughs\", verbose=False\n",
    "            )\n",
    "        else:\n",
    "            print(\"Target file has already existed!\")\n",
    "\n",
    "    # _______________________________________________________________________\n",
    "\n",
    "    fig_width, fig_height = (11.7 * 3 / 2, 8.3 * 2 / 3)\n",
    "    fig = plt.figure(figsize=(fig_width, fig_height))\n",
    "\n",
    "    ax = fig.add_subplot(111)\n",
    "    # _______________________________________________________________________\n",
    "    # Plot the valid groundwater level series\n",
    "    ax.plot(valid_gwl_series, color=\"black\", zorder=1)\n",
    "\n",
    "    # _______________________________________________________________________\n",
    "\n",
    "    # Plot all detected peaks (in grey with transparency)\n",
    "    ax.plot(\n",
    "        signal_peaks.set_index(\"time\"),\n",
    "        marker=\"o\",\n",
    "        linestyle=\" \",\n",
    "        markersize=14,\n",
    "        zorder=1,\n",
    "        color=\"none\",\n",
    "        markeredgecolor=\"black\",\n",
    "        alpha=0.5,\n",
    "    )\n",
    "\n",
    "    # Plot filtered peaks (by year, in blue)\n",
    "    ax.plot(\n",
    "        filtered_peaks.set_index(\"time\"),\n",
    "        marker=\"s\",\n",
    "        linestyle=\" \",\n",
    "        markersize=12,\n",
    "        zorder=2,\n",
    "        color=\"blue\",\n",
    "        alpha=0.2,\n",
    "    )\n",
    "\n",
    "    # Plot final filtered peaks (after consecutive filtering, in lime green)\n",
    "    ax.plot(\n",
    "        final_peaks.set_index(\"time\"),\n",
    "        marker=\"^\",\n",
    "        linestyle=(0, (1, 2)),\n",
    "        markersize=10,\n",
    "        zorder=3,\n",
    "        color=\"lime\",\n",
    "        markeredgecolor=\"black\",\n",
    "        alpha=1,\n",
    "        label=\"Peaks\",\n",
    "    )\n",
    "\n",
    "    # _______________________________________________________________________\n",
    "\n",
    "    # Plot all detected troughs (in grey with transparency)\n",
    "    ax.plot(\n",
    "        signal_troughs.set_index(\"time\"),\n",
    "        marker=\"o\",\n",
    "        linestyle=\" \",\n",
    "        markersize=14,\n",
    "        color=\"none\",\n",
    "        markeredgecolor=\"black\",\n",
    "        zorder=1,\n",
    "        alpha=0.5,\n",
    "    )\n",
    "\n",
    "    # Plot filtered troughs (by year, in red)\n",
    "    ax.plot(\n",
    "        filtered_troughs.set_index(\"time\"),\n",
    "        marker=\"s\",\n",
    "        linestyle=\" \",\n",
    "        markersize=12,\n",
    "        color=\"darkorange\",\n",
    "        zorder=2,\n",
    "        alpha=0.2,\n",
    "    )\n",
    "\n",
    "    # Plot final filtered troughs (after consecutive filtering, in magenta)\n",
    "    ax.plot(\n",
    "        final_troughs.set_index(\"time\"),\n",
    "        marker=\"^\",\n",
    "        linestyle=(0, (1, 2)),\n",
    "        markersize=10,\n",
    "        color=\"magenta\",\n",
    "        markeredgecolor=\"black\",\n",
    "        zorder=3,\n",
    "        alpha=1,\n",
    "        label=\"Troughs\",\n",
    "    )\n",
    "\n",
    "    # _______________________________________________________________________\n",
    "\n",
    "    # Configure datetime ticks for the x-axis\n",
    "    visualize.configure_axis(\n",
    "        ax=ax,\n",
    "        xlabel=\"\",\n",
    "        ylabel=\"Groundwater Levels (m)\",\n",
    "        scaling_factor=1.2,\n",
    "        title=f\"{station} - {wellcode}\",\n",
    "    )\n",
    "    visualize.configure_datetime_ticks(ax=ax, axis=\"x\")\n",
    "    visualize.configure_legend(ax=ax, scaling_factor=1, frameon=False, fontsize_base=12)\n",
    "\n",
    "    # _______________________________________________________________________\n",
    "\n",
    "    # Add grid and set layout for better readability\n",
    "    ax.grid(axis=\"x\", which=\"major\", linestyle=\"-\", linewidth=1, color=\"grey\")\n",
    "    ax.grid(axis=\"x\", which=\"minor\", linestyle=\"--\", linewidth=1, color=\"lightgrey\")\n",
    "    ax.set_axisbelow(True)\n",
    "    ax.set_xlim(datetime(2000, 1, 1), datetime(2025, 1, 1))\n",
    "\n",
    "    # _______________________________________________________________________\n",
    "\n",
    "    # Optimize layout and show the plot\n",
    "    fig.tight_layout()\n",
    "    # Apply rotation to the x-tick labels on the shared axis (ax3)\n",
    "    plt.setp(ax.get_xticklabels(), rotation=90, ha=\"center\")\n",
    "\n",
    "    # _______________________________________________________________________\n",
    "    if save_Figure:\n",
    "        fld2savefig = os.path.join(savefolder, \"Figures\")\n",
    "        os.makedirs(fld2savefig, exist_ok=True)\n",
    "        output_fig_path = os.path.join(fld2savefig, f\"{station}_{wellcode}.png\")\n",
    "        visualize.save_figure(fig, output_fig_path)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    # _______________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a2f51f-140b-4588-86fb-58a581e220d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
