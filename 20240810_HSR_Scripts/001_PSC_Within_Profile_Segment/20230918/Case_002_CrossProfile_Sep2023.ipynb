{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c977b56e-ac61-462c-9fd6-0b4384dda555",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940e7c8a-9c5f-4131-a4f0-11fc437de46c",
   "metadata": {},
   "source": [
    "**Extract PSC within segments**\n",
    "\n",
    "Input file:\n",
    "- segment shapefiles\n",
    "    - segment file required column: C_Length (cumulative length) & Name (Seg_{!C_Length!})\n",
    "- ps point data shapefile\n",
    "\n",
    "Implemented fuction:\n",
    "- `PSC_Within_Profile_Segment()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a53d2aea-a276-4f7a-9612-ad3d494e965f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_parameter_record(savefolder, params_dict):\n",
    "\n",
    "    import os\n",
    "\n",
    "    for i in range(1, 1000):\n",
    "        savepath = os.path.join(savefolder, \"Param_Record_{}.txt\".format(str(i).zfill(3)))\n",
    "        if os.path.exists(savepath):\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    with open(savepath, \"w+\") as file:\n",
    "        for key, value in params_dict.items():\n",
    "            file.write(\"{} : {}\".format(key, value))\n",
    "            file.write(\"\\n\\n\")\n",
    "    pop_up_string = \"Saved at {}\".format(savefolder)\n",
    "    print(pop_up_string)\n",
    "\n",
    "\n",
    "def open_geodata(filepath):\n",
    "    import sys\n",
    "\n",
    "    import geopandas as gpd\n",
    "\n",
    "    geodata_type = type(gpd.GeoDataFrame())\n",
    "\n",
    "    if type(filepath) == geodata_type:\n",
    "        geodata = filepath\n",
    "    elif type(filepath) == str:\n",
    "        extension = filepath.split(\".\")[-1]\n",
    "        if extension == \"pkl\":\n",
    "            geodata = pd.read_pickle(filepath, compression=\"zip\")\n",
    "        elif extension == \"shp\":\n",
    "            geodata = gpd.read_file(filepath)\n",
    "        else:\n",
    "            sys.exit(\n",
    "                \"The datatype of PSC_filepath is invalid.\\\n",
    "            \\nExpect {} or {}, not {}\".format(\n",
    "                    type(\"1\"), geodata_type, type(PSC_filepath)\n",
    "                )\n",
    "            )\n",
    "    else:\n",
    "        sys.exit(\"{} invalid filetype\".format(type(filepath)))\n",
    "    return geodata\n",
    "\n",
    "\n",
    "def PSC_Within_Profile_Segment(psc_filepath, segment_filepath, distance=200):\n",
    "    # ---------------------------------------------\n",
    "    import warnings\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    import os\n",
    "    import sys\n",
    "\n",
    "    import geopandas as gpd\n",
    "    import pandas as pd\n",
    "    from tqdm import tqdm, trange\n",
    "\n",
    "    # ---------------------------------------------\n",
    "    radius = distance\n",
    "\n",
    "    # đọc shapefile của PS candidates\n",
    "\n",
    "    PSC_data = open_geodata(psc_filepath)\n",
    "\n",
    "    if PSC_data.crs == None:\n",
    "        PSC_data.crs = \"epsg:3826\"\n",
    "\n",
    "    # đọc shapefile của profile segment\n",
    "    segment_data = open_geodata(segment_filepath)\n",
    "    segment_data_length = len(segment_data)\n",
    "\n",
    "    # một dataframe trống để chứa thông tin các điểm bên trong buffer\n",
    "    empty_table = pd.DataFrame(data=None)\n",
    "\n",
    "    for i, _temp in zip(range(segment_data_length), trange(segment_data_length)):\n",
    "        try:\n",
    "            # profile_segment = segment_data.loc[i, :]\n",
    "            # profile_segment_buffer = profile_segment.geometry.buffer(radius)\n",
    "\n",
    "            profile_segment_buffer = segment_data.loc[i, :].geometry\n",
    "\n",
    "            psc_within_buffer = PSC_data.geometry.within(profile_segment_buffer)\n",
    "            selected_PSC_table = PSC_data[psc_within_buffer]\n",
    "\n",
    "            segment_name = segment_data.loc[i, \"Name\"]\n",
    "            selected_PSC_table[\"Segment\"] = segment_name\n",
    "\n",
    "            empty_table = pd.concat([empty_table, selected_PSC_table])\n",
    "        except Exception as e:\n",
    "            sys.exit(\"{} at location {}\".format(e, i))\n",
    "\n",
    "    empty_table.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    new_geospatial_datatable = gpd.GeoDataFrame(\n",
    "        data=empty_table, geometry=empty_table.geometry, crs=empty_table.crs\n",
    "    )\n",
    "\n",
    "    return new_geospatial_datatable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71af4fc9-c212-45b9-8626-850d3be5e77a",
   "metadata": {},
   "source": [
    "#### Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28e2b47a-0486-4ae4-941e-d01823c04776",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodata_filepath = r\"D:\\SENTINEL_1A_SAR_IMAGES\\030_REPROCESS_CHOUSHUI_P2\\CALIBRATION_PROCESS\\Calibrated_Files\\LOS_mm_ALL_POINTS_v010\\VERT_mm\\VERT_CALIBRATED_CUMDISP_mm_HSR_BUFFER\\VERT_CALIBRATED_CUMDISP_mm_HSR_BUFFER.pkl\"\n",
    "segment_shp_filepath = r\"E:\\002_ARCGIS_WORK\\ManuscriptArcGIS\\HSR_Shapefiles\\BUFFER\\SELECT_BUFFER\\BUFFER_CrossingLine_Segmented_W50_L5000.shp\"\n",
    "\n",
    "savefolder = r\"D:\\SENTINEL_1A_SAR_IMAGES\\030_REPROCESS_CHOUSHUI_P2\\CALIBRATION_PROCESS\\Calibrated_Files\\LOS_mm_ALL_POINTS_v010\\VERT_mm\\HSR_PROFILE\\CROSSTrackProfile\"\n",
    "extension_option = \"pkl\"\n",
    "\n",
    "if not os.path.exists(savefolder):\n",
    "    os.makedirs(savefolder)\n",
    "\n",
    "params_dict = {\n",
    "    \"geodata_filepath\": geodata_filepath,\n",
    "    \"segment_shp_filepath\": segment_shp_filepath,\n",
    "    \"savefolder\": savefolder,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb1e7f7-29d1-4fea-80a8-0ab4d64a7917",
   "metadata": {},
   "source": [
    "#### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b1f6a8f-15e8-4750-9455-86535f3d82a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|████████████████████████████████████████████████████████████████████████████████▏| 99/100 [00:05<00:00, 17.71it/s]\n",
      " 99%|████████████████████████████████████████████████████████████████████████████████▏| 99/100 [00:05<00:00, 17.92it/s]\n",
      " 99%|████████████████████████████████████████████████████████████████████████████████▏| 99/100 [00:05<00:00, 17.57it/s]\n",
      " 99%|████████████████████████████████████████████████████████████████████████████████▏| 99/100 [00:05<00:00, 17.90it/s]\n"
     ]
    }
   ],
   "source": [
    "segment_shp_data = gpd.read_file(segment_shp_filepath)\n",
    "\n",
    "unique_linename = segment_shp_data[\"LineName\"].unique()\n",
    "\n",
    "cache = []\n",
    "\n",
    "for line_name in unique_linename:\n",
    "\n",
    "    select_segment_data = segment_shp_data[segment_shp_data[\"LineName\"] == line_name]\n",
    "    select_segment_data = select_segment_data.reset_index(drop=True)\n",
    "\n",
    "    psc_data = PSC_Within_Profile_Segment(\n",
    "        psc_filepath=geodata_filepath, segment_filepath=select_segment_data\n",
    "    )\n",
    "\n",
    "    psc_data[\"LineName\"] = line_name\n",
    "\n",
    "    columns = psc_data.columns.tolist()\n",
    "    new_columns = columns[:-3] + columns[-3:][::-1]\n",
    "\n",
    "    output_table = psc_data[new_columns]\n",
    "\n",
    "    cache.append(output_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692771aa-1ba6-43fa-aa79-3af794075e5d",
   "metadata": {},
   "source": [
    "#### Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0395798b-3cac-4df5-bdef-58e7e75d5bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at D:\\SENTINEL_1A_SAR_IMAGES\\030_REPROCESS_CHOUSHUI_P2\\CALIBRATION_PROCESS\\Calibrated_Files\\LOS_mm_ALL_POINTS_v010\\VERT_mm\\HSR_PROFILE\\CROSSTrackProfile\n"
     ]
    }
   ],
   "source": [
    "output_data = pd.concat(cache, ignore_index=True)\n",
    "base = os.path.basename(segment_shp_filepath).split(\".\")[0]\n",
    "\n",
    "if extension_option == \"pkl\":\n",
    "    savename = \"Output_\" + base + \".pkl\"\n",
    "    savepath = os.path.join(savefolder, savename)\n",
    "    output_data.to_pickle(savepath, compression=\"zip\")\n",
    "elif extension_option == \"shp\":\n",
    "    savename = \"Output_\" + base + \".shp\"\n",
    "    savepath = os.path.join(savefolder, savename)\n",
    "    output_data.to_file(savepath)\n",
    "else:\n",
    "    raise (\"Invalid filetype!\")\n",
    "\n",
    "export_parameter_record(savefolder=savefolder, params_dict=params_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362b4023-92c7-4d97-8ac3-2b6a3e02eceb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
