{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38761c81-d831-4dd5-8672-6865daf64651",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "591de77d-a4ed-4624-b809-38d15f14e35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_parameter_record(savefolder, params_dict):\n",
    "\n",
    "    import os\n",
    "\n",
    "    for i in range(1, 1000):\n",
    "        savepath = os.path.join(savefolder, \"Param_Record_{}.txt\".format(str(i).zfill(3)))\n",
    "        if os.path.exists(savepath):\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    with open(savepath, \"w+\") as file:\n",
    "        for key, value in params_dict.items():\n",
    "            file.write(\"{} : {}\".format(key, value))\n",
    "            file.write(\"\\n\\n\")\n",
    "\n",
    "    pop_up_string = \"Saved at {}\".format(savefolder)\n",
    "    print(pop_up_string)\n",
    "\n",
    "\n",
    "def open_geodata(filepath):\n",
    "    import sys\n",
    "\n",
    "    import geopandas as gpd\n",
    "\n",
    "    geodata_type = type(gpd.GeoDataFrame())\n",
    "\n",
    "    if type(filepath) == geodata_type:\n",
    "        geodata = filepath\n",
    "    elif type(filepath) == str:\n",
    "        extension = filepath.split(\".\")[-1]\n",
    "        if extension == \"pkl\":\n",
    "            geodata = pd.read_pickle(filepath, compression=\"zip\")\n",
    "        elif extension == \"shp\":\n",
    "            geodata = gpd.read_file(filepath)\n",
    "        else:\n",
    "            sys.exit(\n",
    "                \"The datatype of PSC_filepath is invalid.\\\n",
    "            \\nExpect {} or {}, not {}\".format(\n",
    "                    type(\"1\"), geodata_type, type(PSC_filepath)\n",
    "                )\n",
    "            )\n",
    "    else:\n",
    "        sys.exit(\"{} invalid filetype\".format(type(filepath)))\n",
    "    return geodata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda920d1-dafa-4f41-a5f2-847c41028228",
   "metadata": {},
   "source": [
    "#### Data Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a60302d8-fa71-49c5-bbc4-1029d2d03dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_segment_psc_folder = r\"E:\\010__SS3_TRY_MY_BEST_TO_SURVIVE_POSTPROCESSING\\HSR_PROFILE_Manuscript\\CROSSTrackProfile\\CR_PSC_GeoData\"\n",
    "\n",
    "file2process = glob(os.path.join(profile_segment_psc_folder, \"Output_*\"))\n",
    "\n",
    "savefolder = r\"E:\\010__SS3_TRY_MY_BEST_TO_SURVIVE_POSTPROCESSING\\HSR_PROFILE_Manuscript\\CROSSTrackProfile\\CR_PSC_CSV_Export\"\n",
    "\n",
    "params_dict = {\n",
    "    \"profile_segment_psc_folder\": profile_segment_psc_folder,\n",
    "    \"file2process\": file2process,\n",
    "    \"savefolder\": savefolder,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11349c6-613e-4abd-902d-a0a9d38aaf8f",
   "metadata": {},
   "source": [
    "#### Function Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c382ae8f-eb33-4bbf-bbcf-7753551534c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at E:\\010__SS3_TRY_MY_BEST_TO_SURVIVE_POSTPROCESSING\\HSR_PROFILE_Manuscript\\CROSSTrackProfile\\CR_PSC_CSV_Export\n"
     ]
    }
   ],
   "source": [
    "for file in file2process:\n",
    "\n",
    "    data = open_geodata(file)\n",
    "\n",
    "    unique_linename = data[\"LineName\"].unique()\n",
    "\n",
    "    for line_name in unique_linename:\n",
    "\n",
    "        select_subdata = data[data[\"LineName\"] == line_name]\n",
    "\n",
    "        select_subdata = select_subdata.iloc[:, 2:-1]\n",
    "\n",
    "        select_subdata = select_subdata.drop(\"LineName\", axis=1)\n",
    "\n",
    "        unique_segment = np.unique(data[\"Segment\"].values)\n",
    "\n",
    "        amount_list = []\n",
    "\n",
    "        empty_mean = pd.DataFrame(data=None)\n",
    "        empty_stdev = pd.DataFrame(data=None)\n",
    "\n",
    "        for segment_name in unique_segment:\n",
    "\n",
    "            data_by_segment = select_subdata[select_subdata[\"Segment\"] == segment_name]\n",
    "            average_by_segment = data_by_segment.groupby(\"Segment\").mean()\n",
    "            stdev_by_segment = data_by_segment.groupby(\"Segment\").std()\n",
    "\n",
    "            amount_list.append(len(data_by_segment))\n",
    "\n",
    "            empty_mean = pd.concat([empty_mean, average_by_segment])\n",
    "            empty_stdev = pd.concat([empty_stdev, stdev_by_segment])\n",
    "\n",
    "        empty_mean[\"Pts_Num\"] = amount_list\n",
    "        empty_stdev[\"Pts_Num\"] = amount_list\n",
    "\n",
    "        savename_mean = \"{}_{}_{}.xlsx\".format(\"Mean\", os.path.basename(file)[:-4], line_name)\n",
    "        savename_stdev = \"{}_{}_{}.xlsx\".format(\"Stdev\", os.path.basename(file)[:-4], line_name)\n",
    "\n",
    "        empty_mean.to_excel(os.path.join(savefolder, savename_mean))\n",
    "        empty_stdev.to_excel(os.path.join(savefolder, savename_stdev))\n",
    "\n",
    "export_parameter_record(savefolder=savefolder, params_dict=params_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
