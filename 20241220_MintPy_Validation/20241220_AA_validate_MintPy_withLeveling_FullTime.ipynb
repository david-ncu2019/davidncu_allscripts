{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18dac78c-1cba-4d49-8135-26dc306ac37f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-26T03:55:21.465155Z",
     "iopub.status.busy": "2024-12-26T03:55:21.442157Z",
     "iopub.status.idle": "2024-12-26T03:55:40.741835Z",
     "shell.execute_reply": "2024-12-26T03:55:40.741835Z",
     "shell.execute_reply.started": "2024-12-26T03:55:21.458153Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current folder: E:\\001_InSAR_Project\\1100_CHOUSHUI_2025\\CRFP_full_2016_2024\\asc_desc_run003K\n",
      "Loading leveling benchmark shapefile...\n",
      "Searching for vertical displacement shapefile...\n",
      "Finding neighbors for each leveling benchmark...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39c366d6048d474180b602cbcc7a181f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1858 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading leveling data from HDF5 file...\n",
      "Filtering benchmarks by time interval...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b48bd57f9e2425680a072d12e9b2624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1228 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing leveling and InSAR measurements...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aebc585823449d285621da429f67079",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/664 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to E:\\001_InSAR_Project\\1100_CHOUSHUI_2025\\CRFP_full_2016_2024\\asc_desc_run003K\\Leveling_InSAR_inBuffer_100m.xlsx\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from appgeopy import *\n",
    "from my_packages import *\n",
    "\n",
    "# ====================================================\n",
    "# Configuration Parameters\n",
    "# ====================================================\n",
    "BUFFER_RADIUS = 100  # Buffer radius for InSAR point search, in meters\n",
    "START_YEAR = 2016  # Start year for analysis\n",
    "END_YEAR = 2023  # End year for analysis\n",
    "\n",
    "# ====================================================\n",
    "# File Paths\n",
    "# ====================================================\n",
    "LEVELING_SHP_PATH = r\"E:\\SUBSIDENCE_PROJECT_DATA\\地陷資料整理\\水準點\\LevelingBenchmarks_DavidNCU\\shapefiles\\leveling_benchmark_location.shp\"\n",
    "VERTICAL_DISP_FILE_PATTERN = f\"*{BUFFER_RADIUS}*.shp\"\n",
    "HDF5_FILE_PATH = r\"D:\\1000_SCRIPTS\\003_Project002\\20241219_LevelingData_to_HDF5\\20241220_All_LevelingData_LandSubsidence-wra-gov-tw.h5\"\n",
    "\n",
    "\n",
    "VERTICAL_DISP_FOLDER = r\"E:\\001_InSAR_Project\\1100_CHOUSHUI_2025\\CRFP_full_2016_2024\\asc_desc_run003L\"\n",
    "\n",
    "# for VERTICAL_DISP_FOLDER in tqdm(\n",
    "#     glob(os.path.join(r\"E:\\001_InSAR_Project\\1100_CHOUSHUI_2025\\CRFP_full_2016_2024\", \"asc_desc_run*\"))\n",
    "# ):\n",
    "\n",
    "print(f\"Current folder: {VERTICAL_DISP_FOLDER}\")\n",
    "# ====================================================\n",
    "# Load Data\n",
    "# ====================================================\n",
    "print(\"Loading leveling benchmark shapefile...\")\n",
    "leveling_shp = gpd.read_file(LEVELING_SHP_PATH)\n",
    "\n",
    "print(\"Searching for vertical displacement shapefile...\")\n",
    "vertical_disp_fpath = glob(os.path.join(VERTICAL_DISP_FOLDER, VERTICAL_DISP_FILE_PATTERN))\n",
    "if not vertical_disp_fpath:\n",
    "    raise FileNotFoundError(\"No matching vertical displacement shapefile found.\")\n",
    "vertical_disp_fpath = vertical_disp_fpath[0]\n",
    "vertical_disp_shp = gpd.read_file(vertical_disp_fpath)\n",
    "\n",
    "# ====================================================\n",
    "# Find Neighbors for Each Benchmark\n",
    "# ====================================================\n",
    "CENTRAL_KEY_COLUMN = \"樁號\"  # Key column for benchmark identifier\n",
    "results = []\n",
    "\n",
    "print(\"Finding neighbors for each leveling benchmark...\")\n",
    "for idx, row in tqdm(leveling_shp.iterrows(), total=len(leveling_shp)):\n",
    "    try:\n",
    "        result = geospatial.find_point_neighbors(row, vertical_disp_shp, CENTRAL_KEY_COLUMN, BUFFER_RADIUS)\n",
    "        results.append(result)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing row {idx}: {e}\")\n",
    "\n",
    "# Combine results into a single GeoDataFrame\n",
    "result_gdf = pd.concat(results, ignore_index=True)\n",
    "\n",
    "# Save results as a pickle file\n",
    "save_path = os.path.join(\n",
    "    VERTICAL_DISP_FOLDER, os.path.basename(vertical_disp_fpath).replace(\".shp\", \"_add_StationNum.pkl\")\n",
    ")\n",
    "result_gdf.to_pickle(save_path)\n",
    "\n",
    "# ====================================================\n",
    "# Load HDF5 Leveling Data\n",
    "# ====================================================\n",
    "print(\"Loading leveling data from HDF5 file...\")\n",
    "with h5py.File(HDF5_FILE_PATH, \"r\") as hdf5_file:\n",
    "    leveling_measure_dict = gwatertools.h5pytools.hdf5_to_data_dict(hdf5_file)\n",
    "    leveling_metadata_dict = gwatertools.h5pytools.hdf5_to_metadata_dict(hdf5_file)\n",
    "\n",
    "# Extract unique benchmarks in the buffer zone\n",
    "unique_leveling_StationNumber = result_gdf[CENTRAL_KEY_COLUMN].unique()\n",
    "\n",
    "# Filter valid benchmarks available in the database\n",
    "valid_leveling_StationNumber = sorted(\n",
    "    set(leveling_metadata_dict.keys()).intersection(set(unique_leveling_StationNumber))\n",
    ")\n",
    "\n",
    "# ====================================================\n",
    "# Filter Benchmarks by Time Interval\n",
    "# ====================================================\n",
    "satisfied_leveling_StationNumber = []\n",
    "print(\"Filtering benchmarks by time interval...\")\n",
    "for select_StationNumber in tqdm(valid_leveling_StationNumber):\n",
    "    metadata = leveling_metadata_dict[select_StationNumber]\n",
    "    first_record_date = pd.to_datetime(metadata[\"First_Record\"])\n",
    "    last_record_date = pd.to_datetime(metadata[\"Last_Record\"])\n",
    "    if first_record_date.year <= START_YEAR and last_record_date.year >= END_YEAR:\n",
    "        satisfied_leveling_StationNumber.append(select_StationNumber)\n",
    "\n",
    "# ====================================================\n",
    "# Compare Leveling and InSAR Measurements\n",
    "# ====================================================\n",
    "cache = {\"StationNumber\": [], \"Leveling_cm_yr\": [], \"InSAR_cm_yr\": []}\n",
    "\n",
    "print(\"Comparing leveling and InSAR measurements...\")\n",
    "for select_StationNumber in tqdm(satisfied_leveling_StationNumber):\n",
    "    try:\n",
    "        # Leveling Measurements\n",
    "        leveling_data = pd.DataFrame(leveling_measure_dict[select_StationNumber])\n",
    "        leveling_data[\"date\"] = leveling_data[\"date\"].apply(lambda x: x.decode(\"utf-8\"))\n",
    "        leveling_data[\"date\"] = pd.to_datetime(leveling_data[\"date\"])\n",
    "        leveling_data.set_index(\"date\", inplace=True)\n",
    "        subset_leveling_data = leveling_data.loc[str(START_YEAR) : str(END_YEAR)]\n",
    "\n",
    "        # Calculate leveling velocity\n",
    "        index_arr = subset_leveling_data.index\n",
    "        y_arr = subset_leveling_data[\"values\"].to_numpy()\n",
    "        days_diff = np.array((index_arr - index_arr[0]).days)\n",
    "        trend, coeffs = analysis.get_polynomial_trend(days_diff, y_arr, order=1)\n",
    "        leveling_slope = coeffs[-1] * 365.25  # m/year\n",
    "        leveling_slope_cm = leveling_slope * 100\n",
    "\n",
    "        # InSAR Measurements\n",
    "        insar_data = result_gdf.query(f\"{CENTRAL_KEY_COLUMN}==@select_StationNumber\")\n",
    "        insar_velocity = insar_data[\"grid_code\"].mean() * 100  # Convert to cm/year\n",
    "\n",
    "        # Append results to cache\n",
    "        cache[\"StationNumber\"].append(select_StationNumber)\n",
    "        cache[\"Leveling_cm_yr\"].append(leveling_slope_cm)\n",
    "        cache[\"InSAR_cm_yr\"].append(insar_velocity)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {select_StationNumber}: {e}\")\n",
    "\n",
    "# ====================================================\n",
    "# Save Results\n",
    "# ====================================================\n",
    "output_path = os.path.join(os.path.dirname(save_path), f\"Leveling_InSAR_inBuffer_{BUFFER_RADIUS}m.xlsx\")\n",
    "leveling_insar_df = pd.DataFrame(cache)\n",
    "leveling_insar_df.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"Results saved to {output_path}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebf0226-b366-4fd5-bfcd-84f05c34b21f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
